name: "ðŸ“º Fixed Narrator News Video Workflow"

on:
  workflow_dispatch:
    inputs:
      topic:
        description: "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ”ãƒƒã‚¯"
        required: true
        default: "æœ€æ–°ã®AIæŠ€è¡“å‹•å‘"
      narrator_seed:
        description: "ãƒŠãƒ¬ãƒ¼ã‚¿ãƒ¼ã®å›ºå®šseedå€¤ï¼ˆåŒã˜äººç‰©ã‚’ç¶­æŒï¼‰"
        required: false
        default: "japanese-female-announcer-2024"
      duration:
        description: "å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰"
        required: false
        default: "60"

env:
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  # Phase 1: Setup and Generate Fixed Narrator
  setup-and-narrator:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    outputs:
      project_dir: ${{ steps.setup.outputs.project_dir }}
      narrator_image_path: ${{ steps.narrator.outputs.image_path }}
      scene_count: ${{ steps.calculate.outputs.scene_count }}
      scene_list: ${{ steps.calculate.outputs.scene_list }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup project directory
        id: setup
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          PROJECT_DIR="projects/fixed-narrator-news-${TIMESTAMP}"
          mkdir -p "${PROJECT_DIR}"/{metadata,logs,media/{images,videos,audio},final,temp}
          echo "project_dir=${PROJECT_DIR}" >> $GITHUB_OUTPUT
          echo "âœ… Project directory: ${PROJECT_DIR}"

      - name: Calculate scene count
        id: calculate
        run: |
          DURATION="${{ inputs.duration }}"
          SCENE_COUNT=$((DURATION / 5))
          echo "scene_count=${SCENE_COUNT}" >> $GITHUB_OUTPUT
          
          # Generate scene list
          SCENE_LIST="["
          for i in $(seq 1 $SCENE_COUNT); do
            [ $i -gt 1 ] && SCENE_LIST="${SCENE_LIST},"
            SCENE_LIST="${SCENE_LIST}${i}"
          done
          SCENE_LIST="${SCENE_LIST}]"
          echo "scene_list=${SCENE_LIST}" >> $GITHUB_OUTPUT
          echo "âœ… Calculated ${SCENE_COUNT} scenes for ${DURATION} seconds"

      - name: Generate fixed Japanese female narrator
        id: narrator
        run: |
          PROJECT_DIR="${{ steps.setup.outputs.project_dir }}"
          SEED="${{ inputs.narrator_seed }}"
          
          # Generate consistent Japanese female news anchor
          NARRATOR_PROMPT="ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæ—¥æœ¬äººå¥³æ€§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã®ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

          é‡è¦ãªè¦ä»¶:
          - å¹´é½¢: 28-35æ­³ã®çŸ¥çš„ãªæ—¥æœ¬äººå¥³æ€§
          - æœè£…: ãƒ€ãƒ¼ã‚¯ãƒ–ãƒ«ãƒ¼ã¾ãŸã¯ã‚°ãƒ¬ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã‚¸ãƒ£ã‚±ãƒƒãƒˆ
          - é«ªåž‹: æ¸…æ½”æ„Ÿã®ã‚ã‚‹ã‚·ãƒ§ãƒ¼ãƒˆãƒœãƒ–ã¾ãŸã¯ã‚»ãƒŸãƒ­ãƒ³ã‚°ï¼ˆé»’é«ªï¼‰
          - è¡¨æƒ…: ç©ã‚„ã‹ã§ä¿¡é ¼æ„Ÿã®ã‚ã‚‹å¾®ç¬‘ã¿
          - èƒŒæ™¯: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ã‚¿ã‚¸ã‚ªé¢¨ï¼ˆã¼ã‹ã—æ°—å‘³ï¼‰
          - ãƒãƒ¼ã‚º: æ­£é¢å‘ãã€ã‚«ãƒ¡ãƒ©ç›®ç·š
          - ãƒ¡ã‚¤ã‚¯: ãƒŠãƒãƒ¥ãƒ©ãƒ«ã§å“ã®ã‚ã‚‹ãƒ¡ã‚¤ã‚¯
          
          æŠ€è¡“è¦ä»¶:
          - seedå€¤: ${SEED}ï¼ˆä¸€è²«æ€§ã®ãŸã‚å›ºå®šï¼‰
          - è§£åƒåº¦: 1920x1080
          - ã‚¹ã‚¿ã‚¤ãƒ«: ãƒ•ã‚©ãƒˆãƒªã‚¢ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã€æ”¾é€å“è³ª
          
          å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: japanese_female_narrator.png"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2i-kamui-imagen3__imagen_t2i,Write" \
            --max-turns 20 \
            --permission-mode "acceptEdits" \
            -p "$NARRATOR_PROMPT"

          # Move to project directory
          if [ -f "japanese_female_narrator.png" ]; then
            mv japanese_female_narrator.png "$PROJECT_DIR/media/images/"
            echo "image_path=$PROJECT_DIR/media/images/japanese_female_narrator.png" >> $GITHUB_OUTPUT
            echo "âœ… Fixed narrator image generated with seed: ${SEED}"
          else
            echo "âŒ Failed to generate narrator image"
            exit 1
          fi

      - name: Upload narrator artifact
        uses: actions/upload-artifact@v4
        with:
          name: narrator-image
          path: ${{ steps.setup.outputs.project_dir }}/media/images/japanese_female_narrator.png

  # Phase 2: Information Gathering
  gather-information:
    runs-on: ubuntu-latest
    needs: setup-and-narrator
    timeout-minutes: 8
    outputs:
      script_path: ${{ steps.script.outputs.path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Research and create script
        id: script
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          TOPIC="${{ inputs.topic }}"
          SCENE_COUNT="${{ needs.setup-and-narrator.outputs.scene_count }}"
          
          RESEARCH_PROMPT="ã€Œ${TOPIC}ã€ã«ã¤ã„ã¦æœ€æ–°æƒ…å ±ã‚’èª¿æŸ»ã—ã€${SCENE_COUNT}ã‚·ãƒ¼ãƒ³æ§‹æˆã®60ç§’ãƒ‹ãƒ¥ãƒ¼ã‚¹åŽŸç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

          è¦ä»¶:
          1. WebSearchã‚’ä½¿ç”¨ã—ã¦æœ€æ–°æƒ…å ±ã‚’åŽé›†
          2. ä¿¡é ¼ã§ãã‚‹è¤‡æ•°ã®æƒ…å ±æºã‹ã‚‰äº‹å®Ÿç¢ºèª
          3. å„ã‚·ãƒ¼ãƒ³5ç§’ã€è¨ˆ${SCENE_COUNT}ã‚·ãƒ¼ãƒ³ã®æ§‹æˆ
          4. æ—¥æœ¬äººå¥³æ€§ã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼ãŒèª­ã¿ä¸Šã’ã‚‹è‡ªç„¶ãªåŽŸç¨¿
          
          å‡ºåŠ›å½¢å¼:
          - news_script.json: ã‚·ãƒ¼ãƒ³ã”ã¨ã®åŽŸç¨¿ã¨ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æŒ‡ç¤º
          - narration_full.txt: å®Œå…¨ãªãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŽŸç¨¿
          
          åŽŸç¨¿ã®ãƒˆãƒ¼ãƒ³:
          - ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ä¿¡é ¼æ„Ÿã®ã‚ã‚‹å£èª¿
          - åˆ†ã‹ã‚Šã‚„ã™ãç°¡æ½”ãªè¡¨ç¾
          - è¦–è´è€…ã«å¯„ã‚Šæ·»ã†æ¸©ã‹ã¿ã®ã‚ã‚‹èªžã‚Š"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "WebSearch,Write" \
            --max-turns 30 \
            --permission-mode "acceptEdits" \
            -p "$RESEARCH_PROMPT"

          # Move files to project
          mkdir -p "$PROJECT_DIR/metadata"
          [ -f "news_script.json" ] && mv news_script.json "$PROJECT_DIR/metadata/"
          [ -f "narration_full.txt" ] && mv narration_full.txt "$PROJECT_DIR/metadata/"
          
          echo "path=$PROJECT_DIR/metadata/news_script.json" >> $GITHUB_OUTPUT
          echo "âœ… Script created for ${SCENE_COUNT} scenes"

      - name: Upload script artifact
        uses: actions/upload-artifact@v4
        with:
          name: news-script
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/metadata/

  # Phase 3: Generate Narration Audio
  generate-narration:
    runs-on: ubuntu-latest
    needs: [setup-and-narrator, gather-information]
    timeout-minutes: 8
    outputs:
      audio_path: ${{ steps.narration.outputs.path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download script
        uses: actions/download-artifact@v4
        with:
          name: news-script
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/metadata/

      - name: Generate narration audio
        id: narration
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          
          # Read narration text
          if [ -f "$PROJECT_DIR/metadata/narration_full.txt" ]; then
            NARRATION_TEXT=$(cat "$PROJECT_DIR/metadata/narration_full.txt")
          else
            NARRATION_TEXT="æœ¬æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠä¼ãˆã—ã¾ã™ã€‚${{ inputs.topic }}ã«ã¤ã„ã¦ã€æœ€æ–°ã®æƒ…å ±ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚"
          fi
          
          TTS_PROMPT="ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬äººå¥³æ€§ã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼ã®å£°ã§èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚

          ãƒ†ã‚­ã‚¹ãƒˆ:
          ${NARRATION_TEXT}
          
          éŸ³å£°è¦ä»¶:
          - å£°è³ª: ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªå¥³æ€§ã‚¢ãƒŠã‚¦ãƒ³ã‚µãƒ¼ï¼ˆè½ã¡ç€ã„ãŸã€ä¿¡é ¼æ„Ÿã®ã‚ã‚‹å£°ï¼‰
          - é€Ÿåº¦: ãƒ‹ãƒ¥ãƒ¼ã‚¹ç•ªçµ„ã«é©ã—ãŸæ¨™æº–çš„ãªé€Ÿåº¦
          - æŠ‘æš: é‡è¦éƒ¨åˆ†ã§ã®é©åˆ‡ãªå¼·èª¿
          - å…¨ä½“ã®é•·ã•: 60ç§’ä»¥å†…
          
          å‡ºåŠ›: narration_audio.mp3"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2s-kamui-minimax-speech__minimax_speech_02_turbo_submit,mcp__t2s-kamui-minimax-speech__minimax_speech_02_turbo_status,mcp__t2s-kamui-minimax-speech__minimax_speech_02_turbo_result,Write" \
            --max-turns 40 \
            --permission-mode "acceptEdits" \
            -p "$TTS_PROMPT"

          # Move audio to project
          if [ -f "narration_audio.mp3" ]; then
            mv narration_audio.mp3 "$PROJECT_DIR/media/audio/"
            echo "path=$PROJECT_DIR/media/audio/narration_audio.mp3" >> $GITHUB_OUTPUT
            echo "âœ… Narration audio generated"
          else
            echo "âŒ Failed to generate narration audio"
          fi

      - name: Upload audio artifact
        uses: actions/upload-artifact@v4
        with:
          name: narration-audio
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/media/audio/

  # Phase 4: Generate Scene Videos with Lip-sync
  generate-scenes:
    runs-on: ubuntu-latest
    needs: [setup-and-narrator, gather-information, generate-narration]
    timeout-minutes: 20
    strategy:
      matrix:
        scene: ${{ fromJson(needs.setup-and-narrator.outputs.scene_list) }}
      max-parallel: 6
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/

      - name: Generate scene with lip-sync
        id: scene
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          SCENE_ID="${{ matrix.scene }}"
          NARRATOR_IMAGE="$PROJECT_DIR/narrator-image/japanese_female_narrator.png"
          AUDIO_FILE="$PROJECT_DIR/narration-audio/narration_audio.mp3"
          
          # Calculate time offsets for this scene
          START_TIME=$(( (SCENE_ID - 1) * 5 ))
          END_TIME=$(( SCENE_ID * 5 ))
          
          # Extract audio segment for this scene
          ffmpeg -i "$AUDIO_FILE" -ss ${START_TIME} -t 5 -acodec copy "$PROJECT_DIR/temp/scene_${SCENE_ID}_audio.mp3"
          
          SCENE_PROMPT="ã‚·ãƒ¼ãƒ³${SCENE_ID}ã®ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

          å…¥åŠ›:
          - ãƒŠãƒ¬ãƒ¼ã‚¿ãƒ¼ç”»åƒ: ${NARRATOR_IMAGE}
          - éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: $PROJECT_DIR/temp/scene_${SCENE_ID}_audio.mp3
          - æ™‚é–“: ${START_TIME}ç§’ã‹ã‚‰${END_TIME}ç§’ï¼ˆ5ç§’é–“ï¼‰
          
          å‡¦ç†è¦ä»¶:
          1. æ—¥æœ¬äººå¥³æ€§ãƒŠãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ç”»åƒã‚’ä½¿ç”¨
          2. éŸ³å£°ã«åˆã‚ã›ãŸè‡ªç„¶ãªãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯
          3. ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼é¢¨ã®è»½å¾®ãªé ­ã®å‹•ã
          4. 5ç§’ã®å‹•ç”»ã¨ã—ã¦å‡ºåŠ›
          
          ä½¿ç”¨ãƒ„ãƒ¼ãƒ«å„ªå…ˆé †ä½:
          1. mcp__v2v-kamui-pixverse-lipsyncï¼ˆæŽ¨å¥¨ï¼‰
          2. mcp__v2v-kamui-creatify-lipsyncï¼ˆä»£æ›¿ï¼‰
          
          å‡ºåŠ›: scene_${SCENE_ID}_lipsync.mp4"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__v2v-kamui-pixverse-lipsync__pixverse_lipsync_submit,mcp__v2v-kamui-pixverse-lipsync__pixverse_lipsync_status,mcp__v2v-kamui-pixverse-lipsync__pixverse_lipsync_result,mcp__v2v-kamui-creatify-lipsync__lipsync_submit,mcp__v2v-kamui-creatify-lipsync__lipsync_status,mcp__v2v-kamui-creatify-lipsync__lipsync_result,Write,Read" \
            --max-turns 50 \
            --permission-mode "acceptEdits" \
            -p "$SCENE_PROMPT"

          # Move to project directory
          if [ -f "scene_${SCENE_ID}_lipsync.mp4" ]; then
            mv "scene_${SCENE_ID}_lipsync.mp4" "$PROJECT_DIR/media/videos/"
            echo "âœ… Scene ${SCENE_ID} with lip-sync completed"
          else
            echo "âš ï¸ Scene ${SCENE_ID} generation failed, creating fallback"
            # Fallback: Create simple video from image
            ffmpeg -loop 1 -i "$NARRATOR_IMAGE" -i "$PROJECT_DIR/temp/scene_${SCENE_ID}_audio.mp3" \
              -c:v libx264 -c:a aac -shortest -t 5 \
              "$PROJECT_DIR/media/videos/scene_${SCENE_ID}_lipsync.mp4"
          fi

      - name: Upload scene artifact
        uses: actions/upload-artifact@v4
        with:
          name: scene-${{ matrix.scene }}
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/media/videos/scene_${{ matrix.scene }}_lipsync.mp4

  # Phase 5: Final Composition
  final-composition:
    runs-on: ubuntu-latest
    needs: [setup-and-narrator, generate-scenes]
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all scenes
        uses: actions/download-artifact@v4
        with:
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/

      - name: Compose final video
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          SCENE_COUNT="${{ needs.setup-and-narrator.outputs.scene_count }}"
          
          # Create scene list file for concatenation
          echo "# Scene list for concatenation" > "$PROJECT_DIR/temp/scene_list.txt"
          for i in $(seq 1 $SCENE_COUNT); do
            SCENE_FILE="$PROJECT_DIR/scene-${i}/scene_${i}_lipsync.mp4"
            if [ -f "$SCENE_FILE" ]; then
              echo "file '$SCENE_FILE'" >> "$PROJECT_DIR/temp/scene_list.txt"
            fi
          done
          
          # Concatenate all scenes
          ffmpeg -f concat -safe 0 -i "$PROJECT_DIR/temp/scene_list.txt" \
            -c:v libx264 -c:a aac -movflags +faststart \
            "$PROJECT_DIR/final/news_video_complete.mp4"
          
          # Add news overlay graphics (optional)
          OVERLAY_PROMPT="æœ€çµ‚ãƒ‹ãƒ¥ãƒ¼ã‚¹å‹•ç”»ã«ãƒ†ãƒ­ãƒƒãƒ—ã¨ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

          å…¥åŠ›å‹•ç”»: $PROJECT_DIR/final/news_video_complete.mp4
          
          è¿½åŠ è¦ç´ :
          1. ãƒ‹ãƒ¥ãƒ¼ã‚¹ç•ªçµ„é¢¨ã®ãƒ­ã‚´ï¼ˆå·¦ä¸Šï¼‰
          2. ãƒˆãƒ”ãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¸‹éƒ¨ãƒ†ãƒ­ãƒƒãƒ—ï¼‰
          3. æ™‚åˆ»è¡¨ç¤ºï¼ˆå³ä¸Šï¼‰
          
          å‡ºåŠ›: news_video_final.mp4"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Read,Write,Bash" \
            --max-turns 20 \
            --permission-mode "acceptEdits" \
            -p "$OVERLAY_PROMPT"

          # Final check
          if [ -f "news_video_final.mp4" ]; then
            mv news_video_final.mp4 "$PROJECT_DIR/final/"
            echo "âœ… Final news video created with fixed narrator"
          elif [ -f "$PROJECT_DIR/final/news_video_complete.mp4" ]; then
            echo "âœ… Final news video created (without overlays)"
          else
            echo "âŒ Failed to create final video"
            exit 1
          fi

      - name: Upload final video
        uses: actions/upload-artifact@v4
        with:
          name: final-news-video
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/final/

      - name: Create summary
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          
          echo "# ðŸ“º Fixed Narrator News Video Generation Complete" > "$PROJECT_DIR/final/summary.md"
          echo "" >> "$PROJECT_DIR/final/summary.md"
          echo "## Details:" >> "$PROJECT_DIR/final/summary.md"
          echo "- Topic: ${{ inputs.topic }}" >> "$PROJECT_DIR/final/summary.md"
          echo "- Duration: ${{ inputs.duration }} seconds" >> "$PROJECT_DIR/final/summary.md"
          echo "- Narrator: Japanese female announcer (fixed)" >> "$PROJECT_DIR/final/summary.md"
          echo "- Scenes: ${{ needs.setup-and-narrator.outputs.scene_count }}" >> "$PROJECT_DIR/final/summary.md"
          echo "- Timestamp: $(date)" >> "$PROJECT_DIR/final/summary.md"
          echo "" >> "$PROJECT_DIR/final/summary.md"
          echo "## Output Files:" >> "$PROJECT_DIR/final/summary.md"
          ls -la "$PROJECT_DIR/final/" >> "$PROJECT_DIR/final/summary.md"
          
          cat "$PROJECT_DIR/final/summary.md"