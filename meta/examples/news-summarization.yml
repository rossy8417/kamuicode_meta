name: "AI News Summarization Workflow"
run-name: "ðŸ“° Analyzing news: ${{ github.event.inputs.news_topic || 'News Analysis' }}"

on:
  workflow_dispatch:
    inputs:
      news_topic:
        description: 'åˆ†æžå¯¾è±¡ãƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'
        required: true
        default: 'AIæŠ€è¡“ã®é€²å±•ã€æš—å·é€šè²¨å¸‚å ´å‹•å‘ã€æ°—å€™å¤‰å‹•å¯¾ç­–ã€çµŒæ¸ˆæ”¿ç­–'
        type: string
      news_sources:
        description: 'ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹'
        required: true
        type: choice
        options:
        - major_media
        - tech_media
        - business_media
        - international
        - comprehensive
        - specialized
        default: 'comprehensive'
      geographic_focus:
        description: 'åœ°åŸŸçš„ç„¦ç‚¹'
        required: true
        type: choice
        options:
        - global
        - japan
        - asia_pacific
        - north_america
        - europe
        default: 'global'
      analysis_period:
        description: 'åˆ†æžå¯¾è±¡æœŸé–“'
        required: true
        type: choice
        options:
        - 24hours
        - 3days
        - 1week
        - 2weeks
        - 1month
        default: '1week'
      summary_length:
        description: 'è¦ç´„ã®è©³ç´°åº¦'
        required: true
        type: choice
        options:
        - brief
        - standard
        - detailed
        - comprehensive
        default: 'standard'
      analysis_focus:
        description: 'åˆ†æžã®ç„¦ç‚¹'
        required: true
        type: choice
        options:
        - trend_analysis
        - sentiment_analysis
        - impact_analysis
        - stakeholder_analysis
        - comparative_analysis
        default: 'trend_analysis'
      output_format:
        description: 'ãƒ¡ã‚¤ãƒ³å‡ºåŠ›å½¢å¼'
        required: true
        type: choice
        options:
        - executive_summary
        - detailed_report
        - newsletter
        - bullet_points
        - timeline
        default: 'detailed_report'
      urgency_level:
        description: 'ç·Šæ€¥åº¦ãƒ»é‡è¦åº¦ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ1-5ï¼‰'
        required: true
        default: '3'
        type: choice
        options:
        - '1'
        - '2'
        - '3'
        - '4'
        - '5'
      include_sources:
        description: 'æƒ…å ±æºã®è¡¨ç¤º'
        required: false
        type: choice
        options:
        - full_citations
        - source_names
        - minimal
        - none
        default: 'source_names'

permissions:
  contents: write
  issues: read
  actions: read

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

jobs:
  # Phase 1: äº‹å‰ãƒ†ã‚¹ãƒˆæ®µéšŽ
  connectivity-test:
    runs-on: ubuntu-latest
    outputs:
      services_ready: ${{ steps.test.outputs.services_ready }}
      web_search_available: ${{ steps.test.outputs.web_search_available }}
      rss_available: ${{ steps.test.outputs.rss_available }}
      ai_analysis_available: ${{ steps.test.outputs.ai_analysis_available }}
    steps:
      - name: Test news collection services
        id: test
        run: |
          echo "ðŸ“° Testing news collection and analysis services..."
          
          mkdir -p generated/logs/connectivity-tests
          
          # Web Search API ãƒ†ã‚¹ãƒˆï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹åŽé›†ã§å¿…é ˆï¼‰
          echo "Testing web search services (required for news collection)..."
          if [ -n "${{ secrets.GOOGLE_SEARCH_API_KEY }}" ] && [ -n "${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}" ]; then
            if timeout 30 curl -s "https://www.googleapis.com/customsearch/v1?key=${{ secrets.GOOGLE_SEARCH_API_KEY }}&cx=${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}&q=latest+technology+news&num=5" > generated/logs/connectivity-tests/web-search-test.log 2>&1; then
              WEB_SEARCH_STATUS="success"
              echo "âœ… Google Search API: Available"
            else
              WEB_SEARCH_STATUS="failed"
              echo "âŒ Google Search API: Failed - Cannot collect news without search"
            fi
          else
            WEB_SEARCH_STATUS="not_configured"
            echo "âš ï¸ Google Search API: Not configured"
          fi
          
          # RSS Feed Parser ãƒ†ã‚¹ãƒˆï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ç”¨ï¼‰
          echo "Testing RSS feed parsing..."
          if timeout 30 curl -s "https://feeds.bbci.co.uk/news/rss.xml" | head -n 20 > generated/logs/connectivity-tests/rss-test.log 2>&1; then
            RSS_STATUS="success"
            echo "âœ… RSS Feed: Available"
          else
            RSS_STATUS="failed"
            echo "âš ï¸ RSS Feed: Not available - will use web search only"
          fi
          
          # Claude Code AIåˆ†æžæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆï¼ˆã‚«ã‚¹ã‚¿ãƒ åˆ†æžæ©Ÿèƒ½ï¼‰
          echo "Testing Claude Code AI analysis functions..."
          if timeout 20 claude-code --prompt "Test prompt: Analyze this sample news text: 'Technology stocks surge as AI developments continue.' Return 'TEST_SUCCESS' if working." > generated/logs/connectivity-tests/ai-analysis-test.log 2>&1; then
            if grep -q "TEST_SUCCESS" generated/logs/connectivity-tests/ai-analysis-test.log; then
              AI_ANALYSIS_STATUS="success"
              echo "âœ… Claude Code AI Analysis: Available"
            else
              AI_ANALYSIS_STATUS="partial"
              echo "âš ï¸ Claude Code AI Analysis: Partial - response received but format needs adjustment"
            fi
          else
            AI_ANALYSIS_STATUS="failed"
            echo "âŒ Claude Code AI Analysis: Failed - will use basic text analysis"
          fi
          
          # å¤–éƒ¨ãƒ‹ãƒ¥ãƒ¼ã‚¹API ãƒ†ã‚¹ãƒˆï¼ˆNewsAPIç­‰ï¼‰
          echo "Testing external news APIs..."
          if [ -n "${{ secrets.NEWS_API_KEY }}" ]; then
            if timeout 30 curl -s "https://newsapi.org/v2/top-headlines?apiKey=${{ secrets.NEWS_API_KEY }}&pageSize=1" > generated/logs/connectivity-tests/news-api-test.log 2>&1; then
              NEWS_API_STATUS="success"
              echo "âœ… News API: Available"
            else
              NEWS_API_STATUS="failed"
              echo "âš ï¸ News API: Failed - will use web search for collection"
            fi
          else
            NEWS_API_STATUS="not_configured"
            echo "â„¹ï¸ News API: Not configured - using web search"
          fi
          
          # æ„Ÿæƒ…åˆ†æžAPI ãƒ†ã‚¹ãƒˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆåˆ†æžç”¨ï¼‰
          echo "Testing sentiment analysis services..."
          if [ -n "${{ secrets.SENTIMENT_API_KEY }}" ]; then
            if timeout 20 curl -s -H "Authorization: Bearer ${{ secrets.SENTIMENT_API_KEY }}" "https://api.example-sentiment.com/analyze" -d "text=test" > generated/logs/connectivity-tests/sentiment-test.log 2>&1; then
              SENTIMENT_API_STATUS="success"
              echo "âœ… Sentiment API: Available"
            else
              SENTIMENT_API_STATUS="failed"
              echo "âš ï¸ Sentiment API: Failed - will use built-in analysis"
            fi
          else
            SENTIMENT_API_STATUS="not_configured"
            echo "â„¹ï¸ Sentiment API: Not configured - using built-in analysis"
          fi
          
          # ãƒ†ã‚¹ãƒˆçµæžœã‚’JSONä¿å­˜
          cat > generated/logs/connectivity-tests/test-results.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "required_for_workflow": {
              "web_search_api": "$WEB_SEARCH_STATUS",
              "rss_parser": "$RSS_STATUS",
              "ai_analysis": "$AI_ANALYSIS_STATUS",
              "news_api": "$NEWS_API_STATUS",
              "sentiment_api": "$SENTIMENT_API_STATUS"
            },
            "overall_status": "$([ "$WEB_SEARCH_STATUS" = "success" ] && echo "ready" || echo "degraded")",
            "critical_services_available": $([ "$WEB_SEARCH_STATUS" = "success" ] && echo "true" || echo "false"),
            "workflow_can_proceed": $([ "$WEB_SEARCH_STATUS" = "success" ] && echo "true" || echo "false"),
            "enhanced_features_available": $([ "$NEWS_API_STATUS" = "success" ] || [ "$RSS_STATUS" = "success" ] && echo "true" || echo "false")
          }
          EOF
          
          # ç’°å¢ƒå¤‰æ•°ã«çµæžœã‚’è¨­å®š
          echo "CONNECTIVITY_STATUS=$([ "$WEB_SEARCH_STATUS" = "success" ] && echo "ready" || echo "failed")" >> $GITHUB_ENV
          echo "ENHANCED_COLLECTION=$([ "$NEWS_API_STATUS" = "success" ] || [ "$RSS_STATUS" = "success" ] && echo "true" || echo "false")" >> $GITHUB_ENV
          echo "ADVANCED_ANALYSIS=$([ "$SENTIMENT_API_STATUS" = "success" ] && echo "true" || echo "false")" >> $GITHUB_ENV
          
          # Set outputs
          echo "services_ready=true" >> $GITHUB_OUTPUT
          echo "web_search_available=$WEB_SEARCH_STATUS" >> $GITHUB_OUTPUT
          echo "rss_available=$RSS_STATUS" >> $GITHUB_OUTPUT
          echo "ai_analysis_available=$AI_ANALYSIS_STATUS" >> $GITHUB_OUTPUT
          
          echo "ðŸ“° News service connectivity tests completed"

  # Phase 2: æƒ…å ±åŽé›†æ®µéšŽ
  topic-extraction:
    needs: connectivity-test
    runs-on: ubuntu-latest
    outputs:
      keywords_ready: ${{ steps.extract.outputs.keywords_ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Extract analysis topics and keywords
        id: extract
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          echo "ðŸ” Extracting analysis topics and keywords..."
          
          mkdir -p generated/logs/information-gathering
          
          # å…¥åŠ›ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã¾ãŸã¯ã‚¤ã‚·ãƒ¥ãƒ¼ã‹ã‚‰åˆ†æžå¯¾è±¡ã‚’æŠ½å‡º
          INPUT_TOPIC="${{ github.event.inputs.news_topic }}"
          ANALYSIS_PERIOD="${{ github.event.inputs.analysis_period }}"
          
          echo "Input topic: $INPUT_TOPIC"
          echo "Analysis period: $ANALYSIS_PERIOD"
          
          # Claude Code ã§ãƒˆãƒ”ãƒƒã‚¯åˆ†æžãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
          claude-code --prompt "ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æžè¦æ±‚ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦JSONå½¢å¼ã§å›žç­”ã—ã¦ãã ã•ã„ï¼š
          
          åˆ†æžå¯¾è±¡: $INPUT_TOPIC
          æœŸé–“: $ANALYSIS_PERIOD
          åœ°åŸŸç„¦ç‚¹: ${{ github.event.inputs.geographic_focus }}
          ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹: ${{ github.event.inputs.news_sources }}
          
          JSONå½¢å¼ã§æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨åˆ†æžæ–¹é‡ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚" > generated/logs/information-gathering/topic-analysis.json
          
          echo "keywords_ready=true" >> $GITHUB_OUTPUT
          echo "âœ… Topic and keyword extraction completed"

  # Phase 3: ãƒ‹ãƒ¥ãƒ¼ã‚¹åŽé›†æ®µéšŽ
  news-collection:
    needs: topic-extraction
    runs-on: ubuntu-latest
    outputs:
      collection_ready: ${{ steps.collect.outputs.collection_ready }}
    steps:
      - name: Collect news from multiple sources
        id: collect
    env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          echo "ðŸ“° Collecting news from multiple sources..."
          
          mkdir -p generated/logs/information-gathering/sources
          
          # Web Search API ã‚’ä½¿ç”¨ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹åŽé›†
          echo "Collecting from web search..."
          if [ -n "${{ secrets.GOOGLE_SEARCH_API_KEY }}" ] && [ -n "${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}" ]; then
            curl -s "https://www.googleapis.com/customsearch/v1?key=${{ secrets.GOOGLE_SEARCH_API_KEY }}&cx=${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}&q=${SEARCH_KEYWORDS}+news&num=10&dateRestrict=d1" \
              > generated/logs/information-gathering/sources/web-search-results.json 2>&1
          else
            echo '{"items":[]}' > generated/logs/information-gathering/sources/web-search-results.json
          fi
          
          # è¿½åŠ ã®æ¤œç´¢ï¼ˆç•°ãªã‚‹è§’åº¦ã‹ã‚‰ï¼‰
          echo "Collecting additional perspectives..."
          RELATED_TERMS=$(echo "$TOPIC_ANALYSIS" | jq -r '.related_terms[0:3] | join("+")')
          if [ -n "${{ secrets.GOOGLE_SEARCH_API_KEY }}" ] && [ -n "${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}" ]; then
            curl -s "https://www.googleapis.com/customsearch/v1?key=${{ secrets.GOOGLE_SEARCH_API_KEY }}&cx=${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}&q=${RELATED_TERMS}+analysis+report&num=10" \
              > generated/logs/information-gathering/sources/related-search-results.json 2>&1
          else
            echo '{"items":[]}' > generated/logs/information-gathering/sources/related-search-results.json
          fi
          
          # å¤–éƒ¨ãƒ‹ãƒ¥ãƒ¼ã‚¹APIä½¿ç”¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
          if [ "$ENHANCED_COLLECTION" = "true" ] && [ -n "${{ secrets.NEWS_API_KEY }}" ]; then
            echo "Collecting from News API..."
            curl -s "https://newsapi.org/v2/everything?q=$SEARCH_KEYWORDS&sortBy=publishedAt&pageSize=30&apiKey=${{ secrets.NEWS_API_KEY }}" \
              > generated/logs/information-gathering/sources/news-api-results.json 2>&1 || echo "News API collection failed"
          fi
          
          # RSS ãƒ•ã‚£ãƒ¼ãƒ‰åŽé›†ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
          if [ "$RSS_STATUS" = "success" ]; then
            echo "Collecting from RSS feeds..."
            # ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆã®RSSãƒ•ã‚£ãƒ¼ãƒ‰
            curl -s "https://rss.cnn.com/rss/edition.rss" | head -n 100 > generated/logs/information-gathering/sources/cnn-rss.xml 2>&1 || echo '{"items":[]}' > generated/logs/information-gathering/sources/cnn-rss.json
            curl -s "https://feeds.reuters.com/reuters/topNews" | head -n 100 > generated/logs/information-gathering/sources/reuters-rss.xml 2>&1 || echo '{"items":[]}' > generated/logs/information-gathering/sources/reuters-rss.json
          fi
          
          # åŽé›†çµæžœã®çµ±åˆ
          echo "Consolidating collected news..."
          claude-code --prompt "ä»¥ä¸‹ã®è¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰åŽé›†ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆãƒ»æ•´ç†ã—ã¦ãã ã•ã„ï¼š
          
          Webæ¤œç´¢çµæžœ: $(cat generated/logs/information-gathering/sources/web-search-results.json 2>/dev/null || echo '{}')
          é–¢é€£æ¤œç´¢çµæžœ: $(cat generated/logs/information-gathering/sources/related-search-results.json 2>/dev/null || echo '{}')
          $([ -f 'generated/logs/information-gathering/sources/news-api-results.json' ] && echo "News APIçµæžœ: $(cat generated/logs/information-gathering/sources/news-api-results.json)" || echo "")
          
          ä»¥ä¸‹ã®å½¢å¼ã§JSONã§å›žç­”ã—ã¦ãã ã•ã„ï¼š
          {
            \"collection_summary\": {
              \"total_articles_found\": \"åŽé›†è¨˜äº‹æ•°\",
              \"unique_sources\": \"ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚½ãƒ¼ã‚¹æ•°\",
              \"collection_timespan\": \"åŽé›†å¯¾è±¡æœŸé–“\",
              \"collection_timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"
            },
            \"articles\": [
              {
                \"title\": \"è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«\",
                \"source\": \"æƒ…å ±æº\",
                \"url\": \"è¨˜äº‹URL\",
                \"published_date\": \"å…¬é–‹æ—¥æ™‚\",
                \"summary\": \"è¨˜äº‹è¦ç´„\",
                \"relevance_score\": \"1-10ç‚¹ã§ã®é–¢é€£æ€§ã‚¹ã‚³ã‚¢\",
                \"source_credibility\": \"high|medium|low\"
              }
            ],
            \"collection_quality\": {
              \"coverage_completeness\": \"1-10ç‚¹ã§ã®ç¶²ç¾…æ€§\",
              \"source_diversity\": \"1-10ç‚¹ã§ã®ã‚½ãƒ¼ã‚¹å¤šæ§˜æ€§\",
              \"content_freshness\": \"1-10ç‚¹ã§ã®æƒ…å ±æ–°é®®åº¦\"
            }
          }" > generated/logs/information-gathering/consolidated-news.json
          
          CONSOLIDATED_NEWS=$(cat generated/logs/information-gathering/consolidated-news.json)
          echo "collection_ready=true" >> $GITHUB_OUTPUT
          echo "ðŸ“° Multi-source news collection completed"

  # Phase 4: ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æžæ®µéšŽ
  news-analysis:
    needs: news-collection
    runs-on: ubuntu-latest
    outputs:
      analysis_ready: ${{ steps.analyze.outputs.analysis_ready }}
    steps:
      - name: Analyze collected news content
        id: analyze
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          echo "ðŸ” Analyzing collected news content..."
          
          mkdir -p generated/logs/news-analysis
          
          claude-code --prompt "åŽé›†ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†æžã—ã€ä»¥ä¸‹ã®è¦³ç‚¹ã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š
          
          åˆ†æžç„¦ç‚¹: ${{ github.event.inputs.analysis_focus }}
          è¦ç´„ãƒ¬ãƒ™ãƒ«: ${{ github.event.inputs.summary_length }}
          æœŸé–“: ${{ github.event.inputs.analysis_period }}
          
          JSONå½¢å¼ã§åˆ†æžçµæžœã‚’è¿”ã—ã¦ãã ã•ã„ã€‚" > generated/logs/news-analysis/analysis-report.json
          
          echo "analysis_ready=true" >> $GITHUB_OUTPUT
          echo "ðŸ” News analysis completed"

  # Phase 5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ®µéšŽ
  report-generation:
    needs: news-analysis
    runs-on: ubuntu-latest
    outputs:
      report_ready: ${{ steps.generate.outputs.report_ready }}
    steps:
      - name: Generate comprehensive news report
        id: generate
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          echo "ðŸ“‹ Generating comprehensive news report..."
          
          mkdir -p generated/logs/report-generation
          
          claude-code --prompt "åˆ†æžã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
          
          å‡ºåŠ›å½¢å¼: ${{ github.event.inputs.output_format }}
          æƒ…å ±æºè¡¨ç¤º: ${{ github.event.inputs.include_sources }}
          ç·Šæ€¥åº¦ãƒ¬ãƒ™ãƒ«: ${{ github.event.inputs.urgency_level }}
          
          æŒ‡å®šã•ã‚ŒãŸå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚" > generated/logs/report-generation/final-report.json
          
          echo "report_ready=true" >> $GITHUB_OUTPUT
          echo "ðŸ“‹ Report generation completed"

  # Phase 6: æœ€çµ‚ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆ
  final-packaging:
    needs: [connectivity-test, topic-extraction, news-collection, news-analysis, report-generation]
    runs-on: ubuntu-latest
    steps:
      - name: Create comprehensive news analysis package
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          echo "ðŸ“¦ Creating comprehensive news analysis package..."
          
          mkdir -p .final-output/{analysis,reports,sources}
          
          # åˆ†æžãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
          cp generated/logs/information-gathering/topic-analysis.json .final-output/analysis/ 2>/dev/null || true
          cp generated/logs/news-analysis/analysis-report.json .final-output/analysis/ 2>/dev/null || true
          
          # ãƒ¬ãƒãƒ¼ãƒˆ
          cp generated/logs/report-generation/final-report.json .final-output/reports/ 2>/dev/null || true
          
          # ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
          cp generated/logs/information-gathering/consolidated-news.json .final-output/sources/ 2>/dev/null || true
          
          # ãƒžã‚¹ã‚¿ãƒ¼æƒ…å ±
          cat > .final-output/news-analysis-master.json << EOF
          {
            "project_info": {
              "project_name": "AI News Summarization & Analysis",
              "created_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "github_run_id": "${{ github.run_id }}",
              "analysis_type": "news_summarization_and_analysis"
            },
            "input_parameters": {
              "news_topic": "${{ github.event.inputs.news_topic }}",
              "news_sources": "${{ github.event.inputs.news_sources }}",
              "geographic_focus": "${{ github.event.inputs.geographic_focus }}",
              "analysis_period": "${{ github.event.inputs.analysis_period }}",
              "summary_length": "${{ github.event.inputs.summary_length }}",
              "analysis_focus": "${{ github.event.inputs.analysis_focus }}",
              "output_format": "${{ github.event.inputs.output_format }}",
              "urgency_level": "${{ github.event.inputs.urgency_level }}",
              "include_sources": "${{ github.event.inputs.include_sources }}"
            },
            "deliverables": {
              "analysis_documents": {
                "topic_analysis": "analysis/topic-analysis.json",
                "content_analysis": "analysis/analysis-report.json"
              },
              "reports": {
                "final_report": "reports/final-report.json"
              },
              "source_data": {
                "consolidated_news": "sources/consolidated-news.json"
              }
            }
          }
          EOF
          
          echo "ðŸ“¦ Final news analysis packaging completed"
          
      - name: Upload News Analysis Package
        uses: actions/upload-artifact@v4
        with:
          name: news-analysis-package-${{ github.run_number }}
          path: .final-output/
          retention-days: 30
