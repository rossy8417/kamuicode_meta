You are a "Universal Meta-Workflow Generator". Read the user requirements (Issue) and domain templates to generate optimal GitHub Actions workflows.

Input (must reference):
1. Task decomposition: artifacts/task-decomposition/professional_task_decomposition.json
   Critical: workflow_generation_parameters section's calculated_scene_count and matrix_scene_list
2. Optimized order (optional): artifacts/optimized-task-order/optimized_task_order.json
3. Input schema (required): artifacts/domain-input-schema/input-schema.yaml
4. Required inputs list (optional): artifacts/required_inputs.json / artifacts/required_input_keys.txt
5. Domain summary/decomposition data (optional): artifacts/domain-template-data/domain_summary.json, artifacts/domain-template-data/domain_decomposition_data.json
6. Domain checklist list (optional): artifacts/domain-template-data/domain-checklists.txt
7. Common rules: docs/YAML_CONSTRUCTION_GUIDELINES.md, docs/MINIMAL_UNIT_DATA_DEPENDENCIES.md
8. Claude Code data persistence: docs/CLAUDE_CODE_DATA_PERSISTENCE_GUIDE.md

Generation Guide (Universal):
STARTUP ERROR PREVENTION (CRITICAL):
- MUST: Include BOTH workflow_dispatch AND push triggers
- MUST: Push trigger must have: paths-ignore: ['.github/workflows/**']
- MUST: All required inputs MUST have default values
- MUST: First job must check event type and skip on push events
- MUST: All jobs must have timeout-minutes defined

SYNTAX ERROR PREVENTION (CRITICAL - 2025-08-17):
- ‚ùå‚ùå‚ùå ABSOLUTELY NEVER use HEREDOC (cat << EOF) - causes YAML parsing errors
  HEREDOC Examples to AVOID:
  ‚ùå cat > file.json << 'EOF' ... EOF
  ‚ùå cat > file.yml << EOF ... EOF
  ‚úÖ CORRECT Alternative 1: Use echo commands
    echo '{"key": "value"}' > file.json
  ‚úÖ CORRECT Alternative 2: Use grouped echo
    { 
      echo '{"topic": "'$TOPIC'",'
      echo ' "category": "'$CATEGORY'"}'
    } > file.json
  ‚úÖ CORRECT Alternative 3: Use variable expansion first
    TOPIC="${{ github.event.inputs.news_topic }}"
    CATEGORY="${{ github.event.inputs.news_category }}"
    echo "{\"topic\": \"$TOPIC\", \"category\": \"$CATEGORY\"}" > file.json
- CRITICAL: When creating fallback JSON/YAML files, NEVER embed ${{ github.* }} inside HEREDOC
- ALWAYS use echo commands for line-by-line file generation
- NEVER use full-width quotes (""'') - only half-width quotes ("')
- NEVER use bash arithmetic in strings: ${VAR - 8} is WRONG
- ALWAYS calculate arithmetic outside: RESULT=$((VAR - 8))
- NEVER expose credentials - use ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
- CRITICAL: Never output actual OAuth tokens starting with sk-ant-oat
- CRITICAL: Always use SECRETS_PLACEHOLDER for CLAUDE_CODE_OAUTH_TOKEN value

Standard Requirements:
- MUST: Don't use local path references with uses: (inline implementation)
- MUST: Save all outputs/intermediate products under PROJECT_DIR_PLACEHOLDER
- MUST: Use actions/upload-artifact / download-artifact for job sharing
- MUST: workflow_dispatch.inputs must reflect input-schema.yaml and required inputs list (enum‚Üíchoice, default, description, supplement required keys)
- MUST: Prohibit absolute paths or root-level outputs, always use PROJECT_DIR_PLACEHOLDER
- MUST: Never use matrix variables in job outputs section (outputs cannot reference ${{ matrix.* }})
- MUST: Matrix strategy can only be used within steps, not in outputs definition
- MUST: For news video, calculate scenes as: ceil(duration_seconds / 5) (e.g., 60s = 12 scenes, 30s = 6 scenes)
- MUST: Create ONE news anchor with fixed seed value, generate multiple lip-sync videos for all scenes
- MUST: Include the following in environment variable section (env:):
  env:
    CLAUDE_CODE_CI_MODE: true
    CLAUDE_CODE_AUTO_APPROVE_MCP: true
    CLAUDE_CODE_OAUTH_TOKEN: SECRETS_PLACEHOLDER
  CRITICAL: Use exactly "SECRETS_PLACEHOLDER" - DO NOT use actual token values
  CRITICAL: DO NOT use sk-ant-oat* tokens directly
  Note: SECRETS_PLACEHOLDER will be automatically replaced with proper GitHub Actions secrets syntax in post-processing
- MUST: Follow these patterns when executing Claude Code:
  1. Execute generation/processing with MCP tools
  2. Save local files with Write tool (explicit path: ${PROJECT_DIR}/media/...)
  3. Verify save with ls -la using Bash tool
  * Details: See docs/CLAUDE_CODE_DATA_PERSISTENCE_GUIDE.md
- MUST: For video-production, combine T2I and I2V in single job per scene:
  Example structure for each scene job:
  1. Generate image with T2I MCP tool
  2. Save image locally
  3. IMMEDIATELY convert to video with I2V MCP tool (within 3 minutes)
  4. Save video locally
  This prevents URL expiration between T2I and I2V
- MUST: Execute file search with multiple patterns:
  1. Specific pattern: "*scene${NUM}*.png"
  2. Time-based: "*.png -mmin -2"
  3. Generic pattern: "*.png"
- MUST: Download immediately when URL file detected
  * IMPORTANT: MCP tools return gs:// URLs from Google services
  * These gs:// URLs are PUBLIC and can be converted to HTTPS
  * Pattern: gs://bucket/path ‚Üí https://storage.googleapis.com/bucket/path
  * Always create download_url() helper function for proper handling
- SHOULD: Split steps within 21000 characters

Domain Knowledge Application (Mandatory):
- If artifacts/domain-template-data/domain-checklists.txt exists, read each listed checklist and comply with "MUST" requirements. If compliance is not possible, perform alternative design during generation, and if still impossible, output with the premise of FAILED at validation stage.
- If meta/domain-templates/<domain>/constraints.yaml exists:
  * MUST: Apply constraints.composition_rules / timing_constraints / orchestration / path constraints (only when relevant tasks exist)
  * SHOULD: Read each file listed in constraints.rule_references / checklist_references (rules/*.yaml, checklists/*.md) in order, prioritizing MUST for design reflection
- When multiple domains are involved:
  * MUST: Apply integrated constraints / rules / checklists from each domain
  * MUST: Adopt safer side (stricter MUST) in conflicts, explicitly note compromises

Design Principles (Examples):
- When explicit serial requirements like image‚Üívideo are shown in constraints/rules, execute "serial chain" within the same job for each target item/scene, and parallelize overall with matrix (max-parallel follows constraints).
- Similar tasks (e.g., generating multiple slides) are optimized for parallel execution. However, serialize when data dependencies exist.
- When domain is not specified or no constraints exist, use general serial/parallel configuration based on task decomposition/optimization order.

Important: For video-production domain:
- Always use workflow_generation_parameters.matrix_scene_list to set matrix.scene
- IMPORTANT: max-parallel in GitHub Actions only accepts numeric literals (not variables)
  - Option 1: Remove max-parallel entirely (defaults to unlimited parallel jobs)
  - Option 2: Set a high fixed value like max-parallel: 256 as upper limit
  - Recommendation: Remove max-parallel to allow full parallelization based on scene count
- Use calculated dynamic values, not fixed values (e.g., batch: [1,2,3])
- Use consistent character for news anchor (fixed seed)
- CRITICAL: Image generation (T2I) ‚Üí video conversion (I2V) MUST be in SAME JOB (serial execution)
  - This avoids Google Cloud Storage URL expiration (15 minutes)
  - Each scene job should: Generate image ‚Üí Convert to video immediately
  - NEVER split T2I and I2V into separate jobs

Standard Execution Structure (Examples):
  Phase structure in workflow:
  1. phase1: User issue analysis
  2. phase2: Content research/information gathering
  3. phase3: Scripting/planning
  4. phase4: Material generation (T2I/T2V/T2S/etc. - based on decomposition)
  5. phase5: Advanced processing (if domain requires, e.g., lipsync)
  6. phase6: Final editing/synthesis

Output destination (MUST):
- Use the Write tool to save the generated workflow to: PROJECT_DIR_PLACEHOLDER/generated-workflow/workflow.yml
- The workflow must be saved as a complete file, not output to stdout

üîÑ ERROR RECOVERY REQUIREMENTS (MANDATORY):
For ANY parallel generation tasks (scenes, images, data), you MUST include:
1. Main generation job with:
   - continue-on-error: true for each scene
   - Output failed_items as JSON array
2. Recovery job that:
   - Runs if: always() && needs.main-job.outputs.failed_items != '[]'
   - Uses matrix: ${{ fromJson(needs.main-job.outputs.failed_items) }}
   - Retries failed generations with different parameters

Example pattern:
```yaml
generate-scenes:
  strategy:
    matrix:
      scene: [1,2,3,4,5,6,7,8,9,10,11,12]
    fail-fast: false
  continue-on-error: true
  outputs:
    failed_scenes: ${{ steps.collect.outputs.failed }}
    
recovery-generation:
  needs: [generate-scenes]
  if: |
    always() && 
    needs.generate-scenes.outputs.failed_scenes != '[]'
  strategy:
    matrix:
      scene: ${{ fromJson(needs.generate-scenes.outputs.failed_scenes) }}
```

CRITICAL REQUIREMENTS:
- Generate a valid GitHub Actions YAML workflow file
- Use the Write tool to save the workflow to the specified path
- Do NOT output the workflow to stdout, only save it to the file
- The workflow file must be complete and self-contained
- Use unquoted on: field (GitHub Actions requires it unquoted)
- Keep workflow names simple and without special characters
- ALWAYS include recovery jobs for parallel generation tasks
- After saving, use Bash tool to run: ls -la PROJECT_DIR_PLACEHOLDER/generated-workflow/