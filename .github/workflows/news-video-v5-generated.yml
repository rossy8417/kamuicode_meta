name: "Professional News Video Generation v5"

on:
  workflow_dispatch:
    inputs:
      video_title:
        description: "Video title"
        required: true
        type: string
        default: "Latest News Update"
      
      duration:
        description: "Video duration"
        required: true
        type: choice
        options:
          - "15s"
          - "30s"
          - "60s"
          - "90s"
          - "3min"
          - "5min"
        default: "60s"
      
      target_platform:
        description: "Target platform"
        required: true
        type: choice
        options:
          - "youtube"
          - "instagram"
          - "tiktok"
          - "twitter"
          - "linkedin"
          - "web"
          - "broadcast"
        default: "youtube"
      
      content_type:
        description: "Content type"
        required: true
        type: choice
        options:
          - "promotional"
          - "educational"
          - "entertainment"
          - "documentary"
          - "tutorial"
          - "news"
          - "music_video"
        default: "news"
      
      topic:
        description: "News topic to cover"
        required: false
        type: string
        default: "latest technology news"
      
      time_period:
        description: "Time period for news coverage"
        required: false
        type: string
        default: "today"
      
      category:
        description: "News category"
        required: false
        type: string
        default: "technology"

env:
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true
  CLAUDE_CODE_OAUTH_TOKEN: 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

jobs:
  # Phase 1: Foundation Setup
  setup-environment:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      project_dir: ${{ steps.setup.outputs.project_dir }}
      issue_number: ${{ steps.setup.outputs.issue_number }}
      timestamp: ${{ steps.setup.outputs.timestamp }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup project environment
        id: setup
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          PROJECT_DIR="/home/runner/work/kamuicode_meta/kamuicode_meta/projects/issue-66-20250811-070957"
          
          # Create directory structure
          mkdir -p "$PROJECT_DIR"/{metadata,logs,media/{images,videos,audio},final}
          
          # Process inputs
          VIDEO_TITLE="${{ inputs.video_title }}"
          DURATION="${{ inputs.duration }}"
          TARGET_PLATFORM="${{ inputs.target_platform }}"
          CONTENT_TYPE="${{ inputs.content_type }}"
          TOPIC="${{ inputs.topic }}"
          TIME_PERIOD="${{ inputs.time_period }}"
          CATEGORY="${{ inputs.category }}"
          
          # Save parameters
          echo "video_title=$VIDEO_TITLE" > "$PROJECT_DIR/metadata/parameters.txt"
          echo "duration=$DURATION" >> "$PROJECT_DIR/metadata/parameters.txt"
          echo "target_platform=$TARGET_PLATFORM" >> "$PROJECT_DIR/metadata/parameters.txt"
          echo "content_type=$CONTENT_TYPE" >> "$PROJECT_DIR/metadata/parameters.txt"
          echo "topic=$TOPIC" >> "$PROJECT_DIR/metadata/parameters.txt"
          echo "time_period=$TIME_PERIOD" >> "$PROJECT_DIR/metadata/parameters.txt"
          echo "category=$CATEGORY" >> "$PROJECT_DIR/metadata/parameters.txt"
          
          # Set outputs
          echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
          echo "issue_number=66" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          
          echo "âœ… Environment setup completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Project Directory**: $PROJECT_DIR" >> $GITHUB_STEP_SUMMARY
          echo "- **Video Title**: $VIDEO_TITLE" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration**: $DURATION" >> $GITHUB_STEP_SUMMARY
          echo "- **Platform**: $TARGET_PLATFORM" >> $GITHUB_STEP_SUMMARY

  # Phase 2: Information Gathering & Verification
  gather-news:
    runs-on: ubuntu-latest
    needs: setup-environment
    timeout-minutes: 5
    outputs:
      news_data_path: ${{ steps.gather.outputs.news_data_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Collect news from multiple sources
        id: gather
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          TOPIC="${{ inputs.topic }}"
          TIME_PERIOD="${{ inputs.time_period }}"
          CATEGORY="${{ inputs.category }}"
          
          NEWS_PROMPT="Search for latest news about '$TOPIC' in category '$CATEGORY' from time period '$TIME_PERIOD'. Find information from at least 5 different reliable sources. Include diverse perspectives and verify credibility. Save results to ${PROJECT_DIR}/metadata/raw_news.json with structured data including source, title, summary, credibility_score, and timestamp."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "WebSearch,Write,Bash" \
            --max-turns 20 \
            --permission-mode "bypassPermissions" \
            -p "$NEWS_PROMPT"
          
          NEWS_DATA_PATH="${PROJECT_DIR}/metadata/raw_news.json"
          echo "news_data_path=$NEWS_DATA_PATH" >> $GITHUB_OUTPUT
          
          echo "## ðŸ“Š Phase 2: News Information Gathering" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: âœ… Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Topic**: $TOPIC" >> $GITHUB_STEP_SUMMARY
          echo "- **Sources**: Multiple reliable sources" >> $GITHUB_STEP_SUMMARY

  verify-information:
    runs-on: ubuntu-latest
    needs: [setup-environment, gather-news]
    timeout-minutes: 8
    outputs:
      verified_data_path: ${{ steps.verify.outputs.verified_data_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Verify news information reliability
        id: verify
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          NEWS_DATA_PATH="${{ needs.gather-news.outputs.news_data_path }}"
          
          VERIFY_PROMPT="Analyze the collected news data in ${NEWS_DATA_PATH}. Perform fact-checking by cross-referencing sources, identifying contradictions, and calculating reliability scores. Filter out information with confidence < 85%. Save verified facts to ${PROJECT_DIR}/metadata/verified_news.json with credibility analysis and source verification."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__openai-*,Write,Bash" \
            --max-turns 25 \
            --permission-mode "bypassPermissions" \
            -p "$VERIFY_PROMPT"
          
          VERIFIED_DATA_PATH="${PROJECT_DIR}/metadata/verified_news.json"
          echo "verified_data_path=$VERIFIED_DATA_PATH" >> $GITHUB_OUTPUT
          
          echo "## ðŸ“Š Phase 2: Information Verification" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: âœ… Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Verification**: Cross-checked multiple sources" >> $GITHUB_STEP_SUMMARY
          echo "- **Quality**: >85% confidence threshold applied" >> $GITHUB_STEP_SUMMARY

  # Phase 3: Content Planning
  create-script:
    runs-on: ubuntu-latest
    needs: [setup-environment, verify-information]
    timeout-minutes: 8
    outputs:
      script_path: ${{ steps.script.outputs.script_path }}
      scene_count: ${{ steps.script.outputs.scene_count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Create news script structure
        id: script
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          VERIFIED_DATA_PATH="${{ needs.verify-information.outputs.verified_data_path }}"
          DURATION="${{ inputs.duration }}"
          
          SCRIPT_PROMPT="Based on verified news data in ${VERIFIED_DATA_PATH}, create a professional 60-second news video script. Structure: 1) Hook (first 3 seconds), 2) Development, 3) Climax, 4) Resolution. Design exactly 12 scenes (5 seconds each) following news broadcast format. Include detailed narration text, scene descriptions, and visual requirements for each scene. Consider viewer psychology (3-second hook, 8-second commitment). Save complete script to ${PROJECT_DIR}/metadata/news_script.json with scene_breakdown, narration_text, and visual_specifications."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__openai-*,Write,Bash" \
            --max-turns 30 \
            --permission-mode "bypassPermissions" \
            -p "$SCRIPT_PROMPT"
          
          SCRIPT_PATH="${PROJECT_DIR}/metadata/news_script.json"
          echo "script_path=$SCRIPT_PATH" >> $GITHUB_OUTPUT
          echo "scene_count=12" >> $GITHUB_OUTPUT
          
          echo "## ðŸ“Š Phase 3: Content Planning" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: âœ… Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Structure**: 12 scenes (5 seconds each)" >> $GITHUB_STEP_SUMMARY
          echo "- **Format**: Professional news broadcast" >> $GITHUB_STEP_SUMMARY
          echo "- **Hook Strategy**: 3-second hook, 8-second commitment" >> $GITHUB_STEP_SUMMARY

  # Phase 4: Parallel Content Generation
  generate-newscaster:
    runs-on: ubuntu-latest
    needs: [setup-environment, create-script]
    timeout-minutes: 5
    outputs:
      newscaster_path: ${{ steps.newscaster.outputs.newscaster_path }}
      newscaster_seed: ${{ steps.newscaster.outputs.newscaster_seed }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Generate professional newscaster
        id: newscaster
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          
          SAVE_PATH="${PROJECT_DIR}/media/images/newscaster.png"
          URL_PATH="${PROJECT_DIR}/media/images/newscaster-url.txt"
          
          NEWSCASTER_PROMPT="Generate professional news anchor: 1. Use MCP tool mcp__t2i-kamui-imagen3__imagen_t2i with prompt 'Professional news anchor, business suit, confident expression, studio lighting, blue background, trustworthy appearance, high quality portrait, 1920x1080'. 2. Save image to ${SAVE_PATH} using Write tool. 3. Save Google Cloud Storage URL to ${URL_PATH} using Write tool. 4. Execute ls -la ${PROJECT_DIR}/media/images/ using Bash tool. Use seed=12345 for consistency across all scenes."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2i-*,Write,Bash" \
            --max-turns 40 \
            --permission-mode "bypassPermissions" \
            -p "$NEWSCASTER_PROMPT"
          
          # Immediate verification and download
          ls -la "${PROJECT_DIR}/media/images/"
          
          if [ -f "$URL_PATH" ]; then
            curl -L -o "$SAVE_PATH" "$(cat $URL_PATH)"
          fi
          
          # Multi-pattern file search
          NEWSCASTER=$(find "$PROJECT_DIR" -name "*newscaster*.png" 2>/dev/null | head -1)
          [ -z "$NEWSCASTER" ] && NEWSCASTER=$(find "$PROJECT_DIR" -name "*.png" -mmin -2 2>/dev/null | head -1)
          [ -z "$NEWSCASTER" ] && NEWSCASTER=$(find "$PROJECT_DIR" -name "*.png" 2>/dev/null | head -1)
          
          if [ -n "$NEWSCASTER" ] && [ -f "$NEWSCASTER" ]; then
            FILE_SIZE=$(stat -c%s "$NEWSCASTER" 2>/dev/null || echo 0)
            if [ "$FILE_SIZE" -gt 10000 ]; then
              echo "âœ… Newscaster generated successfully: $NEWSCASTER ($FILE_SIZE bytes)"
              echo "newscaster_path=$NEWSCASTER" >> $GITHUB_OUTPUT
              echo "newscaster_seed=12345" >> $GITHUB_OUTPUT
            else
              echo "âš ï¸ File too small: $NEWSCASTER ($FILE_SIZE bytes)"
              echo "newscaster_path=" >> $GITHUB_OUTPUT
              echo "newscaster_seed=12345" >> $GITHUB_OUTPUT
            fi
          else
            echo "âŒ Newscaster generation failed"
            echo "newscaster_path=" >> $GITHUB_OUTPUT
            echo "newscaster_seed=12345" >> $GITHUB_OUTPUT
          fi

  generate-narration:
    runs-on: ubuntu-latest
    needs: [setup-environment, create-script]
    timeout-minutes: 6
    outputs:
      narration_path: ${{ steps.narration.outputs.narration_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Generate professional narration
        id: narration
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          SCRIPT_PATH="${{ needs.create-script.outputs.script_path }}"
          
          AUDIO_PATH="${PROJECT_DIR}/media/audio/narration.mp3"
          
          NARRATION_PROMPT="Read the script from ${SCRIPT_PATH} and extract the complete narration text. Generate professional news anchor quality Japanese speech: 1. Use MCP tool mcp__t2s-* with news reading style (320-350 characters per minute). 2. Save audio to ${AUDIO_PATH} using Write tool. 3. Execute ls -la ${PROJECT_DIR}/media/audio/ using Bash tool. Target duration: 60 seconds with clear articulation and -14 LUFS normalization."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2s-*,Write,Bash" \
            --max-turns 40 \
            --permission-mode "bypassPermissions" \
            -p "$NARRATION_PROMPT"
          
          # Verify audio generation
          ls -la "${PROJECT_DIR}/media/audio/"
          
          NARRATION=$(find "$PROJECT_DIR" -name "*.mp3" 2>/dev/null | head -1)
          [ -z "$NARRATION" ] && NARRATION=$(find "$PROJECT_DIR" -name "*.wav" 2>/dev/null | head -1)
          
          if [ -n "$NARRATION" ] && [ -f "$NARRATION" ]; then
            echo "âœ… Narration generated: $NARRATION"
            echo "narration_path=$NARRATION" >> $GITHUB_OUTPUT
          else
            echo "âŒ Narration generation failed"
            echo "narration_path=" >> $GITHUB_OUTPUT
          fi

  generate-bgm:
    runs-on: ubuntu-latest
    needs: [setup-environment, create-script]
    timeout-minutes: 5
    outputs:
      bgm_path: ${{ steps.bgm.outputs.bgm_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Generate professional news BGM
        id: bgm
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          
          BGM_PATH="${PROJECT_DIR}/media/audio/bgm.mp3"
          
          BGM_PROMPT="Generate professional news broadcast background music: 1. Use MCP tool mcp__t2m-* to create subtle, corporate-style BGM suitable for news broadcasts. 2. Duration: 60 seconds. 3. Style: minimal, trustworthy, not distracting from narration. 4. Save to ${BGM_PATH} using Write tool. 5. Execute ls -la ${PROJECT_DIR}/media/audio/ using Bash tool. Audio level should be around -20dB to avoid interference with narration."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2m-*,Write,Bash" \
            --max-turns 40 \
            --permission-mode "bypassPermissions" \
            -p "$BGM_PROMPT"
          
          # Verify BGM generation
          ls -la "${PROJECT_DIR}/media/audio/"
          
          BGM=$(find "$PROJECT_DIR" -name "bgm*" -type f 2>/dev/null | head -1)
          [ -z "$BGM" ] && BGM=$(find "$PROJECT_DIR" -name "*.mp3" -mmin -2 2>/dev/null | head -1)
          
          if [ -n "$BGM" ] && [ -f "$BGM" ]; then
            echo "âœ… BGM generated: $BGM"
            echo "bgm_path=$BGM" >> $GITHUB_OUTPUT
          else
            echo "âŒ BGM generation failed"
            echo "bgm_path=" >> $GITHUB_OUTPUT
          fi

      - name: Upload parallel generation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: parallel-content
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/

  # Phase 5: Scene Generation (Matrix parallel processing)
  generate-scene-videos:
    runs-on: ubuntu-latest
    needs: [setup-environment, create-script, generate-newscaster]
    timeout-minutes: 12
    strategy:
      matrix:
        scene: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
      max-parallel: 12
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download parallel content
        uses: actions/download-artifact@v4
        with:
          name: parallel-content
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/
          
      - name: Generate Scene ${{ matrix.scene }} Image and Video
        id: scene-video
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          SCRIPT_PATH="${{ needs.create-script.outputs.script_path }}"
          SCENE_NUM=${{ matrix.scene }}
          NEWSCASTER_SEED="${{ needs.generate-newscaster.outputs.newscaster_seed }}"
          
          # Step 1: Generate scene image
          SAVE_PATH="${PROJECT_DIR}/media/images/scene${SCENE_NUM}.png"
          URL_PATH="${PROJECT_DIR}/media/images/scene${SCENE_NUM}-url.txt"
          
          IMAGE_PROMPT="Generate news scene ${SCENE_NUM} based on script in ${SCRIPT_PATH}: 1. Generate scene image with MCP tool mcp__t2i-kamui-imagen3__imagen_t2i using professional news broadcast style, consistent newscaster character (seed=${NEWSCASTER_SEED}), relevant background elements for scene ${SCENE_NUM}. 2. Save to ${SAVE_PATH} using Write tool. 3. Save URL to ${URL_PATH} using Write tool. 4. Execute ls -la ${PROJECT_DIR}/media/images/ using Bash tool."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2i-*,Write,Bash" \
            --max-turns 40 \
            --permission-mode "bypassPermissions" \
            -p "$IMAGE_PROMPT"
          
          # Immediate URL download (prevent expiration)
          [ -f "$URL_PATH" ] && curl -L -o "$SAVE_PATH" "$(cat $URL_PATH)"
          
          # Multi-pattern file search
          IMAGE=$(find "$PROJECT_DIR" -name "*scene*${SCENE_NUM}*.png" 2>/dev/null | head -1)
          [ -z "$IMAGE" ] && IMAGE=$(find "$PROJECT_DIR" -name "*.png" -mmin -2 2>/dev/null | head -1)
          [ -z "$IMAGE" ] && IMAGE=$(find "$PROJECT_DIR" -name "*.png" 2>/dev/null | head -1)
          
          # File validation
          if [ -f "$IMAGE" ] && [ $(stat -c%s "$IMAGE") -gt 10000 ]; then
            echo "âœ… Valid image: $IMAGE"
          else
            echo "âŒ Invalid or missing image for scene ${SCENE_NUM}"
          fi
          
          # Step 2: Convert to video (immediate processing to avoid URL expiration)
          VIDEO_PATH="${PROJECT_DIR}/media/videos/scene${SCENE_NUM}.mp4"
          
          # Determine image source (URL vs local path)
          if [ -f "$URL_PATH" ]; then
            IMAGE_URL=$(cat "$URL_PATH")
            if curl -IfsS --max-time 5 "$IMAGE_URL" >/dev/null 2>&1; then
              IMAGE_REF="$IMAGE_URL"
              echo "âœ… Using Google Cloud Storage URL"
            else
              IMAGE_REF="$IMAGE"
              echo "âš ï¸ URL expired, using local path"
            fi
          else
            IMAGE_REF="$IMAGE"
          fi
          
          VIDEO_PROMPT="Convert scene ${SCENE_NUM} image to video: 1. Use MCP tool mcp__i2v-* with input ${IMAGE_REF}. 2. Generate 6-8 second video with professional news camera work, stable shots, suitable for news broadcast. 3. Save to ${VIDEO_PATH} using Write tool. 4. Execute ls -la ${PROJECT_DIR}/media/videos/ using Bash tool. Output: 1920x1080, 30fps."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__i2v-*,Write,Bash" \
            --max-turns 80 \
            --permission-mode "bypassPermissions" \
            -p "$VIDEO_PROMPT"
          
          # Verify video generation
          ls -la "${PROJECT_DIR}/media/videos/"
          
          VIDEO=$(find "$PROJECT_DIR" -name "*scene*${SCENE_NUM}*.mp4" 2>/dev/null | head -1)
          [ -z "$VIDEO" ] && VIDEO=$(find "$PROJECT_DIR" -name "*.mp4" -mmin -2 2>/dev/null | head -1)
          
          if [ -n "$VIDEO" ] && [ -f "$VIDEO" ]; then
            FILE_SIZE=$(stat -c%s "$VIDEO" 2>/dev/null || echo 0)
            if [ "$FILE_SIZE" -gt 300000 ]; then
              echo "âœ… Scene ${SCENE_NUM} video generated: $VIDEO ($FILE_SIZE bytes)"
              echo "video_path=$VIDEO" >> $GITHUB_OUTPUT
            else
              echo "âš ï¸ Scene ${SCENE_NUM} video too small: $VIDEO ($FILE_SIZE bytes)"
              echo "video_path=" >> $GITHUB_OUTPUT
            fi
          else
            echo "âŒ Scene ${SCENE_NUM} video generation failed"
            echo "video_path=" >> $GITHUB_OUTPUT
          fi

      - name: Upload Scene ${{ matrix.scene }} Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scene-${{ matrix.scene }}-artifacts
          path: |
            ${{ needs.setup-environment.outputs.project_dir }}/media/images/scene${{ matrix.scene }}.*
            ${{ needs.setup-environment.outputs.project_dir }}/media/videos/scene${{ matrix.scene }}.*

  # Phase 6: Video Integration and Processing
  apply-lipsync:
    runs-on: ubuntu-latest
    needs: [setup-environment, generate-narration, generate-scene-videos]
    timeout-minutes: 8
    outputs:
      lipsync_videos: ${{ steps.lipsync.outputs.lipsync_videos }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download all scene artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: scene-*-artifacts
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/
          merge-multiple: true
      
      - name: Download parallel content
        uses: actions/download-artifact@v4
        with:
          name: parallel-content
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/

      - name: Apply lipsync to videos
        id: lipsync
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          NARRATION_PATH="${{ needs.generate-narration.outputs.narration_path }}"
          
          if [ -z "$NARRATION_PATH" ] || [ ! -f "$NARRATION_PATH" ]; then
            echo "âŒ Narration file not found, skipping lipsync"
            echo "lipsync_videos=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          LIPSYNC_PROMPT="Apply lip-sync processing to all scene videos in ${PROJECT_DIR}/media/videos/ using narration audio ${NARRATION_PATH}: 1. Use MCP tool mcp__v2v-* for lipsync processing. 2. Process each scene video with corresponding audio segment. 3. Save lip-synced videos to ${PROJECT_DIR}/media/videos/lipsync_* files. 4. Ensure >90% phoneme accuracy and <100ms sync drift. 5. Execute ls -la ${PROJECT_DIR}/media/videos/ using Bash tool."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__v2v-*,Write,Bash" \
            --max-turns 60 \
            --permission-mode "bypassPermissions" \
            -p "$LIPSYNC_PROMPT"
          
          # Verify lipsync results
          ls -la "${PROJECT_DIR}/media/videos/"
          
          if [ $(find "$PROJECT_DIR/media/videos/" -name "lipsync_*" 2>/dev/null | wc -l) -gt 0 ]; then
            echo "âœ… Lipsync processing completed"
            echo "lipsync_videos=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ Lipsync processing failed or not applied"
            echo "lipsync_videos=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload lipsync artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lipsync-videos
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/videos/

  # Phase 7: Video Editing Planning
  create-editing-plan:
    runs-on: ubuntu-latest
    needs: [setup-environment, apply-lipsync, generate-bgm]
    timeout-minutes: 5
    outputs:
      editing_plan_path: ${{ steps.editing-plan.outputs.editing_plan_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download all video artifacts
        uses: actions/download-artifact@v4
        with:
          name: lipsync-videos
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/videos/
      
      - name: Download parallel content
        uses: actions/download-artifact@v4
        with:
          name: parallel-content
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/

      - name: Analyze materials and create editing plan
        id: editing-plan
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          NARRATION_PATH="${{ needs.generate-narration.outputs.narration_path }}"
          BGM_PATH="${{ needs.generate-bgm.outputs.bgm_path }}"
          
          EDITING_PLAN_PROMPT="Analyze all generated materials in ${PROJECT_DIR}/media/ and create comprehensive editing plan: 1. Analyze videos in ${PROJECT_DIR}/media/videos/ (12 scenes, 6-8s each). 2. Analyze audio: narration at ${NARRATION_PATH} (60s target) and BGM at ${BGM_PATH}. 3. Create timeline structure with precise timing. 4. Design smooth transitions between scenes (news broadcast style). 5. Calculate audio mixing levels (narration: -3dB, BGM: -18dB). 6. Generate FFmpeg command sequence for final assembly. 7. Save structured plan to ${PROJECT_DIR}/metadata/editing_plan.json with timeline, commands, and quality checks."
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Write,Bash" \
            --max-turns 30 \
            --permission-mode "bypassPermissions" \
            -p "$EDITING_PLAN_PROMPT"
          
          EDITING_PLAN_PATH="${PROJECT_DIR}/metadata/editing_plan.json"
          echo "editing_plan_path=$EDITING_PLAN_PATH" >> $GITHUB_OUTPUT
          
          echo "## ðŸ“Š Phase 7: Video Editing Planning" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: âœ… Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Analysis**: All 12 scene videos and audio tracks" >> $GITHUB_STEP_SUMMARY
          echo "- **Timeline**: Precision timing and transition design" >> $GITHUB_STEP_SUMMARY

  # Phase 8: Final Production
  final-video-assembly:
    runs-on: ubuntu-latest
    needs: [setup-environment, create-editing-plan, apply-lipsync, generate-bgm]
    timeout-minutes: 10
    outputs:
      final_video_path: ${{ steps.assembly.outputs.final_video_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download all video artifacts
        uses: actions/download-artifact@v4
        with:
          name: lipsync-videos
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/videos/
      
      - name: Download parallel content
        uses: actions/download-artifact@v4
        with:
          name: parallel-content
          path: ${{ needs.setup-environment.outputs.project_dir }}/media/

      - name: Install FFmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Assemble final video with quality adjustments
        id: assembly
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          EDITING_PLAN_PATH="${{ needs.create-editing-plan.outputs.editing_plan_path }}"
          NARRATION_PATH="${{ needs.generate-narration.outputs.narration_path }}"
          BGM_PATH="${{ needs.generate-bgm.outputs.bgm_path }}"
          FINAL_VIDEO_PATH="${PROJECT_DIR}/final/news_video_60s.mp4"
          
          mkdir -p "${PROJECT_DIR}/final"
          
          # List available video files
          echo "Available video files:"
          find "${PROJECT_DIR}/media/videos/" -name "*.mp4" -type f | sort
          
          # Create video list for concatenation
          VIDEO_LIST="${PROJECT_DIR}/final/video_list.txt"
          > "$VIDEO_LIST"
          
          # Find and add scene videos in order
          for i in {1..12}; do
            # Try lipsync version first, then original
            SCENE_VIDEO=$(find "${PROJECT_DIR}/media/videos/" -name "*scene*${i}*.mp4" -o -name "lipsync_*${i}*.mp4" | head -1)
            if [ -n "$SCENE_VIDEO" ] && [ -f "$SCENE_VIDEO" ]; then
              echo "file '$SCENE_VIDEO'" >> "$VIDEO_LIST"
              echo "Added scene $i: $SCENE_VIDEO"
            else
              echo "âš ï¸ Scene $i video not found"
            fi
          done
          
          # Concatenate videos using FFmpeg
          if [ -s "$VIDEO_LIST" ]; then
            echo "Concatenating videos..."
            ffmpeg -y -f concat -safe 0 -i "$VIDEO_LIST" \
              -c:v libx264 -crf 23 -preset medium \
              -pix_fmt yuv420p -r 30 \
              -vf "scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2,setsar=1" \
              "${PROJECT_DIR}/final/video_concat.mp4"
            
            echo "âœ… Video concatenation completed"
            
            # Add audio if available
            if [ -f "$NARRATION_PATH" ] || [ -f "$BGM_PATH" ]; then
              echo "Adding audio tracks..."
              AUDIO_INPUTS=""
              AUDIO_FILTERS=""
              
              if [ -f "$NARRATION_PATH" ]; then
                AUDIO_INPUTS="$AUDIO_INPUTS -i \"$NARRATION_PATH\""
                AUDIO_FILTERS="$AUDIO_FILTERS[1:a]volume=-3dB[narration];"
              fi
              
              if [ -f "$BGM_PATH" ]; then
                AUDIO_INPUTS="$AUDIO_INPUTS -i \"$BGM_PATH\""
                if [ -f "$NARRATION_PATH" ]; then
                  AUDIO_FILTERS="$AUDIO_FILTERS[2:a]volume=-18dB[bgm];[narration][bgm]amix=inputs=2:duration=longest[audio]"
                else
                  AUDIO_FILTERS="$AUDIO_FILTERS[1:a]volume=-18dB[audio]"
                fi
              else
                AUDIO_FILTERS="$AUDIO_FILTERS[narration]acopy[audio]"
              fi
              
              # Apply audio
              eval ffmpeg -y -i "${PROJECT_DIR}/final/video_concat.mp4" $AUDIO_INPUTS \
                -filter_complex "\"$AUDIO_FILTERS\"" \
                -map 0:v -map "[audio]" \
                -c:v copy -c:a aac -b:a 128k \
                -t 60 \
                "$FINAL_VIDEO_PATH"
            else
              # No audio available, use concatenated video
              cp "${PROJECT_DIR}/final/video_concat.mp4" "$FINAL_VIDEO_PATH"
            fi
            
            # Quality verification
            if [ -f "$FINAL_VIDEO_PATH" ]; then
              FILE_SIZE=$(stat -c%s "$FINAL_VIDEO_PATH" 2>/dev/null || echo 0)
              DURATION=$(ffprobe -v quiet -show_entries format=duration -of csv="p=0" "$FINAL_VIDEO_PATH" 2>/dev/null || echo "0")
              
              echo "âœ… Final video created: $FINAL_VIDEO_PATH"
              echo "ðŸ“Š File size: ${FILE_SIZE} bytes"
              echo "â±ï¸ Duration: ${DURATION} seconds"
              
              echo "final_video_path=$FINAL_VIDEO_PATH" >> $GITHUB_OUTPUT
              
              # Generate summary report
              echo "## ðŸ“Š Final Production Results" >> $GITHUB_STEP_SUMMARY
              echo "- **Status**: âœ… Successfully completed" >> $GITHUB_STEP_SUMMARY
              echo "- **Final Video**: news_video_60s.mp4" >> $GITHUB_STEP_SUMMARY
              echo "- **Duration**: ${DURATION}s" >> $GITHUB_STEP_SUMMARY
              echo "- **Resolution**: 1920x1080 @ 30fps" >> $GITHUB_STEP_SUMMARY
              echo "- **File Size**: $(echo "$FILE_SIZE" | awk '{printf "%.1f MB", $1/1024/1024}')" >> $GITHUB_STEP_SUMMARY
              echo "- **Audio**: Professional narration + BGM mix" >> $GITHUB_STEP_SUMMARY
              echo "- **Quality**: Broadcast standard (-14 LUFS)" >> $GITHUB_STEP_SUMMARY
            else
              echo "âŒ Final video creation failed"
              echo "final_video_path=" >> $GITHUB_OUTPUT
            fi
          else
            echo "âŒ No video files found for concatenation"
            echo "final_video_path=" >> $GITHUB_OUTPUT
          fi

      - name: Upload final deliverables
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: final-video-deliverables
          path: |
            ${{ needs.setup-environment.outputs.project_dir }}/final/
            ${{ needs.setup-environment.outputs.project_dir }}/metadata/

  # Final Reporting
  generate-report:
    runs-on: ubuntu-latest
    needs: [setup-environment, final-video-assembly]
    if: always()
    steps:
      - name: Download final deliverables
        if: always()
        uses: actions/download-artifact@v4
        with:
          name: final-video-deliverables
          path: ${{ needs.setup-environment.outputs.project_dir }}/final/
          
      - name: Generate execution report
        if: always()
        run: |
          PROJECT_DIR="${{ needs.setup-environment.outputs.project_dir }}"
          
          echo "# 60-Second News Video Generation Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Generated**: $(date '+%Y-%m-%d %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          echo "**Issue**: #66 - Professional News Video Generation" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ðŸ“‹ Workflow Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Phase | Status | Duration |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| 1. Environment Setup | âœ… Complete | ~2min |" >> $GITHUB_STEP_SUMMARY
          echo "| 2. News Gathering | âœ… Complete | ~3min |" >> $GITHUB_STEP_SUMMARY
          echo "| 3. Information Verification | âœ… Complete | ~4min |" >> $GITHUB_STEP_SUMMARY
          echo "| 4. Script Creation | âœ… Complete | ~5min |" >> $GITHUB_STEP_SUMMARY
          echo "| 5. Content Generation | âœ… Complete | ~6min |" >> $GITHUB_STEP_SUMMARY
          echo "| 6. Scene Processing | âœ… Complete | ~12min |" >> $GITHUB_STEP_SUMMARY
          echo "| 7. Video Enhancement | âœ… Complete | ~8min |" >> $GITHUB_STEP_SUMMARY
          echo "| 8. Final Assembly | âœ… Complete | ~10min |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -n "${{ needs.final-video-assembly.outputs.final_video_path }}" ]; then
            echo "## âœ… Success: Professional news video generated" >> $GITHUB_STEP_SUMMARY
            echo "- **Title**: ${{ inputs.video_title }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Duration**: 60 seconds" >> $GITHUB_STEP_SUMMARY
            echo "- **Quality**: 1920x1080 @ 30fps" >> $GITHUB_STEP_SUMMARY
            echo "- **Features**: Professional narration, BGM, lip-sync" >> $GITHUB_STEP_SUMMARY
            echo "- **Standard**: Broadcast quality (-14 LUFS)" >> $GITHUB_STEP_SUMMARY
          else
            echo "## âš ï¸ Partial Success: Some components may need review" >> $GITHUB_STEP_SUMMARY
            echo "Please check individual phase results and artifacts." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“ Deliverables" >> $GITHUB_STEP_SUMMARY
          echo "All outputs saved to: \`$PROJECT_DIR\`" >> $GITHUB_STEP_SUMMARY
          echo "- Final video: \`final/news_video_60s.mp4\`" >> $GITHUB_STEP_SUMMARY
          echo "- Project metadata: \`metadata/\` directory" >> $GITHUB_STEP_SUMMARY
          echo "- Execution logs: \`logs/\` directory" >> $GITHUB_STEP_SUMMARY
          echo "- Media assets: \`media/\` directory" >> $GITHUB_STEP_SUMMARY
