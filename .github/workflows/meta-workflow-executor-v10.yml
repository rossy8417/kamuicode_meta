name: "Meta Workflow Executor v10 with Claude SDK"
run-name: "ğŸš€ Meta Workflow v10 | Issue #${{ inputs.issue_number }} | ${{ github.actor }}"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number for workflow generation request'
        required: true
        default: '60'

permissions:
  contents: write
  issues: write
  actions: write
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  # ===========================================
  # PHASE 1: ISSUE ANALYSIS & VALIDATION
  # ===========================================
  
  validate-trigger:
    name: "ğŸ” Issue Analysis & Validation"
    runs-on: ubuntu-latest
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
      issue_body: ${{ steps.extract.outputs.issue_body }}
      issue_title: ${{ steps.extract.outputs.issue_title }}
      request_type: ${{ steps.analyze.outputs.request_type }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Extract Issue Information
        id: extract
        run: |
          echo "ğŸ” Analyzing Issue #${{ inputs.issue_number }}..."
          
          # Get issue details using GitHub CLI
          ISSUE_DATA=$(gh issue view ${{ inputs.issue_number }} --json title,body,number --jq '{title: .title, body: .body, number: .number}')
          
          ISSUE_TITLE=$(echo "$ISSUE_DATA" | jq -r '.title')
          ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body')
          ISSUE_NUMBER=$(echo "$ISSUE_DATA" | jq -r '.number')
          
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          
          {
            echo 'issue_title<<EOF'
            echo "$ISSUE_TITLE"
            echo 'EOF'
          } >> $GITHUB_OUTPUT
          
          {
            echo 'issue_body<<EOF'
            echo "$ISSUE_BODY"
            echo 'EOF'
          } >> $GITHUB_OUTPUT
          
          echo "âœ… Issue #$ISSUE_NUMBER validated: $ISSUE_TITLE"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Analyze Request Type
        id: analyze
        run: |
          echo "ğŸ“Š Analyzing request type from issue content..."
          
          # Save issue body to a file to avoid shell interpretation issues
          echo '${{ steps.extract.outputs.issue_body }}' > /tmp/issue_body.txt
          
          REQUEST_TYPE="unknown"
          
          # Determine request type based on content
          if grep -i "video" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="video-generation"
          elif grep -i "image" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="image-generation"
          elif grep -i "audio\|music" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="audio-generation"
          elif grep -i "data\|analysis" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="data-analysis"
          elif grep -i "blog\|article" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="content-creation"
          fi
          
          echo "request_type=$REQUEST_TYPE" >> $GITHUB_OUTPUT
          echo "ğŸ¯ Request type identified: $REQUEST_TYPE"

  # ===========================================
  # PHASE 2: ULTRA-DETAILED TASK DECOMPOSITION
  # ===========================================
  
  ultra-task-decomposition:
    name: "ğŸ§  Ultra-Detailed Task Decomposition"
    runs-on: ubuntu-latest
    needs: validate-trigger
    outputs:
      decomposed_tasks: ${{ steps.decompose.outputs.decomposed_tasks }}
      task_count: ${{ steps.decompose.outputs.task_count }}
      execution_phases: ${{ steps.decompose.outputs.execution_phases }}
      detected_capabilities: ${{ steps.decompose.outputs.detected_capabilities }}
      orchestrator_used: ${{ steps.decompose.outputs.orchestrator_used }}
      orchestrator_sources: ${{ steps.decompose.outputs.orchestrator_sources }}
      job_sequence: ${{ steps.decompose.outputs.job_sequence }}
      mermaid_diagram: ${{ steps.decompose.outputs.mermaid_diagram }}
      fine_grained_tasks: ${{ steps.decompose.outputs.fine_grained_tasks }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq python3-pip
          pip3 install pyyaml
        
      - name: Perform Ultra-Detailed Task Decomposition
        id: decompose
        run: |
          echo "ğŸ§  Starting ultra-detailed task decomposition..."
          
          # Create project directory
          mkdir -p projects/current-session/{logs,metadata,scripts}
          
          # Save issue body to file
          echo '${{ needs.validate-trigger.outputs.issue_body }}' > /tmp/issue_body_safe.txt
          
          # Issue details
          ISSUE_TITLE="${{ needs.validate-trigger.outputs.issue_title }}"
          ISSUE_NUMBER="${{ needs.validate-trigger.outputs.issue_number }}"
          REQUEST_TYPE="${{ needs.validate-trigger.outputs.request_type }}"
          
          echo "ğŸ“‹ Issue: $ISSUE_TITLE"
          echo "ğŸ”¢ Number: #$ISSUE_NUMBER"
          echo "ğŸ“Š Type: $REQUEST_TYPE"
          
          # Dynamic capability detection from issue content
          echo "ğŸ” Detecting required capabilities..."
          
          CAPABILITIES=""
          
          # Video capabilities
          if grep -qi "å‹•ç”»\|video\|ãƒ“ãƒ‡ã‚ª" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}video-generation,"
            echo "  âœ“ Video generation detected"
          fi
          
          # Image capabilities
          if grep -qi "ç”»åƒ\|image\|å†™çœŸ\|ã‚µãƒ ãƒã‚¤ãƒ«" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}image-generation,"
            echo "  âœ“ Image generation detected"
          fi
          
          # Audio capabilities
          if grep -qi "éŸ³å£°\|audio\|sound\|BGM\|éŸ³æ¥½" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}audio-generation,"
            echo "  âœ“ Audio generation detected"
          fi
          
          # Search capabilities
          if grep -qi "æ¤œç´¢\|search\|èª¿æŸ»\|ãƒˆãƒ¬ãƒ³ãƒ‰" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}web-search,"
            echo "  âœ“ Web search detected"
          fi
          
          # Analysis capabilities
          if grep -qi "åˆ†æ\|analysis\|ãƒ‡ãƒ¼ã‚¿" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}data-analysis,"
            echo "  âœ“ Data analysis detected"
          fi
          
          # News capabilities
          if grep -qi "ãƒ‹ãƒ¥ãƒ¼ã‚¹\|news\|æœ€æ–°" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}news-planning,"
            echo "  âœ“ News planning detected"
          fi
          
          # Speech capabilities
          if grep -qi "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\|speech\|èª­ã¿ä¸Šã’" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}text-to-speech,"
            echo "  âœ“ Text-to-speech detected"
          fi
          
          # Editing capabilities
          if grep -qi "ç·¨é›†\|editing\|çµåˆ" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}video-editing,"
            echo "  âœ“ Video editing detected"
          fi
          
          # Remove trailing comma
          CAPABILITIES=$(echo "$CAPABILITIES" | sed 's/,$//')
          
          # Determine complexity
          WORD_COUNT=$(wc -w < /tmp/issue_body_safe.txt)
          if [ "$WORD_COUNT" -gt 200 ]; then
            COMPLEXITY="complex"
            DURATION="45-60 minutes"
          elif [ "$WORD_COUNT" -gt 100 ]; then
            COMPLEXITY="medium"
            DURATION="20-40 minutes"
          else
            COMPLEXITY="simple"
            DURATION="10-20 minutes"
          fi
          
          echo ""
          echo "ğŸ“Š Analysis Results:"
          echo "  - Capabilities: $CAPABILITIES"
          echo "  - Complexity: $COMPLEXITY"
          echo "  - Duration: $DURATION"
          
          # Copy orchestrator analyzer script
          if [ -f scripts/orchestrator_analyzer.py ]; then
            cp scripts/orchestrator_analyzer.py projects/current-session/scripts/
          fi
          
          # Run orchestrator analysis
          echo "ğŸ” Running orchestrator analysis..."
          export USER_REQUEST="$ISSUE_TITLE $(</tmp/issue_body_safe.txt)"
          export CAPABILITIES="$CAPABILITIES"
          
          if [ -f projects/current-session/scripts/orchestrator_analyzer.py ]; then
            cd projects/current-session/scripts
            python3 orchestrator_analyzer.py || echo "âš ï¸ Orchestrator analysis failed, using default logic"
            cd ../../..
            
            # Check if orchestrator analysis succeeded
            if [ -f projects/current-session/metadata/orchestrator_analysis.json ]; then
              echo "âœ… Orchestrator analysis completed successfully"
              ORCHESTRATOR_ANALYSIS=$(cat projects/current-session/metadata/orchestrator_analysis.json)
              
              # Extract execution pattern and job count
              EXECUTION_PATTERN=$(echo "$ORCHESTRATOR_ANALYSIS" | python3 -c "import json, sys; print(json.load(sys.stdin).get('execution_pattern', 'sequential'))")
              echo "ğŸ“Š Recommended execution pattern: $EXECUTION_PATTERN"
            fi
          else
            echo "âš ï¸ Orchestrator analyzer not found, using keyword-based detection"
          fi
          
          # Try Claude Code SDK for additional analysis (if available)
          if command -v claude &> /dev/null; then
            echo "ğŸ¤– Claude CLI is available for enhanced analysis..."
            
            # Create enhanced prompt with orchestrator analysis
            echo "You are the Meta Workflow Generator task decomposition agent." > /tmp/claude_prompt.txt
            echo "Analyze the following issue and orchestrator recommendations to create an optimal workflow." >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Issue: $ISSUE_TITLE" >> /tmp/claude_prompt.txt
            cat /tmp/issue_body_safe.txt >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Detected capabilities: $CAPABILITIES" >> /tmp/claude_prompt.txt
            if [ -f projects/current-session/metadata/orchestrator_analysis.json ]; then
              echo "Orchestrator analysis:" >> /tmp/claude_prompt.txt
              cat projects/current-session/metadata/orchestrator_analysis.json >> /tmp/claude_prompt.txt
            fi
            echo "" >> /tmp/claude_prompt.txt
            echo "IMPORTANT: For complex tasks like 'news-planning', break them down into subtasks:" >> /tmp/claude_prompt.txt
            echo "- content-planning (å†…å®¹ã®ä¼ç”»)" >> /tmp/claude_prompt.txt
            echo "- narration-creation (ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ)" >> /tmp/claude_prompt.txt
            echo "- scene-planning (ã‚·ãƒ¼ãƒ³ä¼ç”»)" >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Output format:" >> /tmp/claude_prompt.txt
            echo "1. Fine-grained task decomposition in JSON" >> /tmp/claude_prompt.txt
            echo "2. Mermaid diagram showing execution flow" >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Please provide the optimal job execution order considering dependencies." >> /tmp/claude_prompt.txt
            
            # Try Claude
            CLAUDE_RESPONSE=$(claude -p "$(cat /tmp/claude_prompt.txt)" 2>&1 || echo '')
            
            if [ -n "$CLAUDE_RESPONSE" ]; then
              echo "âœ… Claude Code SDK provided enhanced analysis"
              echo "$CLAUDE_RESPONSE" > projects/current-session/metadata/claude_analysis.txt
              
              # Extract fine-grained tasks if available
              if echo "$CLAUDE_RESPONSE" | grep -q "subtasks"; then
                echo "ğŸ” Fine-grained task decomposition detected"
                FINE_GRAINED_TASKS=$(echo "$CLAUDE_RESPONSE" | grep -A 50 '"subtasks"' || echo '')
                echo "fine_grained_tasks<<EOF" >> $GITHUB_OUTPUT
                echo "$FINE_GRAINED_TASKS" >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              fi
              
              # Extract Mermaid diagram if available
              if echo "$CLAUDE_RESPONSE" | grep -q "graph"; then
                echo "ğŸ“Š Mermaid diagram detected"
                MERMAID_DIAGRAM=$(echo "$CLAUDE_RESPONSE" | sed -n '/```mermaid/,/```/p' | sed '1d;$d' || echo '')
                echo "mermaid_diagram<<EOF" >> $GITHUB_OUTPUT
                echo "$MERMAID_DIAGRAM" >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              fi
            fi
          else
            echo "â„¹ï¸ Claude CLI not installed, generating basic Mermaid diagram"
            
            # Generate basic Mermaid diagram based on capabilities
            echo "graph TD" > projects/current-session/metadata/mermaid.txt
            echo "    Start[é–‹å§‹]" >> projects/current-session/metadata/mermaid.txt
            
            # Parse capabilities and create diagram
            IFS=',' read -ra CAP_ARRAY <<< "$CAPABILITIES"
            PREV_NODE="Start"
            NODE_COUNT=1
            
            for cap in "${CAP_ARRAY[@]}"; do
              NODE_NAME="Node$NODE_COUNT"
              
              # Create node label based on capability
              case "$cap" in
                "web-search") LABEL="ğŸ” Webæ¤œç´¢" ;;
                "data-analysis") LABEL="ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æ" ;;
                "news-planning") LABEL="ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¼ç”»\\nâ”œâ”€ å†…å®¹ä¼ç”»\\nâ”œâ”€ ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ\\nâ””â”€ ã‚·ãƒ¼ãƒ³æ§‹æˆ" ;;
                "image-generation") LABEL="ğŸ–¼ï¸ ç”»åƒç”Ÿæˆ" ;;
                "audio-generation") LABEL="ğŸµ éŸ³å£°ç”Ÿæˆ" ;;
                "video-generation") LABEL="ğŸ¬ å‹•ç”»ç”Ÿæˆ" ;;
                "video-editing") LABEL="âœ‚ï¸ å‹•ç”»ç·¨é›†" ;;
                *) LABEL="$cap" ;;
              esac
              
              echo "    $NODE_NAME[$LABEL]" >> projects/current-session/metadata/mermaid.txt
              echo "    $PREV_NODE --> $NODE_NAME" >> projects/current-session/metadata/mermaid.txt
              
              PREV_NODE=$NODE_NAME
              NODE_COUNT=$((NODE_COUNT + 1))
            done
            
            echo "    $PREV_NODE --> End[å®Œäº†]" >> projects/current-session/metadata/mermaid.txt
            
            # Save as output
            MERMAID_CONTENT=$(cat projects/current-session/metadata/mermaid.txt)
            echo "mermaid_diagram<<EOF" >> $GITHUB_OUTPUT
            echo "$MERMAID_CONTENT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi
          
          # Generate workflow metadata
          mkdir -p projects/current-session/metadata
          
          # Export for Python script
          export CAPABILITIES="$CAPABILITIES"
          export COMPLEXITY="$COMPLEXITY"
          export REQUIREMENTS="General workflow request"
          
          # Use optimized workflow generator
          if [ -f scripts/generate_optimized_workflow.py ]; then
            cp scripts/generate_optimized_workflow.py projects/current-session/scripts/
            cd projects/current-session/scripts
            python3 generate_optimized_workflow.py
            cd ../../..
          elif [ -f scripts/generate_dynamic_workflow.py ]; then
            cp scripts/generate_dynamic_workflow.py projects/current-session/scripts/
            cd projects/current-session/scripts
            python3 generate_dynamic_workflow.py
            cd ../../..
          else
            # Fallback: create workflow JSON directly
            echo '{' > projects/current-session/metadata/dynamic_workflow.json
            echo '  "metadata": {' >> projects/current-session/metadata/dynamic_workflow.json
            echo "    \"generated_at\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"," >> projects/current-session/metadata/dynamic_workflow.json
            echo "    \"complexity\": \"$COMPLEXITY\"," >> projects/current-session/metadata/dynamic_workflow.json
            echo "    \"total_units\": $(echo \"$CAPABILITIES\" | tr ',' '\n' | wc -l)," >> projects/current-session/metadata/dynamic_workflow.json
            CAPS_JSON=$(echo "$CAPABILITIES" | sed 's/,/","/g' | sed 's/^/"/' | sed 's/$/"/' || echo '')
            echo "    \"capabilities_detected\": [$CAPS_JSON]" >> projects/current-session/metadata/dynamic_workflow.json
            echo '  },' >> projects/current-session/metadata/dynamic_workflow.json
            echo '  "minimal_units": [' >> projects/current-session/metadata/dynamic_workflow.json
            
            # Add units based on capabilities
            FIRST=true
            for cap in $(echo "$CAPABILITIES" | tr ',' ' '); do
              [ "$FIRST" = true ] && FIRST=false || echo "," >> projects/current-session/metadata/dynamic_workflow.json
              
              case $cap in
                "web-search")
                  UNIT_PATH="minimal-units/planning/web-search.yml"
                  ;;
                "news-planning")
                  UNIT_PATH="minimal-units/planning/news-planning.yml"
                  ;;
                "image-generation")
                  UNIT_PATH="minimal-units/media/image/t2i-imagen3.yml"
                  ;;
                "video-generation")
                  UNIT_PATH="minimal-units/media/video/t2v-veo3.yml"
                  ;;
                "audio-generation")
                  UNIT_PATH="minimal-units/media/audio/bgm-generate-mcp.yml"
                  ;;
                "text-to-speech")
                  UNIT_PATH="minimal-units/media/audio/t2s-minimax-turbo-mcp.yml"
                  ;;
                "video-editing")
                  UNIT_PATH="minimal-units/postprod/video-concat.yml"
                  ;;
                "data-analysis")
                  UNIT_PATH="minimal-units/planning/data-analysis.yml"
                  ;;
                *)
                  UNIT_PATH="minimal-units/planning/web-search.yml"
                  ;;
              esac
              
              echo '    {' >> projects/current-session/metadata/dynamic_workflow.json
              echo "      \"capability\": \"$cap\"," >> projects/current-session/metadata/dynamic_workflow.json
              echo "      \"unit_path\": \"$UNIT_PATH\"," >> projects/current-session/metadata/dynamic_workflow.json
              echo '      "estimated_time": "3-5 minutes"' >> projects/current-session/metadata/dynamic_workflow.json
              echo -n '    }' >> projects/current-session/metadata/dynamic_workflow.json
            done
            
            echo '' >> projects/current-session/metadata/dynamic_workflow.json
            echo '  ],' >> projects/current-session/metadata/dynamic_workflow.json
            EXEC_PATTERN=$( [ "$COMPLEXITY" = "simple" ] && echo "sequential" || echo "mixed_parallel" )
            echo "  \"execution_pattern\": \"$EXEC_PATTERN\"" >> projects/current-session/metadata/dynamic_workflow.json
            echo '}' >> projects/current-session/metadata/dynamic_workflow.json
          fi
          
          # Generate fine-grained task decomposition for complex tasks
          echo '{}' > projects/current-session/metadata/fine_grained_tasks.json
          
          # Check for complex tasks that need decomposition
          if echo "$CAPABILITIES" | grep -q "news-planning"; then
            echo "ğŸ” Decomposing news-planning into subtasks..."
            
            # Create fine-grained decomposition
            echo '{' > projects/current-session/metadata/fine_grained_tasks.json
            echo '  "news-planning": {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '    "subtasks": [' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "name": "content-planning",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "description": "ãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã®ä¼ç”»",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "unit": "minimal-units/planning/content-planning.yml",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "duration": "5-10 minutes"' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      },' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "name": "narration-creation",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "description": "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ä½œæˆ",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "unit": "minimal-units/planning/narration-creation.yml",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "duration": "10-15 minutes"' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      },' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "name": "scene-planning",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "description": "ã‚·ãƒ¼ãƒ³æ§‹æˆã®ä¼ç”»",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "unit": "minimal-units/planning/scene-planning.yml",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "duration": "5-10 minutes"' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      }' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '    ]' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '  }' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '}' >> projects/current-session/metadata/fine_grained_tasks.json
          fi
          
          # Validate and output results
          if [ -f projects/current-session/metadata/dynamic_workflow.json ]; then
            UNIT_COUNT=$(jq '.minimal_units | length' projects/current-session/metadata/dynamic_workflow.json)
            EXECUTION_PATTERN=$(jq -r '.execution_pattern' projects/current-session/metadata/dynamic_workflow.json)
            
            echo "decomposed_tasks=$(cat projects/current-session/metadata/dynamic_workflow.json | jq -c .)" >> $GITHUB_OUTPUT
            echo "task_count=$UNIT_COUNT" >> $GITHUB_OUTPUT
            echo "execution_phases=$EXECUTION_PATTERN" >> $GITHUB_OUTPUT
            
            # Extract additional information for summary
            DETECTED_CAPS=$(jq -r '.metadata.capabilities_detected | join(", ")' projects/current-session/metadata/dynamic_workflow.json)
            echo "detected_capabilities=$DETECTED_CAPS" >> $GITHUB_OUTPUT
            
            # Check if orchestrator was used
            if [ -f projects/current-session/metadata/orchestrator_analysis.json ]; then
              ORCH_USED=$(jq -r '.analysis.orchestrators | length > 0' projects/current-session/metadata/orchestrator_analysis.json)
              ORCH_SOURCES=$(jq -r '.analysis.orchestrators[].name' projects/current-session/metadata/orchestrator_analysis.json | head -3 | tr '\n' ',' | sed 's/,$//')
              echo "orchestrator_used=$ORCH_USED" >> $GITHUB_OUTPUT
              echo "orchestrator_sources=$ORCH_SOURCES" >> $GITHUB_OUTPUT
            else
              echo "orchestrator_used=false" >> $GITHUB_OUTPUT
              echo "orchestrator_sources=none" >> $GITHUB_OUTPUT
            fi
            
            # Export fine-grained tasks if available
            if [ -f projects/current-session/metadata/fine_grained_tasks.json ] && [ -s projects/current-session/metadata/fine_grained_tasks.json ]; then
              FINE_GRAINED=$(cat projects/current-session/metadata/fine_grained_tasks.json)
              if [ "$FINE_GRAINED" != "{}" ]; then
                echo "fine_grained_tasks<<EOF" >> $GITHUB_OUTPUT
                echo "$FINE_GRAINED" >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              fi
            fi
            
            # Extract job sequence
            JOB_SEQUENCE=$(jq -r '.minimal_units[].capability' projects/current-session/metadata/dynamic_workflow.json | tr '\n' ' â†’ ' | sed 's/ â†’ $//')
            echo "job_sequence=$JOB_SEQUENCE" >> $GITHUB_OUTPUT
            
            echo ""
            echo "âœ… Dynamic workflow generated with $UNIT_COUNT minimal units"
            echo "ğŸ“‹ Execution pattern: $EXECUTION_PATTERN"
          else
            echo "âŒ Dynamic workflow generation failed"
            exit 1
          fi

  # ===========================================
  # PHASE 3: DYNAMIC WORKFLOW GENERATION  
  # ===========================================
  
  dynamic-workflow-generation:
    name: "ğŸš€ Dynamic Workflow Generation"
    runs-on: ubuntu-latest
    needs: [validate-trigger, ultra-task-decomposition]
    outputs:
      generated_workflow: ${{ steps.generation.outputs.generated_workflow }}
      workflow_path: ${{ steps.generation.outputs.workflow_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Generate Dynamic Workflow
        id: generation
        run: |
          echo "ğŸš€ Generating complete executable workflow..."
          
          # Create necessary directories
          mkdir -p projects/current-session/{metadata,generated-workflows}
          
          # Restore workflow metadata from job outputs
          echo '${{ needs.ultra-task-decomposition.outputs.decomposed_tasks }}' > projects/current-session/metadata/dynamic_workflow.json
          
          # Read workflow metadata
          WORKFLOW_DATA=$(cat projects/current-session/metadata/dynamic_workflow.json)
          EXECUTION_PATTERN=$(echo "$WORKFLOW_DATA" | jq -r '.execution_pattern')
          UNIT_COUNT=$(echo "$WORKFLOW_DATA" | jq '.minimal_units | length')
          
          echo "ğŸ“Š Generating workflow with $UNIT_COUNT units"
          echo "ğŸ”„ Execution pattern: $EXECUTION_PATTERN"
          
          # Generate GitHub Actions workflow YAML
          WORKFLOW_FILE="projects/current-session/generated-workflows/dynamic-workflow-${{ inputs.issue_number }}.yml"
          
          # Create workflow header
          echo 'name: "ğŸ¯ Dynamic Workflow - Issue #${{ github.event.inputs.issue_number }}"' > "$WORKFLOW_FILE"
          echo 'run-name: "ğŸ“Š Dynamic | ${{ github.actor }} | Issue #${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'on:' >> "$WORKFLOW_FILE"
          echo '  workflow_dispatch:' >> "$WORKFLOW_FILE"
          echo '    inputs:' >> "$WORKFLOW_FILE"
          echo '      issue_number:' >> "$WORKFLOW_FILE"
          echo '        description: "Source issue number"' >> "$WORKFLOW_FILE"
          echo '        required: true' >> "$WORKFLOW_FILE"
          echo '        default: "${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'permissions:' >> "$WORKFLOW_FILE"
          echo '  contents: write' >> "$WORKFLOW_FILE"
          echo '  actions: write' >> "$WORKFLOW_FILE"
          echo '  issues: write' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'env:' >> "$WORKFLOW_FILE"
          echo '  CLAUDE_CODE_CI_MODE: true' >> "$WORKFLOW_FILE"
          echo '  CLAUDE_CODE_AUTO_APPROVE_MCP: true' >> "$WORKFLOW_FILE"
          echo '  PROJECT_BASE: "projects/issue-${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'jobs:' >> "$WORKFLOW_FILE"
          
          # Add initialization job
          echo '  initialize:' >> "$WORKFLOW_FILE"
          echo '    name: "ğŸš€ Initialize Workflow"' >> "$WORKFLOW_FILE"
          echo '    runs-on: ubuntu-latest' >> "$WORKFLOW_FILE"
          echo '    outputs:' >> "$WORKFLOW_FILE"
          echo '      project_dir: ${{ steps.setup.outputs.project_dir }}' >> "$WORKFLOW_FILE"
          echo '    steps:' >> "$WORKFLOW_FILE"
          echo '      - name: Checkout Repository' >> "$WORKFLOW_FILE"
          echo '        uses: actions/checkout@v4' >> "$WORKFLOW_FILE"
          echo '        ' >> "$WORKFLOW_FILE"
          echo '      - name: Setup Project Directory' >> "$WORKFLOW_FILE"
          echo '        id: setup' >> "$WORKFLOW_FILE"
          echo '        run: |' >> "$WORKFLOW_FILE"
          echo '          PROJECT_DIR="${{ env.PROJECT_BASE }}"' >> "$WORKFLOW_FILE"
          echo '          mkdir -p "$PROJECT_DIR"/{logs,metadata,temp,final}' >> "$WORKFLOW_FILE"
          echo '          echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT' >> "$WORKFLOW_FILE"
          echo '          echo "âœ… Project directory initialized: $PROJECT_DIR"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          
          # Add jobs based on execution phases
          JOB_NUMBER=1
          PREVIOUS_JOB="initialize"
          PHASE_JOBS=""
          
          # Check if we have execution phases
          HAS_PHASES=$(echo "$WORKFLOW_DATA" | jq -r '.metadata.execution_phases // null')
          
          if [ "$HAS_PHASES" != "null" ]; then
            # Process by phases for optimized execution
            echo "$WORKFLOW_DATA" | jq -c '.metadata.execution_phases[]' | while read -r phase; do
              PHASE_NAME=$(echo "$phase" | jq -r '.name')
              IS_PARALLEL=$(echo "$phase" | jq -r '.parallel')
              
              echo "# Phase: $PHASE_NAME (parallel: $IS_PARALLEL)" >> "$WORKFLOW_FILE"
              
              PHASE_FIRST_JOB=""
              PHASE_JOB_NAMES=""
              
              echo "$phase" | jq -c '.jobs[]' | while read -r job; do
                CAPABILITY=$(echo "$job" | jq -r '.capability')
                UNIT_PATH=$(echo "$job" | jq -r '.unit_path')
                
                # Generate safe job name
                JOB_NAME="job_${JOB_NUMBER}_$(echo "$CAPABILITY" | tr '-' '_')"
                
                if [ -z "$PHASE_FIRST_JOB" ]; then
                  PHASE_FIRST_JOB="$JOB_NAME"
                fi
                PHASE_JOB_NAMES="${PHASE_JOB_NAMES}${JOB_NAME},"
                
                echo "  $JOB_NAME:" >> "$WORKFLOW_FILE"
                echo "    name: \"ğŸ“¦ Execute: $CAPABILITY\"" >> "$WORKFLOW_FILE"
                echo "    runs-on: ubuntu-latest" >> "$WORKFLOW_FILE"
                
                # Set dependencies based on parallel execution
                if [ "$IS_PARALLEL" = "true" ]; then
                  echo "    needs: $PREVIOUS_JOB" >> "$WORKFLOW_FILE"
                else
                  if [ "$JOB_NAME" = "$PHASE_FIRST_JOB" ]; then
                    echo "    needs: $PREVIOUS_JOB" >> "$WORKFLOW_FILE"
                  else
                    PREV_JOB_NAME="job_$((JOB_NUMBER - 1))_$(echo "$CAPABILITY" | tr '-' '_')"
                    echo "    needs: $PREV_JOB_NAME" >> "$WORKFLOW_FILE"
                  fi
                fi
                
                echo "    steps:" >> "$WORKFLOW_FILE"
                echo "      - name: Checkout Repository" >> "$WORKFLOW_FILE"
                echo "        uses: actions/checkout@v4" >> "$WORKFLOW_FILE"
                echo "        " >> "$WORKFLOW_FILE"
                echo "      - name: Execute $CAPABILITY" >> "$WORKFLOW_FILE"
                echo "        run: |" >> "$WORKFLOW_FILE"
                echo "          echo \"ğŸ”§ Executing minimal unit: $CAPABILITY\"" >> "$WORKFLOW_FILE"
                echo "          echo \"ğŸ“‚ Unit path: $UNIT_PATH\"" >> "$WORKFLOW_FILE"
                echo "          " >> "$WORKFLOW_FILE"
                echo "          # Here you would include the actual minimal unit" >> "$WORKFLOW_FILE"
                echo "          # For now, we'll simulate execution" >> "$WORKFLOW_FILE"
                echo "          echo \"âœ… $CAPABILITY completed successfully\"" >> "$WORKFLOW_FILE"
                echo "          " >> "$WORKFLOW_FILE"
                echo "          # Save output" >> "$WORKFLOW_FILE"
                echo "          mkdir -p \\\${{ env.PROJECT_BASE }}/outputs" >> "$WORKFLOW_FILE"
                echo "          echo \"Output from $CAPABILITY\" > \\\${{ env.PROJECT_BASE }}/outputs/${JOB_NUMBER}_$CAPABILITY.txt" >> "$WORKFLOW_FILE"
                echo "" >> "$WORKFLOW_FILE"
                
                JOB_NUMBER=$((JOB_NUMBER + 1))
              done
              
              # Update previous job for next phase
              if [ "$IS_PARALLEL" = "true" ]; then
                # All jobs in parallel phase become dependencies for next phase
                PREVIOUS_JOB="[${PHASE_JOB_NAMES%,}]"
              else
                # Last job in sequential phase
                PREVIOUS_JOB="job_$((JOB_NUMBER - 1))_*"
              fi
            done
          else
            # Fallback to simple sequential execution
            echo "$WORKFLOW_DATA" | jq -c '.minimal_units[]' | while read -r unit; do
              CAPABILITY=$(echo "$unit" | jq -r '.capability')
              UNIT_PATH=$(echo "$unit" | jq -r '.unit_path')
              
              # Generate safe job name
              JOB_NAME="job_${JOB_NUMBER}_$(echo "$CAPABILITY" | tr '-' '_')"
              
              echo "  $JOB_NAME:" >> "$WORKFLOW_FILE"
              echo "    name: \"ğŸ“¦ Execute: $CAPABILITY\"" >> "$WORKFLOW_FILE"
              echo "    runs-on: ubuntu-latest" >> "$WORKFLOW_FILE"
              echo "    needs: $PREVIOUS_JOB" >> "$WORKFLOW_FILE"
              echo "    steps:" >> "$WORKFLOW_FILE"
              echo "      - name: Checkout Repository" >> "$WORKFLOW_FILE"
              echo "        uses: actions/checkout@v4" >> "$WORKFLOW_FILE"
              echo "        " >> "$WORKFLOW_FILE"
              echo "      - name: Execute $CAPABILITY" >> "$WORKFLOW_FILE"
              echo "        run: |" >> "$WORKFLOW_FILE"
              echo "          echo \"ğŸ”§ Executing minimal unit: $CAPABILITY\"" >> "$WORKFLOW_FILE"
              echo "          echo \"ğŸ“‚ Unit path: $UNIT_PATH\"" >> "$WORKFLOW_FILE"
              echo "          " >> "$WORKFLOW_FILE"
              echo "          # Here you would include the actual minimal unit" >> "$WORKFLOW_FILE"
              echo "          # For now, we'll simulate execution" >> "$WORKFLOW_FILE"
              echo "          echo \"âœ… $CAPABILITY completed successfully\"" >> "$WORKFLOW_FILE"
              echo "          " >> "$WORKFLOW_FILE"
              echo "          # Save output" >> "$WORKFLOW_FILE"
              echo "          mkdir -p \\\${{ env.PROJECT_BASE }}/outputs" >> "$WORKFLOW_FILE"
              echo "          echo \"Output from $CAPABILITY\" > \\\${{ env.PROJECT_BASE }}/outputs/${JOB_NUMBER}_$CAPABILITY.txt" >> "$WORKFLOW_FILE"
              echo "" >> "$WORKFLOW_FILE"
              
              PREVIOUS_JOB="$JOB_NAME"
              JOB_NUMBER=$((JOB_NUMBER + 1))
            done
          fi
          
          # Add finalization job
          echo '  finalize:' >> "$WORKFLOW_FILE"
          echo '    name: "ğŸ‰ Finalize Workflow"' >> "$WORKFLOW_FILE"
          echo '    runs-on: ubuntu-latest' >> "$WORKFLOW_FILE"
          echo '    needs: [initialize]' >> "$WORKFLOW_FILE"
          echo '    if: always()' >> "$WORKFLOW_FILE"
          echo '    steps:' >> "$WORKFLOW_FILE"
          echo '      - name: Checkout Repository' >> "$WORKFLOW_FILE"
          echo '        uses: actions/checkout@v4' >> "$WORKFLOW_FILE"
          echo '        ' >> "$WORKFLOW_FILE"
          echo '      - name: Generate Summary' >> "$WORKFLOW_FILE"
          echo '        run: |' >> "$WORKFLOW_FILE"
          echo '          echo "## ğŸ“Š Workflow Execution Summary" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Issue**: #${{ github.event.inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Project**: ${{ env.PROJECT_BASE }}" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Status**: Completed" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "âœ… Dynamic workflow execution completed!" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          
          # Output workflow information
          WORKFLOW_PATH="$WORKFLOW_FILE"
          echo "workflow_path=$WORKFLOW_PATH" >> $GITHUB_OUTPUT
          
          # Encode workflow for output
          if [ -f "$WORKFLOW_PATH" ]; then
            ENCODED_WORKFLOW=$(base64 -w 0 "$WORKFLOW_PATH" 2>/dev/null || base64 "$WORKFLOW_PATH")
            echo "generated_workflow=$ENCODED_WORKFLOW" >> $GITHUB_OUTPUT
            echo "âœ… Dynamic workflow YAML generated successfully"
            echo "ğŸ“ Path: $WORKFLOW_PATH"
          else
            echo "âŒ Failed to generate workflow file"
            exit 1
          fi

  # ===========================================
  # PHASE 4: WORKFLOW DEPLOYMENT
  # ===========================================
  
  deploy-workflow:
    name: "ğŸš€ Deploy Generated Workflow"
    runs-on: ubuntu-latest
    needs: [validate-trigger, ultra-task-decomposition, dynamic-workflow-generation]
    outputs:
      deployment_status: ${{ steps.deploy.outputs.deployment_status }}
      deployed_path: ${{ steps.deploy.outputs.deployed_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Deploy Generated Workflow
        id: deploy
        run: |
          echo "ğŸš€ Deploying generated workflow..."
          
          # Create deployment directory
          mkdir -p .github/workflows/generated
          
          # Decode and save workflow
          WORKFLOW_PATH="${{ needs.dynamic-workflow-generation.outputs.workflow_path }}"
          DEPLOYMENT_NAME="issue-${{ inputs.issue_number }}-$(date +%Y%m%d-%H%M%S).yml.disabled"
          DEPLOYMENT_PATH=".github/workflows/generated/$DEPLOYMENT_NAME"
          
          # Restore generated workflow
          echo "${{ needs.dynamic-workflow-generation.outputs.generated_workflow }}" | base64 -d > "$DEPLOYMENT_PATH"
          
          if [ -f "$DEPLOYMENT_PATH" ]; then
            echo "âœ… Workflow deployed successfully"
            echo "ğŸ“ Deployed to: $DEPLOYMENT_PATH"
            echo "âš ï¸  Note: Workflow is deployed with .disabled extension for safety"
            
            # Display generated workflow content
            echo ""
            echo "ğŸ“„ Generated Workflow Content:"
            echo "================================"
            head -50 "$DEPLOYMENT_PATH"
            echo "================================"
            echo "(Showing first 50 lines)"
            echo ""
            echo "To activate the workflow:"
            echo "  1. Review the generated workflow"
            echo "  2. Remove the .disabled extension"
            echo "  3. Commit and push the changes"
            
            # Commit the generated workflow
            git config --global user.name "github-actions[bot]"
            git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git add "$DEPLOYMENT_PATH"
            git commit -m "ğŸ¤– Generated workflow for Issue #${{ inputs.issue_number }} - Meta Workflow v10 with dynamic capability detection" || echo "No changes to commit"
            
            git push origin main || echo "Push failed - may need permissions"
            
            echo "deployment_status=success" >> $GITHUB_OUTPUT
            echo "deployed_path=$DEPLOYMENT_PATH" >> $GITHUB_OUTPUT
            
            # Create deployment summary
            echo "## ğŸš€ Workflow Deployment Summary" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- **Status**: âœ… Success" >> $GITHUB_STEP_SUMMARY
            echo "- **Issue**: #${{ inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Deployed Path**: \`$DEPLOYMENT_PATH\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Activation**: Remove \`.disabled\` extension to activate" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Generated Workflow Details:" >> $GITHUB_STEP_SUMMARY
            echo "- **Units**: ${{ needs.ultra-task-decomposition.outputs.task_count }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Pattern**: ${{ needs.ultra-task-decomposition.outputs.execution_phases }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Deployment failed"
            echo "deployment_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

  # ===========================================
  # PHASE 5: EXECUTION SUMMARY
  # ===========================================
  
  execution-summary:
    name: "ğŸ“Š Execution Summary"
    runs-on: ubuntu-latest  
    needs: [validate-trigger, ultra-task-decomposition, dynamic-workflow-generation, deploy-workflow]
    if: always()
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Generate Execution Summary
        run: |
          echo "# ğŸ“Š Meta Workflow v10 å®Ÿè¡Œçµæœãƒ¬ãƒãƒ¼ãƒˆ" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ğŸ“‹ ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±" >> $GITHUB_STEP_SUMMARY
          echo "- **Issueç•ªå·**: #${{ inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- **ã‚¿ã‚¤ãƒˆãƒ«**: ${{ needs.validate-trigger.outputs.issue_title }}" >> $GITHUB_STEP_SUMMARY
          echo "- **æ¤œå‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒ—**: ${{ needs.validate-trigger.outputs.request_type }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ğŸ” ã‚¿ã‚¹ã‚¯åˆ†è§£çµæœ" >> $GITHUB_STEP_SUMMARY
          echo "### æ¤œå‡ºã•ã‚ŒãŸèƒ½åŠ›" >> $GITHUB_STEP_SUMMARY
          echo "${{ needs.ultra-task-decomposition.outputs.detected_capabilities }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### ğŸ“š å‚è€ƒã«ã—ãŸã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼" >> $GITHUB_STEP_SUMMARY
          if [ "${{ needs.ultra-task-decomposition.outputs.orchestrator_used }}" = "true" ]; then
            echo "ä»¥ä¸‹ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚è€ƒã«æœ€é©åŒ–ã—ã¾ã—ãŸï¼š" >> $GITHUB_STEP_SUMMARY
            echo "- ${{ needs.ultra-task-decomposition.outputs.orchestrator_sources }}" | sed 's/,/\n- /g' >> $GITHUB_STEP_SUMMARY
          else
            echo "æ—¢å­˜ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãƒãƒƒãƒã—ãªã‹ã£ãŸãŸã‚ã€å°‚é–€å®¶è¦–ç‚¹ã®ãƒ­ã‚¸ãƒƒã‚¯ã§æ§‹ç¯‰ã—ã¾ã—ãŸã€‚" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### ğŸ”„ ã‚¸ãƒ§ãƒ–å®Ÿè¡Œé †åº" >> $GITHUB_STEP_SUMMARY
          
          # Mermaidå›³ãŒã‚ã‚Œã°è¡¨ç¤º
          if [ -n "${{ needs.ultra-task-decomposition.outputs.mermaid_diagram }}" ]; then
            echo "#### ğŸ“Š å®Ÿè¡Œãƒ•ãƒ­ãƒ¼å›³" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`mermaid" >> $GITHUB_STEP_SUMMARY
            echo "${{ needs.ultra-task-decomposition.outputs.mermaid_diagram }}" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "#### ğŸ“ å®Ÿè¡Œé †åºè©³ç´°" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "${{ needs.ultra-task-decomposition.outputs.job_sequence }}" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ç´°ç²’åº¦ã‚¿ã‚¹ã‚¯åˆ†è§£ãŒã‚ã‚Œã°è¡¨ç¤º
          if [ -n "${{ needs.ultra-task-decomposition.outputs.fine_grained_tasks }}" ]; then
            echo "### ğŸ¯ ç´°ç²’åº¦ã‚¿ã‚¹ã‚¯åˆ†è§£" >> $GITHUB_STEP_SUMMARY
            echo "è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¯ä»¥ä¸‹ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã•ã‚Œã¾ã—ãŸï¼š" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            echo "${{ needs.ultra-task-decomposition.outputs.fine_grained_tasks }}" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "## ğŸ“Š å®Ÿè¡Œçµ±è¨ˆ" >> $GITHUB_STEP_SUMMARY
          echo "- **ç·ãƒ¦ãƒ‹ãƒƒãƒˆæ•°**: ${{ needs.ultra-task-decomposition.outputs.task_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³**: ${{ needs.ultra-task-decomposition.outputs.execution_phases }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ğŸ”„ å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º" >> $GITHUB_STEP_SUMMARY
          echo "| ãƒ•ã‚§ãƒ¼ã‚º | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-----------|" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ” Issueæ¤œè¨¼ | ${{ needs.validate-trigger.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ§  ã‚¿ã‚¹ã‚¯åˆ†è§£ | ${{ needs.ultra-task-decomposition.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸš€ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆ | ${{ needs.dynamic-workflow-generation.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ“¦ ãƒ‡ãƒ—ãƒ­ã‚¤ | ${{ needs.deploy-workflow.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.deploy-workflow.outputs.deployment_status }}" = "success" ]; then
            echo "## âœ… å®Ÿè¡Œçµæœ: æˆåŠŸ" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "å‹•çš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒæ­£å¸¸ã«ç”Ÿæˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¾ã—ãŸï¼š" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼" >> $GITHUB_STEP_SUMMARY
            echo "- **ä¿å­˜å ´æ‰€**: \`${{ needs.deploy-workflow.outputs.deployed_path }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: .disabledæ‹¡å¼µå­ä»˜ãï¼ˆå®‰å…¨ã®ãŸã‚ï¼‰" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ğŸš€ ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•" >> $GITHUB_STEP_SUMMARY
            echo "1. ç”Ÿæˆã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼" >> $GITHUB_STEP_SUMMARY
            echo "2. \`.disabled\`æ‹¡å¼µå­ã‚’å‰Šé™¤" >> $GITHUB_STEP_SUMMARY
            echo "3. ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦æœ‰åŠ¹åŒ–" >> $GITHUB_STEP_SUMMARY
          else
            echo "## âš ï¸ å®Ÿè¡Œçµæœ: å•é¡Œæ¤œå‡º" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Meta Workflow v10 with Claude SDK & Orchestrator Integration ã«ã‚ˆã‚Šç”Ÿæˆ*" >> $GITHUB_STEP_SUMMARY
          echo "*å®Ÿè¡Œæ™‚åˆ»: $(date -u '+%Y-%m-%d %H:%M:%S UTC')*" >> $GITHUB_STEP_SUMMARY