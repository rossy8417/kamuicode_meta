name: "Meta Workflow Executor v10 with Optimized Design"
run-name: "üöÄ Meta Workflow v10 | Issue #${{ inputs.issue_number }} | ${{ github.actor }}"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number for workflow generation request'
        required: true
        default: '60'

permissions:
  contents: write
  issues: write
  actions: write
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  # ===========================================
  # PHASE 1: ISSUE VALIDATION
  # ===========================================
  
  validate-trigger:
    name: "üîç Issue Validation"
    runs-on: ubuntu-latest
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
      issue_title: ${{ steps.extract.outputs.issue_title }}
      request_type: ${{ steps.analyze.outputs.request_type }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Extract Issue Information
        id: extract
        run: |
          echo "üîç Analyzing Issue #${{ inputs.issue_number }}..."
          
          # Get issue details using GitHub CLI
          ISSUE_DATA=$(gh issue view ${{ inputs.issue_number }} --json title,body,number --jq '{title: .title, body: .body, number: .number}')
          
          ISSUE_TITLE=$(echo "$ISSUE_DATA" | jq -r '.title')
          ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body')
          ISSUE_NUMBER=$(echo "$ISSUE_DATA" | jq -r '.number')
          
          # Save to artifacts for next jobs
          mkdir -p artifacts
          echo "$ISSUE_TITLE" > artifacts/issue_title.txt
          echo "$ISSUE_BODY" > artifacts/issue_body.txt
          echo "$ISSUE_NUMBER" > artifacts/issue_number.txt
          
          # Output minimal data
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          echo "issue_title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Issue #$ISSUE_NUMBER validated: $ISSUE_TITLE"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Analyze Request Type
        id: analyze
        run: |
          ISSUE_BODY=$(cat artifacts/issue_body.txt)
          
          REQUEST_TYPE="unknown"
          if echo "$ISSUE_BODY" | grep -qi "video\|ÂãïÁîª"; then
            REQUEST_TYPE="video-generation"
          elif echo "$ISSUE_BODY" | grep -qi "image\|ÁîªÂÉè"; then
            REQUEST_TYPE="image-generation"
          elif echo "$ISSUE_BODY" | grep -qi "audio\|Èü≥Â£∞\|music"; then
            REQUEST_TYPE="audio-generation"
          fi
          
          echo "request_type=$REQUEST_TYPE" >> $GITHUB_OUTPUT
          
      - name: Upload Issue Data
        uses: actions/upload-artifact@v4
        with:
          name: issue-data
          path: artifacts/

  # ===========================================
  # PHASE 2: BASIC TASK DECOMPOSITION
  # ===========================================
  
  basic-task-decomposition:
    name: "üìã Basic Task Decomposition"
    runs-on: ubuntu-latest
    needs: ['validate-trigger']
    outputs:
      capabilities_count: ${{ steps.detect.outputs.capabilities_count }}
      has_video: ${{ steps.detect.outputs.has_video }}
      has_narration: ${{ steps.detect.outputs.has_narration }}
      complexity: ${{ steps.detect.outputs.complexity }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Issue Data
        uses: actions/download-artifact@v4
        with:
          name: issue-data
          path: artifacts/
          
      - name: Detect Capabilities
        id: detect
        run: |
          echo "üîç Detecting required capabilities..."
          
          ISSUE_BODY=$(cat artifacts/issue_body.txt)
          CAPABILITIES=""
          
          # Video capabilities
          if echo "$ISSUE_BODY" | grep -qi "ÂãïÁîª\|video\|„Éì„Éá„Ç™"; then
            CAPABILITIES="${CAPABILITIES}video-generation,"
            echo "has_video=true" >> $GITHUB_OUTPUT
            
            # Context-based additions
            if echo "$ISSUE_BODY" | grep -qi "„Éä„É¨„Éº„Ç∑„Éß„É≥\|narration\|Èü≥Â£∞‰ªò"; then
              CAPABILITIES="${CAPABILITIES}lipsync,subtitle-overlay,"
              echo "has_narration=true" >> $GITHUB_OUTPUT
            fi
            
            if echo "$ISSUE_BODY" | grep -qi "„Ç∑„Éº„É≥\|Ë§áÊï∞\|„Çπ„Éà„Éº„É™„Éº"; then
              CAPABILITIES="${CAPABILITIES}scene-composition,image-generation,"
            fi
          fi
          
          # Web search
          if echo "$ISSUE_BODY" | grep -qi "Ê§úÁ¥¢\|Ë™øÊüª\|„Éã„É•„Éº„Çπ\|ÊúÄÊñ∞"; then
            CAPABILITIES="${CAPABILITIES}web-search,"
          fi
          
          # Planning
          if echo "$ISSUE_BODY" | grep -qi "‰ºÅÁîª\|Ë®àÁîª\|ÊßãÊàê"; then
            CAPABILITIES="${CAPABILITIES}planning,"
          fi
          
          # Save capabilities
          mkdir -p metadata
          echo "$CAPABILITIES" > metadata/capabilities.txt
          
          # Count and complexity
          CAP_COUNT=$(echo "$CAPABILITIES" | tr ',' '\n' | grep -v '^$' | wc -l)
          echo "capabilities_count=$CAP_COUNT" >> $GITHUB_OUTPUT
          
          if [ "$CAP_COUNT" -gt 6 ]; then
            echo "complexity=complex" >> $GITHUB_OUTPUT
          elif [ "$CAP_COUNT" -gt 3 ]; then
            echo "complexity=medium" >> $GITHUB_OUTPUT
          else
            echo "complexity=simple" >> $GITHUB_OUTPUT
          fi
          
          echo "‚úÖ Detected $CAP_COUNT capabilities"
          
      - name: Upload Capabilities
        uses: actions/upload-artifact@v4
        with:
          name: capabilities-data
          path: metadata/

  # ===========================================
  # PHASE 3: DETAILED ANALYSIS
  # ===========================================
  
  detailed-analysis:
    name: "üß† Detailed Analysis"
    runs-on: ubuntu-latest
    needs: ['validate-trigger', 'basic-task-decomposition']
    outputs:
      orchestrator_match: ${{ steps.orchestrator.outputs.match_found }}
      execution_pattern: ${{ steps.orchestrator.outputs.pattern }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml
          
      - name: Download Previous Data
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Orchestrator Analysis
        id: orchestrator
        run: |
          echo "üîç Running orchestrator analysis..."
          
          # Copy analyzer script
          if [ -f scripts/orchestrator_analyzer.py ]; then
            cp scripts/orchestrator_analyzer.py .
            
            # Run analysis
            export USER_REQUEST=$(cat artifacts/issue-data/issue_title.txt)
            export CAPABILITIES=$(cat artifacts/capabilities-data/capabilities.txt)
            
            python orchestrator_analyzer.py || echo "‚ö†Ô∏è Orchestrator analysis failed"
            
            if [ -f projects/current-session/metadata/orchestrator_analysis.json ]; then
              echo "match_found=true" >> $GITHUB_OUTPUT
              # Extract pattern
              PATTERN=$(jq -r '.execution_pattern // "sequential"' projects/current-session/metadata/orchestrator_analysis.json)
              echo "pattern=$PATTERN" >> $GITHUB_OUTPUT
            else
              echo "match_found=false" >> $GITHUB_OUTPUT
              echo "pattern=sequential" >> $GITHUB_OUTPUT
            fi
          fi
          
      - name: Generate Mermaid Diagram
        run: |
          echo "üìä Generating execution flow diagram..."
          
          # Create metadata directory
          mkdir -p metadata
          
          CAPABILITIES=$(cat artifacts/capabilities-data/capabilities.txt)
          
          # Generate basic Mermaid diagram
          echo "graph TD" > metadata/mermaid.txt
          echo "    Start[ÈñãÂßã]" >> metadata/mermaid.txt
          
          IFS=',' read -ra CAP_ARRAY <<< "$CAPABILITIES"
          PREV_NODE="Start"
          NODE_COUNT=1
          
          for cap in "${CAP_ARRAY[@]}"; do
            if [ -n "$cap" ]; then
              NODE_NAME="Node$NODE_COUNT"
              
              case "$cap" in
                "web-search") LABEL="üîç WebÊ§úÁ¥¢" ;;
                "planning") LABEL="üìã ‰ºÅÁîª„ÉªË®àÁîª" ;;
                "image-generation") LABEL="üñºÔ∏è ÁîªÂÉèÁîüÊàê" ;;
                "video-generation") LABEL="üé¨ ÂãïÁîªÁîüÊàê" ;;
                "lipsync") LABEL="üëÑ „É™„ÉÉ„Éó„Ç∑„É≥„ÇØ" ;;
                "subtitle-overlay") LABEL="üìù Â≠óÂπïËøΩÂä†" ;;
                *) LABEL="$cap" ;;
              esac
              
              echo "    $NODE_NAME[$LABEL]" >> metadata/mermaid.txt
              echo "    $PREV_NODE --> $NODE_NAME" >> metadata/mermaid.txt
              
              PREV_NODE=$NODE_NAME
              NODE_COUNT=$((NODE_COUNT + 1))
            fi
          done
          
          echo "    $PREV_NODE --> End[ÂÆå‰∫Ü]" >> metadata/mermaid.txt
          
      - name: Upload Analysis Results
        uses: actions/upload-artifact@v4
        with:
          name: analysis-data
          path: |
            metadata/
            projects/current-session/metadata/

  # ===========================================
  # PHASE 4: WORKFLOW GENERATION
  # ===========================================
  
  workflow-generation:
    name: "üöÄ Workflow Generation"
    runs-on: ubuntu-latest
    needs: ['validate-trigger', 'basic-task-decomposition', 'detailed-analysis']
    outputs:
      workflow_id: ${{ steps.generate.outputs.workflow_id }}
      total_jobs: ${{ steps.generate.outputs.total_jobs }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Generate Workflow
        id: generate
        run: |
          echo "üöÄ Generating optimized workflow..."
          
          ISSUE_NUMBER=$(cat artifacts/issue-data/issue_number.txt)
          CAPABILITIES=$(cat artifacts/capabilities-data/capabilities.txt)
          COMPLEXITY="${{ needs['basic-task-decomposition'].outputs.complexity }}"
          
          # Create workflow directory
          mkdir -p generated-workflows
          WORKFLOW_FILE="generated-workflows/dynamic-workflow-${ISSUE_NUMBER}.yml"
          
          # Generate workflow header
          echo 'name: "üéØ Dynamic Workflow - Issue #${{ github.event.inputs.issue_number }}"' > "$WORKFLOW_FILE"
          echo 'run-name: "üìä Dynamic | ${{ github.actor }} | Issue #${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'on:' >> "$WORKFLOW_FILE"
          echo '  workflow_dispatch:' >> "$WORKFLOW_FILE"
          echo '    inputs:' >> "$WORKFLOW_FILE"
          echo '      issue_number:' >> "$WORKFLOW_FILE"
          echo '        description: "Source issue number"' >> "$WORKFLOW_FILE"
          echo '        required: true' >> "$WORKFLOW_FILE"
          echo "        default: \"$ISSUE_NUMBER\"" >> "$WORKFLOW_FILE"
          echo '      branch_name:' >> "$WORKFLOW_FILE"
          echo '        description: "Working branch name"' >> "$WORKFLOW_FILE"
          echo '        required: false' >> "$WORKFLOW_FILE"
          echo "        default: \"issue-${ISSUE_NUMBER}\"" >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          
          # Add permissions and environment
          echo 'permissions:' >> "$WORKFLOW_FILE"
          echo '  contents: write' >> "$WORKFLOW_FILE"
          echo '  actions: write' >> "$WORKFLOW_FILE"
          echo '  issues: write' >> "$WORKFLOW_FILE"
          echo '  pull-requests: write' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'env:' >> "$WORKFLOW_FILE"
          echo '  CLAUDE_CODE_CI_MODE: true' >> "$WORKFLOW_FILE"
          echo '  CLAUDE_CODE_AUTO_APPROVE_MCP: true' >> "$WORKFLOW_FILE"
          echo '  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          
          # Add jobs based on capabilities
          echo 'jobs:' >> "$WORKFLOW_FILE"
          
          # Setup job (minimal to avoid expression limits)
          echo '  setup:' >> "$WORKFLOW_FILE"
          echo '    name: "üöÄ Setup"' >> "$WORKFLOW_FILE"
          echo '    runs-on: ubuntu-latest' >> "$WORKFLOW_FILE"
          echo '    outputs:' >> "$WORKFLOW_FILE"
          echo '      project_dir: ${{ steps.setup.outputs.project_dir }}' >> "$WORKFLOW_FILE"
          echo '      timestamp: ${{ steps.setup.outputs.timestamp }}' >> "$WORKFLOW_FILE"
          echo '    steps:' >> "$WORKFLOW_FILE"
          echo '      - name: Checkout Repository' >> "$WORKFLOW_FILE"
          echo '        uses: actions/checkout@v4' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo '      - name: Create Project Structure' >> "$WORKFLOW_FILE"
          echo '        id: setup' >> "$WORKFLOW_FILE"
          echo '        run: |' >> "$WORKFLOW_FILE"
          echo '          TIMESTAMP=$(date +%Y%m%d-%H%M%S)' >> "$WORKFLOW_FILE"
          echo '          PROJECT_DIR="projects/issue-${{ github.event.inputs.issue_number }}-$TIMESTAMP"' >> "$WORKFLOW_FILE"
          echo '          mkdir -p "$PROJECT_DIR"/{logs,metadata,temp,final,media}' >> "$WORKFLOW_FILE"
          echo '          echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT' >> "$WORKFLOW_FILE"
          echo '          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT' >> "$WORKFLOW_FILE"
          echo '          echo "‚úÖ Project structure created: $PROJECT_DIR"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          
          # Group capabilities and create phases
          IFS=',' read -ra CAP_ARRAY <<< "$CAPABILITIES"
          
          # Capability mapping to minimal units
          declare -A UNIT_MAP
          UNIT_MAP["web-search"]="./minimal-units/planning/web-search.yml"
          UNIT_MAP["data-analysis"]="./minimal-units/planning/data-analysis.yml"
          UNIT_MAP["planning"]="./minimal-units/planning/planning-ccsdk.yml"
          UNIT_MAP["content-planning"]="./minimal-units/planning/content-planning.yml"
          UNIT_MAP["scene-composition"]="./minimal-units/planning/scene-composition.yml"
          UNIT_MAP["image-generation"]="./minimal-units/media/image/t2i-imagen3.yml"
          UNIT_MAP["video-generation"]="./minimal-units/media/video/t2v-veo3.yml"
          UNIT_MAP["audio-generation"]="./minimal-units/media/audio/bgm-generate-mcp.yml"
          UNIT_MAP["lipsync"]="./minimal-units/postprod/lipsync-generation.yml"
          UNIT_MAP["subtitle-overlay"]="./minimal-units/postprod/subtitle-overlay.yml"
          UNIT_MAP["video-editing"]="./minimal-units/postprod/video-concat.yml"
          
          # Phase separation
          RESEARCH_JOBS=""
          PLANNING_JOBS=""
          MEDIA_JOBS=""
          POST_JOBS=""
          
          for cap in "${CAP_ARRAY[@]}"; do
            if [ -n "$cap" ]; then
              case "$cap" in
                web-search|data-analysis)
                  RESEARCH_JOBS="${RESEARCH_JOBS}${cap},"
                  ;;
                planning|scene-composition|content-planning|narration*)
                  PLANNING_JOBS="${PLANNING_JOBS}${cap},"
                  ;;
                image-generation|video-generation|audio-generation|text-to-speech)
                  MEDIA_JOBS="${MEDIA_JOBS}${cap},"
                  ;;
                lipsync|subtitle-overlay|video-editing|video-concat)
                  POST_JOBS="${POST_JOBS}${cap},"
                  ;;
              esac
            fi
          done
          
          # Research phase (sequential)
          if [ -n "$RESEARCH_JOBS" ]; then
            IFS=',' read -ra RESEARCH_ARRAY <<< "$RESEARCH_JOBS"
            JOB_INDEX=1
            for research_job in "${RESEARCH_ARRAY[@]}"; do
              if [ -n "$research_job" ]; then
                JOB_NAME="research_${JOB_INDEX}"
                echo "  ${JOB_NAME}:" >> "$WORKFLOW_FILE"
                echo "    name: \"üîç Research: ${research_job}\"" >> "$WORKFLOW_FILE"
                if [ -f "${UNIT_MAP[$research_job]}" ]; then
                  echo "    uses: ${UNIT_MAP[$research_job]}" >> "$WORKFLOW_FILE"
                else
                  echo "    uses: ./minimal-units/planning/web-search.yml" >> "$WORKFLOW_FILE"
                fi
                if [ $JOB_INDEX -eq 1 ]; then
                  echo '    needs: setup' >> "$WORKFLOW_FILE"
                else
                  PREV_JOB="research_$((JOB_INDEX - 1))"
                  echo "    needs: [setup, ${PREV_JOB}]" >> "$WORKFLOW_FILE"
                fi
                echo '    with:' >> "$WORKFLOW_FILE"
                echo '      query: "${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
                echo '      output_dir: "${{ needs.setup.outputs.project_dir }}/metadata"' >> "$WORKFLOW_FILE"
                echo '' >> "$WORKFLOW_FILE"
                JOB_INDEX=$((JOB_INDEX + 1))
              fi
            done
          fi
          
          # Planning phase (sequential with dependency)
          if [ -n "$PLANNING_JOBS" ]; then
            IFS=',' read -ra PLANNING_ARRAY <<< "$PLANNING_JOBS"
            JOB_INDEX=1
            PREV_PHASE_JOB=""
            if [ -n "$RESEARCH_JOBS" ]; then
              RESEARCH_COUNT=$(echo "$RESEARCH_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)
              PREV_PHASE_JOB="research_${RESEARCH_COUNT}"
            fi
            
            for planning_job in "${PLANNING_ARRAY[@]}"; do
              if [ -n "$planning_job" ]; then
                JOB_NAME="planning_${JOB_INDEX}"
                echo "  ${JOB_NAME}:" >> "$WORKFLOW_FILE"
                echo "    name: \"üìã Planning: ${planning_job}\"" >> "$WORKFLOW_FILE"
                if [ -f "${UNIT_MAP[$planning_job]}" ]; then
                  echo "    uses: ${UNIT_MAP[$planning_job]}" >> "$WORKFLOW_FILE"
                else
                  echo "    uses: ./minimal-units/planning/planning-ccsdk.yml" >> "$WORKFLOW_FILE"
                fi
                
                # Dependencies
                if [ $JOB_INDEX -eq 1 ]; then
                  if [ -n "$PREV_PHASE_JOB" ]; then
                    echo "    needs: [setup, ${PREV_PHASE_JOB}]" >> "$WORKFLOW_FILE"
                  else
                    echo '    needs: setup' >> "$WORKFLOW_FILE"
                  fi
                else
                  PREV_JOB="planning_$((JOB_INDEX - 1))"
                  echo "    needs: ${PREV_JOB}" >> "$WORKFLOW_FILE"
                fi
                
                echo '    with:' >> "$WORKFLOW_FILE"
                echo '      concept: "Issue #${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
                echo '      output_dir: "${{ needs.setup.outputs.project_dir }}/metadata"' >> "$WORKFLOW_FILE"
                echo '    secrets:' >> "$WORKFLOW_FILE"
                echo '      CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}' >> "$WORKFLOW_FILE"
                echo '' >> "$WORKFLOW_FILE"
                JOB_INDEX=$((JOB_INDEX + 1))
              fi
            done
          fi
          
          # Media generation phase (parallel execution)
          if [ -n "$MEDIA_JOBS" ]; then
            # Determine dependencies for media jobs
            MEDIA_DEPS="setup"
            if [ -n "$PLANNING_JOBS" ]; then
              PLANNING_COUNT=$(echo "$PLANNING_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)
              MEDIA_DEPS="planning_${PLANNING_COUNT}"
            elif [ -n "$RESEARCH_JOBS" ]; then
              RESEARCH_COUNT=$(echo "$RESEARCH_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)
              MEDIA_DEPS="research_${RESEARCH_COUNT}"
            fi
            
            IFS=',' read -ra MEDIA_ARRAY <<< "$MEDIA_JOBS"
            for media_job in "${MEDIA_ARRAY[@]}"; do
              if [ -n "$media_job" ]; then
                JOB_NAME=$(echo "$media_job" | tr '-' '_')
                echo "  ${JOB_NAME}:" >> "$WORKFLOW_FILE"
                echo "    name: \"üé® ${media_job}\"" >> "$WORKFLOW_FILE"
                if [ -f "${UNIT_MAP[$media_job]}" ]; then
                  echo "    uses: ${UNIT_MAP[$media_job]}" >> "$WORKFLOW_FILE"
                else
                  echo "    runs-on: ubuntu-latest" >> "$WORKFLOW_FILE"
                fi
                echo "    needs: ${MEDIA_DEPS}" >> "$WORKFLOW_FILE"
                echo '    with:' >> "$WORKFLOW_FILE"
                echo '      prompt: "Generated content for issue #${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
                echo '      output_dir: "${{ needs.setup.outputs.project_dir }}/media"' >> "$WORKFLOW_FILE"
                echo '    secrets:' >> "$WORKFLOW_FILE"
                echo '      CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}' >> "$WORKFLOW_FILE"
                echo '' >> "$WORKFLOW_FILE"
              fi
            done
          fi
          
          # Post-processing phase (sequential)
          if [ -n "$POST_JOBS" ]; then
            # Collect all media job names for dependencies
            MEDIA_JOB_NAMES=""
            if [ -n "$MEDIA_JOBS" ]; then
              IFS=',' read -ra MEDIA_ARRAY <<< "$MEDIA_JOBS"
              for media_job in "${MEDIA_ARRAY[@]}"; do
                if [ -n "$media_job" ]; then
                  JOB_NAME=$(echo "$media_job" | tr '-' '_')
                  MEDIA_JOB_NAMES="${MEDIA_JOB_NAMES}${JOB_NAME}, "
                fi
              done
              MEDIA_JOB_NAMES="${MEDIA_JOB_NAMES%, }"
            fi
            
            IFS=',' read -ra POST_ARRAY <<< "$POST_JOBS"
            JOB_INDEX=1
            for post_job in "${POST_ARRAY[@]}"; do
              if [ -n "$post_job" ]; then
                JOB_NAME="post_${JOB_INDEX}"
                echo "  ${JOB_NAME}:" >> "$WORKFLOW_FILE"
                echo "    name: \"üîß Post: ${post_job}\"" >> "$WORKFLOW_FILE"
                if [ -f "${UNIT_MAP[$post_job]}" ]; then
                  echo "    uses: ${UNIT_MAP[$post_job]}" >> "$WORKFLOW_FILE"
                else
                  echo "    runs-on: ubuntu-latest" >> "$WORKFLOW_FILE"
                fi
                
                # Dependencies
                if [ $JOB_INDEX -eq 1 ]; then
                  if [ -n "$MEDIA_JOB_NAMES" ]; then
                    echo "    needs: [${MEDIA_JOB_NAMES}]" >> "$WORKFLOW_FILE"
                  else
                    echo '    needs: setup' >> "$WORKFLOW_FILE"
                  fi
                else
                  PREV_JOB="post_$((JOB_INDEX - 1))"
                  echo "    needs: ${PREV_JOB}" >> "$WORKFLOW_FILE"
                fi
                
                echo '    with:' >> "$WORKFLOW_FILE"
                echo '      video_list: "placeholder"' >> "$WORKFLOW_FILE"
                echo '      output_dir: "${{ needs.setup.outputs.project_dir }}/final"' >> "$WORKFLOW_FILE"
                echo '' >> "$WORKFLOW_FILE"
                JOB_INDEX=$((JOB_INDEX + 1))
              fi
            done
          fi
          
          # Summary job
          echo '  summary:' >> "$WORKFLOW_FILE"
          echo '    name: "üìä Summary"' >> "$WORKFLOW_FILE"
          echo '    runs-on: ubuntu-latest' >> "$WORKFLOW_FILE"
          echo '    if: always()' >> "$WORKFLOW_FILE"
          
          # Build needs list for summary
          ALL_JOBS="setup"
          if [ -n "$RESEARCH_JOBS" ]; then
            RESEARCH_COUNT=$(echo "$RESEARCH_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)
            for i in $(seq 1 $RESEARCH_COUNT); do
              ALL_JOBS="${ALL_JOBS}, research_${i}"
            done
          fi
          if [ -n "$PLANNING_JOBS" ]; then
            PLANNING_COUNT=$(echo "$PLANNING_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)
            for i in $(seq 1 $PLANNING_COUNT); do
              ALL_JOBS="${ALL_JOBS}, planning_${i}"
            done
          fi
          if [ -n "$MEDIA_JOBS" ]; then
            IFS=',' read -ra MEDIA_ARRAY <<< "$MEDIA_JOBS"
            for media_job in "${MEDIA_ARRAY[@]}"; do
              if [ -n "$media_job" ]; then
                JOB_NAME=$(echo "$media_job" | tr '-' '_')
                ALL_JOBS="${ALL_JOBS}, ${JOB_NAME}"
              fi
            done
          fi
          if [ -n "$POST_JOBS" ]; then
            POST_COUNT=$(echo "$POST_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)
            for i in $(seq 1 $POST_COUNT); do
              ALL_JOBS="${ALL_JOBS}, post_${i}"
            done
          fi
          
          echo "    needs: [${ALL_JOBS}]" >> "$WORKFLOW_FILE"
          echo '    steps:' >> "$WORKFLOW_FILE"
          echo '      - name: Generate Summary' >> "$WORKFLOW_FILE"
          echo '        run: |' >> "$WORKFLOW_FILE"
          echo '          echo "# üéØ Workflow Execution Summary" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Issue**: #${{ github.event.inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Status**: Completed" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Project**: ${{ needs.setup.outputs.project_dir }}" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          
          # Count total jobs
          JOB_COUNT=2  # setup + summary
          [ -n "$RESEARCH_JOBS" ] && JOB_COUNT=$((JOB_COUNT + $(echo "$RESEARCH_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)))
          [ -n "$PLANNING_JOBS" ] && JOB_COUNT=$((JOB_COUNT + $(echo "$PLANNING_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)))
          [ -n "$MEDIA_JOBS" ] && JOB_COUNT=$((JOB_COUNT + $(echo "$MEDIA_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)))
          [ -n "$POST_JOBS" ] && JOB_COUNT=$((JOB_COUNT + $(echo "$POST_JOBS" | tr ',' '\n' | grep -v '^$' | wc -l)))
          
          echo "workflow_id=${ISSUE_NUMBER}-$(date +%Y%m%d-%H%M%S)" >> $GITHUB_OUTPUT
          echo "total_jobs=$JOB_COUNT" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Generated workflow with $JOB_COUNT jobs"
          
      - name: Upload Generated Workflow
        uses: actions/upload-artifact@v4
        with:
          name: generated-workflow
          path: generated-workflows/

  # ===========================================
  # PHASE 5: WORKFLOW VALIDATION
  # ===========================================
  
  workflow-validation:
    name: "‚úÖ Workflow Validation"
    runs-on: ubuntu-latest
    needs: ['workflow-generation']
    outputs:
      validation_passed: ${{ steps.validate.outputs.passed }}
      optimization_needed: ${{ steps.validate.outputs.needs_optimization }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Generated Workflow
        uses: actions/download-artifact@v4
        with:
          name: generated-workflow
          path: generated-workflows/
          
      - name: Validate Workflow
        id: validate
        run: |
          echo "‚úÖ Validating generated workflow..."
          
          WORKFLOW_FILE=$(find generated-workflows -name '*.yml' | head -1)
          
          # Check YAML syntax
          python3 -c "import yaml; yaml.safe_load(open('$WORKFLOW_FILE'))" 2>/dev/null
          if [ $? -eq 0 ]; then
            echo "‚úÖ YAML syntax valid"
            SYNTAX_OK=true
          else
            echo "‚ùå YAML syntax error"
            SYNTAX_OK=false
          fi
          
          # Check for long expressions
          LONG_LINES=$(grep -n '\${{' "$WORKFLOW_FILE" | grep '}}' | awk 'length($0) > 500' | wc -l)
          if [ "$LONG_LINES" -gt 0 ]; then
            echo "‚ö†Ô∏è Found $LONG_LINES long expression lines"
            echo "needs_optimization=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ No long expressions found"
            echo "needs_optimization=false" >> $GITHUB_OUTPUT
          fi
          
          # Check job count
          JOB_COUNT=$(grep -c "^  [a-zA-Z][a-zA-Z0-9_-]*:" "$WORKFLOW_FILE" | grep -v "^on:" | grep -v "^jobs:" || echo 0)
          if [ "$JOB_COUNT" -gt 10 ]; then
            echo "‚ö†Ô∏è Too many jobs ($JOB_COUNT), consider parallelization"
            echo "needs_optimization=true" >> $GITHUB_OUTPUT
          fi
          
          if [ "$SYNTAX_OK" = true ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "passed=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Prepare Optimization Script Part 1
        if: ${{ steps.validate.outputs.needs_optimization == 'true' }}
        run: |
          echo "üìä Preparing optimization script (Part 1)..."
          
          # Create optimization script header
          cat > optimize_part1.py << 'EOF'
#!/usr/bin/env python3
import yaml
import sys
import json
from typing import List, Dict, Any

def load_workflow(file_path: str) -> Dict:
    """„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def analyze_node_length(job_content: Dict) -> int:
    """„Éé„Éº„Éâ„ÅÆÈï∑„Åï„ÇíÂàÜÊûê"""
    content_str = yaml.dump(job_content)
    return len(content_str)

def identify_long_nodes(workflow: Dict, threshold: int = 15000) -> List[str]:
    """Èï∑„ÅÑ„Éé„Éº„Éâ„ÇíÁâπÂÆö"""
    long_nodes = []
    if 'jobs' in workflow:
        for job_name, job_content in workflow['jobs'].items():
            length = analyze_node_length(job_content)
            if length > threshold:
                long_nodes.append(job_name)
                print(f"‚ö†Ô∏è Long node detected: {job_name} ({length} chars)")
    return long_nodes
EOF
          
      - name: Prepare Optimization Script Part 2
        if: ${{ steps.validate.outputs.needs_optimization == 'true' }}
        run: |
          echo "üìä Preparing optimization script (Part 2)..."
          
          # Add node splitting logic
          cat >> optimize_part1.py << 'EOF'

def split_long_node(job_name: str, job_content: Dict) -> Dict[str, Dict]:
    """Èï∑„ÅÑ„Éé„Éº„Éâ„ÇíÂàÜÂâ≤"""
    split_jobs = {}
    
    if 'steps' in job_content and len(job_content['steps']) > 10:
        # „Çπ„ÉÜ„ÉÉ„ÉóÊï∞„ÅåÂ§ö„ÅÑÂ†¥Âêà„ÅØÂàÜÂâ≤
        steps = job_content['steps']
        mid_point = len(steps) // 2
        
        # Part 1
        job1 = job_content.copy()
        job1['steps'] = steps[:mid_point]
        split_jobs[f"{job_name}_part1"] = job1
        
        # Part 2
        job2 = job_content.copy()
        job2['steps'] = steps[mid_point:]
        if 'needs' in job1:
            job2['needs'] = [f"{job_name}_part1"]
        split_jobs[f"{job_name}_part2"] = job2
        
        print(f"‚úÖ Split {job_name} into 2 parts")
    else:
        split_jobs[job_name] = job_content
    
    return split_jobs

def identify_parallel_opportunities(workflow: Dict) -> List[List[str]]:
    """‰∏¶ÂàóÂÆüË°åÂèØËÉΩ„Å™„Ç∏„Éß„Éñ„ÇíÁâπÂÆö"""
    parallel_groups = []
    jobs = workflow.get('jobs', {})
    
    # ‰æùÂ≠òÈñ¢‰øÇ„ÅÆ„Å™„ÅÑ„Ç∏„Éß„Éñ„Çí„Ç∞„É´„Éº„ÉóÂåñ
    no_deps = []
    for job_name, job_content in jobs.items():
        if 'needs' not in job_content or not job_content['needs']:
            no_deps.append(job_name)
    
    if len(no_deps) > 1:
        parallel_groups.append(no_deps)
        print(f"üöÄ Found parallel group: {no_deps}")
    
    return parallel_groups
EOF

      - name: Prepare Optimization Script Part 3
        if: ${{ steps.validate.outputs.needs_optimization == 'true' }}
        run: |
          echo "üìä Preparing optimization script (Part 3)..."
          
          # Add main optimization logic
          cat >> optimize_part1.py << 'EOF'

def optimize_workflow(workflow: Dict) -> Dict:
    """„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÊúÄÈÅ©Âåñ"""
    optimized = workflow.copy()
    
    # 1. Èï∑„ÅÑ„Éé„Éº„Éâ„ÇíÁâπÂÆö„Åó„Å¶ÂàÜÂâ≤
    long_nodes = identify_long_nodes(workflow)
    if long_nodes:
        print(f"\nüîç Found {len(long_nodes)} long nodes to split")
        new_jobs = {}
        
        for job_name, job_content in workflow.get('jobs', {}).items():
            if job_name in long_nodes:
                split_jobs = split_long_node(job_name, job_content)
                new_jobs.update(split_jobs)
            else:
                new_jobs[job_name] = job_content
        
        optimized['jobs'] = new_jobs
    
    # 2. ‰∏¶ÂàóÂÆüË°å„ÅÆÊúÄÈÅ©Âåñ
    parallel_groups = identify_parallel_opportunities(optimized)
    if parallel_groups:
        print(f"\nüöÄ Identified {len(parallel_groups)} parallel execution opportunities")
    
    return optimized

# „É°„Ç§„É≥Âá¶ÁêÜ
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python optimize.py <workflow.yml>")
        sys.exit(1)
    
    workflow_file = sys.argv[1]
    print(f"üîß Optimizing workflow: {workflow_file}")
    
    # „ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíË™≠„ÅøËæº„Åø
    workflow = load_workflow(workflow_file)
    
    # ÊúÄÈÅ©Âåñ
    optimized = optimize_workflow(workflow)
    
    # ÁµêÊûú„Çí‰øùÂ≠ò
    output_file = workflow_file.replace('.yml', '_optimized.yml')
    with open(output_file, 'w', encoding='utf-8') as f:
        yaml.dump(optimized, f, default_flow_style=False, sort_keys=False)
    
    print(f"‚úÖ Optimized workflow saved to: {output_file}")
    
    # „É°„Çø„Éá„Éº„Çø„ÇíÂá∫Âäõ
    metadata = {
        "original_jobs": len(workflow.get('jobs', {})),
        "optimized_jobs": len(optimized.get('jobs', {})),
        "long_nodes_split": len(identify_long_nodes(workflow)),
        "parallel_groups": len(identify_parallel_opportunities(optimized))
    }
    
    with open('optimization_metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)
EOF

      - name: Execute Optimization
        if: ${{ steps.validate.outputs.needs_optimization == 'true' }}
        run: |
          echo "üöÄ Executing optimization..."
          
          # Combine script parts
          mv optimize_part1.py optimize.py
          
          # Find and optimize workflow
          WORKFLOW_FILE=$(find generated-workflows -name '*.yml' | head -1)
          
          if [ -f "$WORKFLOW_FILE" ]; then
            python optimize.py "$WORKFLOW_FILE"
            
            # Check if optimization was successful
            OPTIMIZED_FILE="${WORKFLOW_FILE%.yml}_optimized.yml"
            if [ -f "$OPTIMIZED_FILE" ]; then
              # Replace original with optimized version
              mv "$OPTIMIZED_FILE" "$WORKFLOW_FILE"
              echo "‚úÖ Workflow optimized successfully"
              
              # Read metadata
              if [ -f "optimization_metadata.json" ]; then
                cat optimization_metadata.json
              fi
            else
              echo "‚ö†Ô∏è Optimization did not produce output"
            fi
          else
            echo "‚ö†Ô∏è No workflow file found to optimize"
          fi
          
      - name: Upload Validated Workflow
        uses: actions/upload-artifact@v4
        with:
          name: validated-workflow
          path: generated-workflows/

  # ===========================================
  # PHASE 6: DEPLOYMENT
  # ===========================================
  
  deployment:
    name: "üì¶ Deployment"
    runs-on: ubuntu-latest
    needs: ['workflow-validation', 'workflow-generation']
    if: ${{ needs['workflow-validation'].outputs.validation_passed == 'true' }}
    outputs:
      deployed_path: ${{ steps.deploy.outputs.path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Validated Workflow
        uses: actions/download-artifact@v4
        with:
          name: validated-workflow
          path: generated-workflows/
          
      - name: Deploy Workflow
        id: deploy
        run: |
          echo "üì¶ Deploying workflow..."
          
          WORKFLOW_FILE=$(find generated-workflows -name '*.yml' | head -1)
          DEPLOYMENT_NAME="issue-${{ inputs.issue_number }}-$(date +%Y%m%d-%H%M%S).yml.disabled"
          DEPLOYMENT_PATH=".github/workflows/generated/$DEPLOYMENT_NAME"
          
          # Create deployment directory
          mkdir -p .github/workflows/generated
          
          # Copy workflow
          cp "$WORKFLOW_FILE" "$DEPLOYMENT_PATH"
          
          echo "path=$DEPLOYMENT_PATH" >> $GITHUB_OUTPUT
          
          # Commit and push
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add "$DEPLOYMENT_PATH"
          git commit -m "ü§ñ Generated workflow for Issue #${{ inputs.issue_number }}" || echo "No changes"
          git push origin main || echo "Push failed"
          
          echo "‚úÖ Deployed to: $DEPLOYMENT_PATH"

  # ===========================================
  # PHASE 7: EXECUTION SUMMARY
  # ===========================================
  
  execution-summary:
    name: "üìä Execution Summary"
    runs-on: ubuntu-latest
    needs: ['validate-trigger', 'basic-task-decomposition', 'detailed-analysis', 'workflow-generation', 'workflow-validation', 'deployment']
    if: ${{ always() }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Generate Summary
        env:
          ISSUE_NUMBER: ${{ inputs.issue_number }}
          ISSUE_TITLE: ${{ needs['validate-trigger'].outputs.issue_title }}
          REQUEST_TYPE: ${{ needs['validate-trigger'].outputs.request_type }}
          CAPABILITIES_COUNT: ${{ needs['basic-task-decomposition'].outputs.capabilities_count }}
          COMPLEXITY: ${{ needs['basic-task-decomposition'].outputs.complexity }}
          HAS_VIDEO: ${{ needs['basic-task-decomposition'].outputs.has_video }}
          HAS_NARRATION: ${{ needs['basic-task-decomposition'].outputs.has_narration }}
          ORCHESTRATOR_MATCH: ${{ needs['detailed-analysis'].outputs.orchestrator_match }}
          EXECUTION_PATTERN: ${{ needs['detailed-analysis'].outputs.execution_pattern }}
          TOTAL_JOBS: ${{ needs['workflow-generation'].outputs.total_jobs }}
          VALIDATION_PASSED: ${{ needs['workflow-validation'].outputs.validation_passed }}
          OPTIMIZATION_NEEDED: ${{ needs['workflow-validation'].outputs.optimization_needed }}
          DEPLOYED_PATH: ${{ needs.deployment.outputs.deployed_path }}
        run: |
          echo "# üìä Meta Workflow v10 ÂÆüË°åÁµêÊûú" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üìã „É™„ÇØ„Ç®„Çπ„ÉàÊÉÖÂ†±" >> $GITHUB_STEP_SUMMARY
          echo "- **Issue**: #$ISSUE_NUMBER" >> $GITHUB_STEP_SUMMARY
          echo "- **„Çø„Ç§„Éà„É´**: $ISSUE_TITLE" >> $GITHUB_STEP_SUMMARY
          echo "- **„Çø„Ç§„Éó**: $REQUEST_TYPE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üîç „Çø„Çπ„ÇØÂàÜËß£ÁµêÊûú" >> $GITHUB_STEP_SUMMARY
          echo "### Ê§úÂá∫„Åï„Çå„ÅüËÉΩÂäõ" >> $GITHUB_STEP_SUMMARY
          if [ -f "artifacts/capabilities-data/capabilities.txt" ]; then
            CAPABILITIES=$(cat artifacts/capabilities-data/capabilities.txt)
            IFS=',' read -ra CAP_ARRAY <<< "$CAPABILITIES"
            for cap in "${CAP_ARRAY[@]}"; do
              if [ -n "$cap" ]; then
                echo "- ‚úÖ $cap" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### „Çø„Çπ„ÇØÂàÜËß£„ÅÆË©≥Á¥∞" >> $GITHUB_STEP_SUMMARY
          echo "- **Ê§úÂá∫ËÉΩÂäõÊï∞**: $CAPABILITIES_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- **Ë§áÈõëÂ∫¶**: $COMPLEXITY" >> $GITHUB_STEP_SUMMARY
          
          # Show fine-grained decomposition
          if [ "$HAS_VIDEO" == "true" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "#### üé¨ ÂãïÁîªÁîüÊàê„Çø„Çπ„ÇØ„ÅÆË©≥Á¥∞ÂàÜËß£:" >> $GITHUB_STEP_SUMMARY
            echo "- üìã „Ç≥„É≥„ÉÜ„É≥„ÉÑ‰ºÅÁîª (content-planning)" >> $GITHUB_STEP_SUMMARY
            if [ "$HAS_NARRATION" == "true" ]; then
              echo "- üé§ „Éä„É¨„Éº„Ç∑„Éß„É≥‰ΩúÊàê (narration-creation)" >> $GITHUB_STEP_SUMMARY
              echo "- üëÑ „É™„ÉÉ„Éó„Ç∑„É≥„ÇØÂá¶ÁêÜ (lipsync)" >> $GITHUB_STEP_SUMMARY
              echo "- üìù Â≠óÂπï„Ç™„Éº„Éê„Éº„É¨„Ç§ (subtitle-overlay)" >> $GITHUB_STEP_SUMMARY
            fi
            echo "- üé® „Ç∑„Éº„É≥ÊßãÊàê (scene-composition)" >> $GITHUB_STEP_SUMMARY
            echo "- üñºÔ∏è ÁîªÂÉèÁîüÊàê (image-generation)" >> $GITHUB_STEP_SUMMARY
            echo "- üé¨ ÂãïÁîªÁîüÊàê (video-generation)" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üß† „Ç™„Éº„Ç±„Çπ„Éà„É¨„Éº„Çø„ÉºÂàÜÊûê" >> $GITHUB_STEP_SUMMARY
          echo "- **„Éû„ÉÉ„ÉÅ„É≥„Ç∞**: $ORCHESTRATOR_MATCH" >> $GITHUB_STEP_SUMMARY
          echo "- **ÂÆüË°å„Éë„Çø„Éº„É≥**: $EXECUTION_PATTERN" >> $GITHUB_STEP_SUMMARY
          
          # Show Mermaid diagram if exists
          if [ -f "artifacts/analysis-data/metadata/mermaid.txt" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üìä ÂÆüË°å„Éï„É≠„ÉºÂõ≥" >> $GITHUB_STEP_SUMMARY
            echo '```mermaid' >> $GITHUB_STEP_SUMMARY
            cat artifacts/analysis-data/metadata/mermaid.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üöÄ „ÉØ„Éº„ÇØ„Éï„É≠„ÉºÁîüÊàê" >> $GITHUB_STEP_SUMMARY
          echo "- **ÁîüÊàê„Ç∏„Éß„ÉñÊï∞**: $TOTAL_JOBS" >> $GITHUB_STEP_SUMMARY
          echo "- **Ê§úË®ºÁµêÊûú**: $VALIDATION_PASSED" >> $GITHUB_STEP_SUMMARY
          echo "- **ÊúÄÈÅ©Âåñ**: $OPTIMIZATION_NEEDED" >> $GITHUB_STEP_SUMMARY
          
          # Show job structure
          if [ -d "artifacts/generated-workflow" ] && [ -n "$(ls -A artifacts/generated-workflow/*.yml 2>/dev/null)" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üìã ÁîüÊàê„Åï„Çå„Åü„Ç∏„Éß„ÉñÊßãÈÄ†" >> $GITHUB_STEP_SUMMARY
            WORKFLOW_FILE=$(find artifacts/generated-workflow -name '*.yml' | head -1)
            # Extract job names
            grep -E "^  [a-zA-Z_-]+:" "$WORKFLOW_FILE" | grep -v "^  workflow_dispatch:" | sed 's/://g' | while read job; do
              echo "- $job" >> $GITHUB_STEP_SUMMARY
            done
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$DEPLOYED_PATH" != "" ]; then
            echo "## ‚úÖ „Éá„Éó„É≠„Ç§ÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
            echo "- **‰øùÂ≠òÂ†¥ÊâÄ**: \`$DEPLOYED_PATH\`" >> $GITHUB_STEP_SUMMARY
            echo "- **„Ç¢„ÇØ„ÉÜ„Ç£„Éô„Éº„Ç∑„Éß„É≥**: .disabledÊã°ÂºµÂ≠ê„ÇíÂâäÈô§„Åó„Å¶ÊúâÂäπÂåñ" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üéØ Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó" >> $GITHUB_STEP_SUMMARY
            echo "1. ÁîüÊàê„Åï„Çå„Åü„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÁ¢∫Ë™ç" >> $GITHUB_STEP_SUMMARY
            echo "2. \`.disabled\`Êã°ÂºµÂ≠ê„ÇíÂâäÈô§„Åó„Å¶ÊúâÂäπÂåñ" >> $GITHUB_STEP_SUMMARY
            echo "3. Actions „Çø„Éñ„Åã„ÇâÊâãÂãïÂÆüË°å" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ‚ö†Ô∏è „Éá„Éó„É≠„Ç§„Çπ„Ç≠„ÉÉ„Éó" >> $GITHUB_STEP_SUMMARY
            echo "Ê§úË®º„Ç®„É©„Éº„ÅÆ„Åü„ÇÅ„Éá„Éó„É≠„Ç§„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åó„Åü„ÄÇ" >> $GITHUB_STEP_SUMMARY
          fi