name: "Meta Workflow Executor v10 with Claude SDK"
run-name: "🚀 Meta Workflow v10 | Issue #${{ inputs.issue_number }} | ${{ github.actor }}"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number for workflow generation request'
        required: true
        default: '60'

permissions:
  contents: write
  issues: write
  actions: write
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  # ===========================================
  # PHASE 1: ISSUE ANALYSIS & VALIDATION
  # ===========================================
  
  validate-trigger:
    name: "🔍 Issue Analysis & Validation"
    runs-on: ubuntu-latest
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
      issue_body: ${{ steps.extract.outputs.issue_body }}
      issue_title: ${{ steps.extract.outputs.issue_title }}
      request_type: ${{ steps.analyze.outputs.request_type }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Extract Issue Information
        id: extract
        run: |
          echo "🔍 Analyzing Issue #${{ inputs.issue_number }}..."
          
          # Get issue details using GitHub CLI
          ISSUE_DATA=$(gh issue view ${{ inputs.issue_number }} --json title,body,number --jq '{title: .title, body: .body, number: .number}')
          
          ISSUE_TITLE=$(echo "$ISSUE_DATA" | jq -r '.title')
          ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body')
          ISSUE_NUMBER=$(echo "$ISSUE_DATA" | jq -r '.number')
          
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          
          {
            echo 'issue_title<<EOF'
            echo "$ISSUE_TITLE"
            echo 'EOF'
          } >> $GITHUB_OUTPUT
          
          {
            echo 'issue_body<<EOF'
            echo "$ISSUE_BODY"
            echo 'EOF'
          } >> $GITHUB_OUTPUT
          
          echo "✅ Issue #$ISSUE_NUMBER validated: $ISSUE_TITLE"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Analyze Request Type
        id: analyze
        run: |
          echo "📊 Analyzing request type from issue content..."
          
          # Save issue body to a file to avoid shell interpretation issues
          echo '${{ steps.extract.outputs.issue_body }}' > /tmp/issue_body.txt
          
          REQUEST_TYPE="unknown"
          
          # Determine request type based on content
          if grep -i "video" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="video-generation"
          elif grep -i "image" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="image-generation"
          elif grep -i "audio\|music" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="audio-generation"
          elif grep -i "data\|analysis" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="data-analysis"
          elif grep -i "blog\|article" /tmp/issue_body.txt > /dev/null; then
            REQUEST_TYPE="content-creation"
          fi
          
          echo "request_type=$REQUEST_TYPE" >> $GITHUB_OUTPUT
          echo "🎯 Request type identified: $REQUEST_TYPE"

  # ===========================================
  # PHASE 2: ULTRA-DETAILED TASK DECOMPOSITION
  # ===========================================
  
  ultra-task-decomposition:
    name: "🧠 Ultra-Detailed Task Decomposition"
    runs-on: ubuntu-latest
    needs: validate-trigger
    outputs:
      decomposed_tasks: ${{ steps.decompose.outputs.decomposed_tasks }}
      task_count: ${{ steps.decompose.outputs.task_count }}
      execution_phases: ${{ steps.decompose.outputs.execution_phases }}
      detected_capabilities: ${{ steps.decompose.outputs.detected_capabilities }}
      orchestrator_used: ${{ steps.decompose.outputs.orchestrator_used }}
      orchestrator_sources: ${{ steps.decompose.outputs.orchestrator_sources }}
      job_sequence: ${{ steps.decompose.outputs.job_sequence }}
      mermaid_diagram: ${{ steps.decompose.outputs.mermaid_diagram }}
      fine_grained_tasks: ${{ steps.decompose.outputs.fine_grained_tasks }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq python3-pip
          pip3 install pyyaml
        
      - name: Perform Ultra-Detailed Task Decomposition
        id: decompose
        run: |
          echo "🧠 Starting ultra-detailed task decomposition..."
          
          # Create project directory
          mkdir -p projects/current-session/{logs,metadata,scripts}
          
          # Save issue body to file
          echo '${{ needs.validate-trigger.outputs.issue_body }}' > /tmp/issue_body_safe.txt
          
          # Issue details
          ISSUE_TITLE="${{ needs.validate-trigger.outputs.issue_title }}"
          ISSUE_NUMBER="${{ needs.validate-trigger.outputs.issue_number }}"
          REQUEST_TYPE="${{ needs.validate-trigger.outputs.request_type }}"
          
          echo "📋 Issue: $ISSUE_TITLE"
          echo "🔢 Number: #$ISSUE_NUMBER"
          echo "📊 Type: $REQUEST_TYPE"
          
          # Dynamic capability detection from issue content
          echo "🔍 Detecting required capabilities..."
          
          CAPABILITIES=""
          
          # Video capabilities
          if grep -qi "動画\|video\|ビデオ" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}video-generation,"
            echo "  ✓ Video generation detected"
          fi
          
          # Image capabilities
          if grep -qi "画像\|image\|写真\|サムネイル" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}image-generation,"
            echo "  ✓ Image generation detected"
          fi
          
          # Audio capabilities
          if grep -qi "音声\|audio\|sound\|BGM\|音楽" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}audio-generation,"
            echo "  ✓ Audio generation detected"
          fi
          
          # Search capabilities
          if grep -qi "検索\|search\|調査\|トレンド" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}web-search,"
            echo "  ✓ Web search detected"
          fi
          
          # Analysis capabilities
          if grep -qi "分析\|analysis\|データ" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}data-analysis,"
            echo "  ✓ Data analysis detected"
          fi
          
          # News capabilities
          if grep -qi "ニュース\|news\|最新" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}news-planning,"
            echo "  ✓ News planning detected"
          fi
          
          # Speech capabilities
          if grep -qi "ナレーション\|speech\|読み上げ" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}text-to-speech,"
            echo "  ✓ Text-to-speech detected"
          fi
          
          # Editing capabilities
          if grep -qi "編集\|editing\|結合" /tmp/issue_body_safe.txt; then
            CAPABILITIES="${CAPABILITIES}video-editing,"
            echo "  ✓ Video editing detected"
          fi
          
          # Remove trailing comma
          CAPABILITIES=$(echo "$CAPABILITIES" | sed 's/,$//')
          
          # Determine complexity
          WORD_COUNT=$(wc -w < /tmp/issue_body_safe.txt)
          if [ "$WORD_COUNT" -gt 200 ]; then
            COMPLEXITY="complex"
            DURATION="45-60 minutes"
          elif [ "$WORD_COUNT" -gt 100 ]; then
            COMPLEXITY="medium"
            DURATION="20-40 minutes"
          else
            COMPLEXITY="simple"
            DURATION="10-20 minutes"
          fi
          
          echo ""
          echo "📊 Analysis Results:"
          echo "  - Capabilities: $CAPABILITIES"
          echo "  - Complexity: $COMPLEXITY"
          echo "  - Duration: $DURATION"
          
          # Copy orchestrator analyzer script
          if [ -f scripts/orchestrator_analyzer.py ]; then
            cp scripts/orchestrator_analyzer.py projects/current-session/scripts/
          fi
          
          # Run orchestrator analysis
          echo "🔍 Running orchestrator analysis..."
          export USER_REQUEST="$ISSUE_TITLE $(</tmp/issue_body_safe.txt)"
          export CAPABILITIES="$CAPABILITIES"
          
          if [ -f projects/current-session/scripts/orchestrator_analyzer.py ]; then
            cd projects/current-session/scripts
            python3 orchestrator_analyzer.py || echo "⚠️ Orchestrator analysis failed, using default logic"
            cd ../../..
            
            # Check if orchestrator analysis succeeded
            if [ -f projects/current-session/metadata/orchestrator_analysis.json ]; then
              echo "✅ Orchestrator analysis completed successfully"
              ORCHESTRATOR_ANALYSIS=$(cat projects/current-session/metadata/orchestrator_analysis.json)
              
              # Extract execution pattern and job count
              EXECUTION_PATTERN=$(echo "$ORCHESTRATOR_ANALYSIS" | python3 -c "import json, sys; print(json.load(sys.stdin).get('execution_pattern', 'sequential'))")
              echo "📊 Recommended execution pattern: $EXECUTION_PATTERN"
            fi
          else
            echo "⚠️ Orchestrator analyzer not found, using keyword-based detection"
          fi
          
          # Try Claude Code SDK for additional analysis (if available)
          if command -v claude &> /dev/null; then
            echo "🤖 Claude CLI is available for enhanced analysis..."
            
            # Create enhanced prompt with orchestrator analysis
            echo "You are the Meta Workflow Generator task decomposition agent." > /tmp/claude_prompt.txt
            echo "Analyze the following issue and orchestrator recommendations to create an optimal workflow." >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Issue: $ISSUE_TITLE" >> /tmp/claude_prompt.txt
            cat /tmp/issue_body_safe.txt >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Detected capabilities: $CAPABILITIES" >> /tmp/claude_prompt.txt
            if [ -f projects/current-session/metadata/orchestrator_analysis.json ]; then
              echo "Orchestrator analysis:" >> /tmp/claude_prompt.txt
              cat projects/current-session/metadata/orchestrator_analysis.json >> /tmp/claude_prompt.txt
            fi
            echo "" >> /tmp/claude_prompt.txt
            echo "IMPORTANT: For complex tasks like 'news-planning', break them down into subtasks:" >> /tmp/claude_prompt.txt
            echo "- content-planning (内容の企画)" >> /tmp/claude_prompt.txt
            echo "- narration-creation (ナレーション作成)" >> /tmp/claude_prompt.txt
            echo "- scene-planning (シーン企画)" >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Output format:" >> /tmp/claude_prompt.txt
            echo "1. Fine-grained task decomposition in JSON" >> /tmp/claude_prompt.txt
            echo "2. Mermaid diagram showing execution flow" >> /tmp/claude_prompt.txt
            echo "" >> /tmp/claude_prompt.txt
            echo "Please provide the optimal job execution order considering dependencies." >> /tmp/claude_prompt.txt
            
            # Try Claude
            CLAUDE_RESPONSE=$(claude -p "$(cat /tmp/claude_prompt.txt)" 2>&1 || echo '')
            
            if [ -n "$CLAUDE_RESPONSE" ]; then
              echo "✅ Claude Code SDK provided enhanced analysis"
              echo "$CLAUDE_RESPONSE" > projects/current-session/metadata/claude_analysis.txt
              
              # Extract fine-grained tasks if available
              if echo "$CLAUDE_RESPONSE" | grep -q "subtasks"; then
                echo "🔍 Fine-grained task decomposition detected"
                FINE_GRAINED_TASKS=$(echo "$CLAUDE_RESPONSE" | grep -A 50 '"subtasks"' || echo '')
                echo "fine_grained_tasks<<EOF" >> $GITHUB_OUTPUT
                echo "$FINE_GRAINED_TASKS" >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              fi
              
              # Extract Mermaid diagram if available
              if echo "$CLAUDE_RESPONSE" | grep -q "graph"; then
                echo "📊 Mermaid diagram detected"
                MERMAID_DIAGRAM=$(echo "$CLAUDE_RESPONSE" | sed -n '/```mermaid/,/```/p' | sed '1d;$d' || echo '')
                echo "mermaid_diagram<<EOF" >> $GITHUB_OUTPUT
                echo "$MERMAID_DIAGRAM" >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              fi
            fi
          else
            echo "ℹ️ Claude CLI not installed, generating basic Mermaid diagram"
            
            # Generate basic Mermaid diagram based on capabilities
            echo "graph TD" > projects/current-session/metadata/mermaid.txt
            echo "    Start[開始]" >> projects/current-session/metadata/mermaid.txt
            
            # Parse capabilities and create diagram
            IFS=',' read -ra CAP_ARRAY <<< "$CAPABILITIES"
            PREV_NODE="Start"
            NODE_COUNT=1
            
            for cap in "${CAP_ARRAY[@]}"; do
              NODE_NAME="Node$NODE_COUNT"
              
              # Create node label based on capability
              case "$cap" in
                "web-search") LABEL="🔍 Web検索" ;;
                "data-analysis") LABEL="📊 データ分析" ;;
                "news-planning") LABEL="📰 ニュース企画\\n├─ 内容企画\\n├─ ナレーション作成\\n└─ シーン構成" ;;
                "image-generation") LABEL="🖼️ 画像生成" ;;
                "audio-generation") LABEL="🎵 音声生成" ;;
                "video-generation") LABEL="🎬 動画生成" ;;
                "video-editing") LABEL="✂️ 動画編集" ;;
                *) LABEL="$cap" ;;
              esac
              
              echo "    $NODE_NAME[$LABEL]" >> projects/current-session/metadata/mermaid.txt
              echo "    $PREV_NODE --> $NODE_NAME" >> projects/current-session/metadata/mermaid.txt
              
              PREV_NODE=$NODE_NAME
              NODE_COUNT=$((NODE_COUNT + 1))
            done
            
            echo "    $PREV_NODE --> End[完了]" >> projects/current-session/metadata/mermaid.txt
            
            # Save as output
            MERMAID_CONTENT=$(cat projects/current-session/metadata/mermaid.txt)
            echo "mermaid_diagram<<EOF" >> $GITHUB_OUTPUT
            echo "$MERMAID_CONTENT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi
          
          # Generate workflow metadata
          mkdir -p projects/current-session/metadata
          
          # Export for Python script
          export CAPABILITIES="$CAPABILITIES"
          export COMPLEXITY="$COMPLEXITY"
          export REQUIREMENTS="General workflow request"
          
          # Use optimized workflow generator
          if [ -f scripts/generate_optimized_workflow.py ]; then
            cp scripts/generate_optimized_workflow.py projects/current-session/scripts/
            cd projects/current-session/scripts
            python3 generate_optimized_workflow.py
            cd ../../..
          elif [ -f scripts/generate_dynamic_workflow.py ]; then
            cp scripts/generate_dynamic_workflow.py projects/current-session/scripts/
            cd projects/current-session/scripts
            python3 generate_dynamic_workflow.py
            cd ../../..
          else
            # Fallback: create workflow JSON directly
            echo '{' > projects/current-session/metadata/dynamic_workflow.json
            echo '  "metadata": {' >> projects/current-session/metadata/dynamic_workflow.json
            echo "    \"generated_at\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"," >> projects/current-session/metadata/dynamic_workflow.json
            echo "    \"complexity\": \"$COMPLEXITY\"," >> projects/current-session/metadata/dynamic_workflow.json
            echo "    \"total_units\": $(echo \"$CAPABILITIES\" | tr ',' '\n' | wc -l)," >> projects/current-session/metadata/dynamic_workflow.json
            CAPS_JSON=$(echo "$CAPABILITIES" | sed 's/,/","/g' | sed 's/^/"/' | sed 's/$/"/' || echo '')
            echo "    \"capabilities_detected\": [$CAPS_JSON]" >> projects/current-session/metadata/dynamic_workflow.json
            echo '  },' >> projects/current-session/metadata/dynamic_workflow.json
            echo '  "minimal_units": [' >> projects/current-session/metadata/dynamic_workflow.json
            
            # Add units based on capabilities
            FIRST=true
            for cap in $(echo "$CAPABILITIES" | tr ',' ' '); do
              [ "$FIRST" = true ] && FIRST=false || echo "," >> projects/current-session/metadata/dynamic_workflow.json
              
              case $cap in
                "web-search")
                  UNIT_PATH="minimal-units/planning/web-search.yml"
                  ;;
                "news-planning")
                  UNIT_PATH="minimal-units/planning/news-planning.yml"
                  ;;
                "image-generation")
                  UNIT_PATH="minimal-units/media/image/t2i-imagen3.yml"
                  ;;
                "video-generation")
                  UNIT_PATH="minimal-units/media/video/t2v-veo3.yml"
                  ;;
                "audio-generation")
                  UNIT_PATH="minimal-units/media/audio/bgm-generate-mcp.yml"
                  ;;
                "text-to-speech")
                  UNIT_PATH="minimal-units/media/audio/t2s-minimax-turbo-mcp.yml"
                  ;;
                "video-editing")
                  UNIT_PATH="minimal-units/postprod/video-concat.yml"
                  ;;
                "data-analysis")
                  UNIT_PATH="minimal-units/planning/data-analysis.yml"
                  ;;
                *)
                  UNIT_PATH="minimal-units/planning/web-search.yml"
                  ;;
              esac
              
              echo '    {' >> projects/current-session/metadata/dynamic_workflow.json
              echo "      \"capability\": \"$cap\"," >> projects/current-session/metadata/dynamic_workflow.json
              echo "      \"unit_path\": \"$UNIT_PATH\"," >> projects/current-session/metadata/dynamic_workflow.json
              echo '      "estimated_time": "3-5 minutes"' >> projects/current-session/metadata/dynamic_workflow.json
              echo -n '    }' >> projects/current-session/metadata/dynamic_workflow.json
            done
            
            echo '' >> projects/current-session/metadata/dynamic_workflow.json
            echo '  ],' >> projects/current-session/metadata/dynamic_workflow.json
            EXEC_PATTERN=$( [ "$COMPLEXITY" = "simple" ] && echo "sequential" || echo "mixed_parallel" )
            echo "  \"execution_pattern\": \"$EXEC_PATTERN\"" >> projects/current-session/metadata/dynamic_workflow.json
            echo '}' >> projects/current-session/metadata/dynamic_workflow.json
          fi
          
          # Generate fine-grained task decomposition for complex tasks
          echo '{}' > projects/current-session/metadata/fine_grained_tasks.json
          
          # Check for complex tasks that need decomposition
          if echo "$CAPABILITIES" | grep -q "news-planning"; then
            echo "🔍 Decomposing news-planning into subtasks..."
            
            # Create fine-grained decomposition
            echo '{' > projects/current-session/metadata/fine_grained_tasks.json
            echo '  "news-planning": {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '    "subtasks": [' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "name": "content-planning",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "description": "ニュース内容の企画",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "unit": "minimal-units/planning/content-planning.yml",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "duration": "5-10 minutes"' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      },' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "name": "narration-creation",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "description": "ナレーション原稿作成",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "unit": "minimal-units/planning/narration-creation.yml",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "duration": "10-15 minutes"' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      },' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      {' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "name": "scene-planning",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "description": "シーン構成の企画",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "unit": "minimal-units/planning/scene-planning.yml",' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '        "duration": "5-10 minutes"' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '      }' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '    ]' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '  }' >> projects/current-session/metadata/fine_grained_tasks.json
            echo '}' >> projects/current-session/metadata/fine_grained_tasks.json
          fi
          
          # Validate and output results
          if [ -f projects/current-session/metadata/dynamic_workflow.json ]; then
            UNIT_COUNT=$(jq '.minimal_units | length' projects/current-session/metadata/dynamic_workflow.json)
            EXECUTION_PATTERN=$(jq -r '.execution_pattern' projects/current-session/metadata/dynamic_workflow.json)
            
            echo "decomposed_tasks=$(cat projects/current-session/metadata/dynamic_workflow.json | jq -c .)" >> $GITHUB_OUTPUT
            echo "task_count=$UNIT_COUNT" >> $GITHUB_OUTPUT
            echo "execution_phases=$EXECUTION_PATTERN" >> $GITHUB_OUTPUT
            
            # Extract additional information for summary
            DETECTED_CAPS=$(jq -r '.metadata.capabilities_detected | join(", ")' projects/current-session/metadata/dynamic_workflow.json)
            echo "detected_capabilities=$DETECTED_CAPS" >> $GITHUB_OUTPUT
            
            # Check if orchestrator was used
            if [ -f projects/current-session/metadata/orchestrator_analysis.json ]; then
              ORCH_USED=$(jq -r '.analysis.orchestrators | length > 0' projects/current-session/metadata/orchestrator_analysis.json)
              ORCH_SOURCES=$(jq -r '.analysis.orchestrators[].name' projects/current-session/metadata/orchestrator_analysis.json | head -3 | tr '\n' ',' | sed 's/,$//')
              echo "orchestrator_used=$ORCH_USED" >> $GITHUB_OUTPUT
              echo "orchestrator_sources=$ORCH_SOURCES" >> $GITHUB_OUTPUT
            else
              echo "orchestrator_used=false" >> $GITHUB_OUTPUT
              echo "orchestrator_sources=none" >> $GITHUB_OUTPUT
            fi
            
            # Export fine-grained tasks if available
            if [ -f projects/current-session/metadata/fine_grained_tasks.json ] && [ -s projects/current-session/metadata/fine_grained_tasks.json ]; then
              FINE_GRAINED=$(cat projects/current-session/metadata/fine_grained_tasks.json)
              if [ "$FINE_GRAINED" != "{}" ]; then
                echo "fine_grained_tasks<<EOF" >> $GITHUB_OUTPUT
                echo "$FINE_GRAINED" >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              fi
            fi
            
            # Extract job sequence
            JOB_SEQUENCE=$(jq -r '.minimal_units[].capability' projects/current-session/metadata/dynamic_workflow.json | tr '\n' ' → ' | sed 's/ → $//')
            echo "job_sequence=$JOB_SEQUENCE" >> $GITHUB_OUTPUT
            
            echo ""
            echo "✅ Dynamic workflow generated with $UNIT_COUNT minimal units"
            echo "📋 Execution pattern: $EXECUTION_PATTERN"
          else
            echo "❌ Dynamic workflow generation failed"
            exit 1
          fi

  # ===========================================
  # PHASE 3: DYNAMIC WORKFLOW GENERATION  
  # ===========================================
  
  dynamic-workflow-generation:
    name: "🚀 Dynamic Workflow Generation"
    runs-on: ubuntu-latest
    needs: [validate-trigger, ultra-task-decomposition]
    outputs:
      generated_workflow: ${{ steps.generation.outputs.generated_workflow }}
      workflow_path: ${{ steps.generation.outputs.workflow_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Generate Dynamic Workflow
        id: generation
        run: |
          echo "🚀 Generating complete executable workflow..."
          
          # Create necessary directories
          mkdir -p projects/current-session/{metadata,generated-workflows}
          
          # Restore workflow metadata from job outputs
          echo '${{ needs.ultra-task-decomposition.outputs.decomposed_tasks }}' > projects/current-session/metadata/dynamic_workflow.json
          
          # Read workflow metadata
          WORKFLOW_DATA=$(cat projects/current-session/metadata/dynamic_workflow.json)
          EXECUTION_PATTERN=$(echo "$WORKFLOW_DATA" | jq -r '.execution_pattern')
          UNIT_COUNT=$(echo "$WORKFLOW_DATA" | jq '.minimal_units | length')
          
          echo "📊 Generating workflow with $UNIT_COUNT units"
          echo "🔄 Execution pattern: $EXECUTION_PATTERN"
          
          # Generate GitHub Actions workflow YAML
          WORKFLOW_FILE="projects/current-session/generated-workflows/dynamic-workflow-${{ inputs.issue_number }}.yml"
          
          # Create workflow header
          echo 'name: "🎯 Dynamic Workflow - Issue #${{ github.event.inputs.issue_number }}"' > "$WORKFLOW_FILE"
          echo 'run-name: "📊 Dynamic | ${{ github.actor }} | Issue #${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'on:' >> "$WORKFLOW_FILE"
          echo '  workflow_dispatch:' >> "$WORKFLOW_FILE"
          echo '    inputs:' >> "$WORKFLOW_FILE"
          echo '      issue_number:' >> "$WORKFLOW_FILE"
          echo '        description: "Source issue number"' >> "$WORKFLOW_FILE"
          echo '        required: true' >> "$WORKFLOW_FILE"
          echo '        default: "${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'permissions:' >> "$WORKFLOW_FILE"
          echo '  contents: write' >> "$WORKFLOW_FILE"
          echo '  actions: write' >> "$WORKFLOW_FILE"
          echo '  issues: write' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'env:' >> "$WORKFLOW_FILE"
          echo '  CLAUDE_CODE_CI_MODE: true' >> "$WORKFLOW_FILE"
          echo '  CLAUDE_CODE_AUTO_APPROVE_MCP: true' >> "$WORKFLOW_FILE"
          echo '  PROJECT_BASE: "projects/issue-${{ github.event.inputs.issue_number }}"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          echo 'jobs:' >> "$WORKFLOW_FILE"
          
          # Add initialization job
          echo '  initialize:' >> "$WORKFLOW_FILE"
          echo '    name: "🚀 Initialize Workflow"' >> "$WORKFLOW_FILE"
          echo '    runs-on: ubuntu-latest' >> "$WORKFLOW_FILE"
          echo '    outputs:' >> "$WORKFLOW_FILE"
          echo '      project_dir: ${{ steps.setup.outputs.project_dir }}' >> "$WORKFLOW_FILE"
          echo '    steps:' >> "$WORKFLOW_FILE"
          echo '      - name: Checkout Repository' >> "$WORKFLOW_FILE"
          echo '        uses: actions/checkout@v4' >> "$WORKFLOW_FILE"
          echo '        ' >> "$WORKFLOW_FILE"
          echo '      - name: Setup Project Directory' >> "$WORKFLOW_FILE"
          echo '        id: setup' >> "$WORKFLOW_FILE"
          echo '        run: |' >> "$WORKFLOW_FILE"
          echo '          PROJECT_DIR="${{ env.PROJECT_BASE }}"' >> "$WORKFLOW_FILE"
          echo '          mkdir -p "$PROJECT_DIR"/{logs,metadata,temp,final}' >> "$WORKFLOW_FILE"
          echo '          echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT' >> "$WORKFLOW_FILE"
          echo '          echo "✅ Project directory initialized: $PROJECT_DIR"' >> "$WORKFLOW_FILE"
          echo '' >> "$WORKFLOW_FILE"
          
          # Add jobs based on execution phases
          JOB_NUMBER=1
          PREVIOUS_JOB="initialize"
          PHASE_JOBS=""
          
          # Check if we have execution phases
          HAS_PHASES=$(echo "$WORKFLOW_DATA" | jq -r '.metadata.execution_phases // null')
          
          if [ "$HAS_PHASES" != "null" ]; then
            # Process by phases for optimized execution
            echo "$WORKFLOW_DATA" | jq -c '.metadata.execution_phases[]' | while read -r phase; do
              PHASE_NAME=$(echo "$phase" | jq -r '.name')
              IS_PARALLEL=$(echo "$phase" | jq -r '.parallel')
              
              echo "# Phase: $PHASE_NAME (parallel: $IS_PARALLEL)" >> "$WORKFLOW_FILE"
              
              PHASE_FIRST_JOB=""
              PHASE_JOB_NAMES=""
              
              echo "$phase" | jq -c '.jobs[]' | while read -r job; do
                CAPABILITY=$(echo "$job" | jq -r '.capability')
                UNIT_PATH=$(echo "$job" | jq -r '.unit_path')
                
                # Generate safe job name
                JOB_NAME="job_${JOB_NUMBER}_$(echo "$CAPABILITY" | tr '-' '_')"
                
                if [ -z "$PHASE_FIRST_JOB" ]; then
                  PHASE_FIRST_JOB="$JOB_NAME"
                fi
                PHASE_JOB_NAMES="${PHASE_JOB_NAMES}${JOB_NAME},"
                
                echo "  $JOB_NAME:" >> "$WORKFLOW_FILE"
                echo "    name: \"📦 Execute: $CAPABILITY\"" >> "$WORKFLOW_FILE"
                echo "    runs-on: ubuntu-latest" >> "$WORKFLOW_FILE"
                
                # Set dependencies based on parallel execution
                if [ "$IS_PARALLEL" = "true" ]; then
                  echo "    needs: $PREVIOUS_JOB" >> "$WORKFLOW_FILE"
                else
                  if [ "$JOB_NAME" = "$PHASE_FIRST_JOB" ]; then
                    echo "    needs: $PREVIOUS_JOB" >> "$WORKFLOW_FILE"
                  else
                    PREV_JOB_NAME="job_$((JOB_NUMBER - 1))_$(echo "$CAPABILITY" | tr '-' '_')"
                    echo "    needs: $PREV_JOB_NAME" >> "$WORKFLOW_FILE"
                  fi
                fi
                
                echo "    steps:" >> "$WORKFLOW_FILE"
                echo "      - name: Checkout Repository" >> "$WORKFLOW_FILE"
                echo "        uses: actions/checkout@v4" >> "$WORKFLOW_FILE"
                echo "        " >> "$WORKFLOW_FILE"
                echo "      - name: Execute $CAPABILITY" >> "$WORKFLOW_FILE"
                echo "        run: |" >> "$WORKFLOW_FILE"
                echo "          echo \"🔧 Executing minimal unit: $CAPABILITY\"" >> "$WORKFLOW_FILE"
                echo "          echo \"📂 Unit path: $UNIT_PATH\"" >> "$WORKFLOW_FILE"
                echo "          " >> "$WORKFLOW_FILE"
                echo "          # Here you would include the actual minimal unit" >> "$WORKFLOW_FILE"
                echo "          # For now, we'll simulate execution" >> "$WORKFLOW_FILE"
                echo "          echo \"✅ $CAPABILITY completed successfully\"" >> "$WORKFLOW_FILE"
                echo "          " >> "$WORKFLOW_FILE"
                echo "          # Save output" >> "$WORKFLOW_FILE"
                echo "          mkdir -p \\\${{ env.PROJECT_BASE }}/outputs" >> "$WORKFLOW_FILE"
                echo "          echo \"Output from $CAPABILITY\" > \\\${{ env.PROJECT_BASE }}/outputs/${JOB_NUMBER}_$CAPABILITY.txt" >> "$WORKFLOW_FILE"
                echo "" >> "$WORKFLOW_FILE"
                
                JOB_NUMBER=$((JOB_NUMBER + 1))
              done
              
              # Update previous job for next phase
              if [ "$IS_PARALLEL" = "true" ]; then
                # All jobs in parallel phase become dependencies for next phase
                PREVIOUS_JOB="[${PHASE_JOB_NAMES%,}]"
              else
                # Last job in sequential phase
                PREVIOUS_JOB="job_$((JOB_NUMBER - 1))_*"
              fi
            done
          else
            # Fallback to simple sequential execution
            echo "$WORKFLOW_DATA" | jq -c '.minimal_units[]' | while read -r unit; do
              CAPABILITY=$(echo "$unit" | jq -r '.capability')
              UNIT_PATH=$(echo "$unit" | jq -r '.unit_path')
              
              # Generate safe job name
              JOB_NAME="job_${JOB_NUMBER}_$(echo "$CAPABILITY" | tr '-' '_')"
              
              echo "  $JOB_NAME:" >> "$WORKFLOW_FILE"
              echo "    name: \"📦 Execute: $CAPABILITY\"" >> "$WORKFLOW_FILE"
              echo "    runs-on: ubuntu-latest" >> "$WORKFLOW_FILE"
              echo "    needs: $PREVIOUS_JOB" >> "$WORKFLOW_FILE"
              echo "    steps:" >> "$WORKFLOW_FILE"
              echo "      - name: Checkout Repository" >> "$WORKFLOW_FILE"
              echo "        uses: actions/checkout@v4" >> "$WORKFLOW_FILE"
              echo "        " >> "$WORKFLOW_FILE"
              echo "      - name: Execute $CAPABILITY" >> "$WORKFLOW_FILE"
              echo "        run: |" >> "$WORKFLOW_FILE"
              echo "          echo \"🔧 Executing minimal unit: $CAPABILITY\"" >> "$WORKFLOW_FILE"
              echo "          echo \"📂 Unit path: $UNIT_PATH\"" >> "$WORKFLOW_FILE"
              echo "          " >> "$WORKFLOW_FILE"
              echo "          # Here you would include the actual minimal unit" >> "$WORKFLOW_FILE"
              echo "          # For now, we'll simulate execution" >> "$WORKFLOW_FILE"
              echo "          echo \"✅ $CAPABILITY completed successfully\"" >> "$WORKFLOW_FILE"
              echo "          " >> "$WORKFLOW_FILE"
              echo "          # Save output" >> "$WORKFLOW_FILE"
              echo "          mkdir -p \\\${{ env.PROJECT_BASE }}/outputs" >> "$WORKFLOW_FILE"
              echo "          echo \"Output from $CAPABILITY\" > \\\${{ env.PROJECT_BASE }}/outputs/${JOB_NUMBER}_$CAPABILITY.txt" >> "$WORKFLOW_FILE"
              echo "" >> "$WORKFLOW_FILE"
              
              PREVIOUS_JOB="$JOB_NAME"
              JOB_NUMBER=$((JOB_NUMBER + 1))
            done
          fi
          
          # Add finalization job
          echo '  finalize:' >> "$WORKFLOW_FILE"
          echo '    name: "🎉 Finalize Workflow"' >> "$WORKFLOW_FILE"
          echo '    runs-on: ubuntu-latest' >> "$WORKFLOW_FILE"
          echo '    needs: [initialize]' >> "$WORKFLOW_FILE"
          echo '    if: always()' >> "$WORKFLOW_FILE"
          echo '    steps:' >> "$WORKFLOW_FILE"
          echo '      - name: Checkout Repository' >> "$WORKFLOW_FILE"
          echo '        uses: actions/checkout@v4' >> "$WORKFLOW_FILE"
          echo '        ' >> "$WORKFLOW_FILE"
          echo '      - name: Generate Summary' >> "$WORKFLOW_FILE"
          echo '        run: |' >> "$WORKFLOW_FILE"
          echo '          echo "## 📊 Workflow Execution Summary" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Issue**: #${{ github.event.inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Project**: ${{ env.PROJECT_BASE }}" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "- **Status**: Completed" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          echo '          echo "✅ Dynamic workflow execution completed!" >> $GITHUB_STEP_SUMMARY' >> "$WORKFLOW_FILE"
          
          # Output workflow information
          WORKFLOW_PATH="$WORKFLOW_FILE"
          echo "workflow_path=$WORKFLOW_PATH" >> $GITHUB_OUTPUT
          
          # Encode workflow for output
          if [ -f "$WORKFLOW_PATH" ]; then
            ENCODED_WORKFLOW=$(base64 -w 0 "$WORKFLOW_PATH" 2>/dev/null || base64 "$WORKFLOW_PATH")
            echo "generated_workflow=$ENCODED_WORKFLOW" >> $GITHUB_OUTPUT
            echo "✅ Dynamic workflow YAML generated successfully"
            echo "📁 Path: $WORKFLOW_PATH"
          else
            echo "❌ Failed to generate workflow file"
            exit 1
          fi

  # ===========================================
  # PHASE 4: WORKFLOW DEPLOYMENT
  # ===========================================
  
  deploy-workflow:
    name: "🚀 Deploy Generated Workflow"
    runs-on: ubuntu-latest
    needs: [validate-trigger, ultra-task-decomposition, dynamic-workflow-generation]
    outputs:
      deployment_status: ${{ steps.deploy.outputs.deployment_status }}
      deployed_path: ${{ steps.deploy.outputs.deployed_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Deploy Generated Workflow
        id: deploy
        run: |
          echo "🚀 Deploying generated workflow..."
          
          # Create deployment directory
          mkdir -p .github/workflows/generated
          
          # Decode and save workflow
          WORKFLOW_PATH="${{ needs.dynamic-workflow-generation.outputs.workflow_path }}"
          DEPLOYMENT_NAME="issue-${{ inputs.issue_number }}-$(date +%Y%m%d-%H%M%S).yml.disabled"
          DEPLOYMENT_PATH=".github/workflows/generated/$DEPLOYMENT_NAME"
          
          # Restore generated workflow
          echo "${{ needs.dynamic-workflow-generation.outputs.generated_workflow }}" | base64 -d > "$DEPLOYMENT_PATH"
          
          if [ -f "$DEPLOYMENT_PATH" ]; then
            echo "✅ Workflow deployed successfully"
            echo "📁 Deployed to: $DEPLOYMENT_PATH"
            echo "⚠️  Note: Workflow is deployed with .disabled extension for safety"
            
            # Display generated workflow content
            echo ""
            echo "📄 Generated Workflow Content:"
            echo "================================"
            head -50 "$DEPLOYMENT_PATH"
            echo "================================"
            echo "(Showing first 50 lines)"
            echo ""
            echo "To activate the workflow:"
            echo "  1. Review the generated workflow"
            echo "  2. Remove the .disabled extension"
            echo "  3. Commit and push the changes"
            
            # Commit the generated workflow
            git config --global user.name "github-actions[bot]"
            git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git add "$DEPLOYMENT_PATH"
            git commit -m "🤖 Generated workflow for Issue #${{ inputs.issue_number }} - Meta Workflow v10 with dynamic capability detection" || echo "No changes to commit"
            
            git push origin main || echo "Push failed - may need permissions"
            
            echo "deployment_status=success" >> $GITHUB_OUTPUT
            echo "deployed_path=$DEPLOYMENT_PATH" >> $GITHUB_OUTPUT
            
            # Create deployment summary
            echo "## 🚀 Workflow Deployment Summary" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- **Status**: ✅ Success" >> $GITHUB_STEP_SUMMARY
            echo "- **Issue**: #${{ inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Deployed Path**: \`$DEPLOYMENT_PATH\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Activation**: Remove \`.disabled\` extension to activate" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Generated Workflow Details:" >> $GITHUB_STEP_SUMMARY
            echo "- **Units**: ${{ needs.ultra-task-decomposition.outputs.task_count }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Pattern**: ${{ needs.ultra-task-decomposition.outputs.execution_phases }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Deployment failed"
            echo "deployment_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

  # ===========================================
  # PHASE 5: EXECUTION SUMMARY
  # ===========================================
  
  execution-summary:
    name: "📊 Execution Summary"
    runs-on: ubuntu-latest  
    needs: [validate-trigger, ultra-task-decomposition, dynamic-workflow-generation, deploy-workflow]
    if: always()
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Generate Execution Summary
        run: |
          echo "# 📊 Meta Workflow v10 実行結果レポート" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## 📋 リクエスト情報" >> $GITHUB_STEP_SUMMARY
          echo "- **Issue番号**: #${{ inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- **タイトル**: ${{ needs.validate-trigger.outputs.issue_title }}" >> $GITHUB_STEP_SUMMARY
          echo "- **検出されたタイプ**: ${{ needs.validate-trigger.outputs.request_type }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## 🔍 タスク分解結果" >> $GITHUB_STEP_SUMMARY
          echo "### 検出された能力" >> $GITHUB_STEP_SUMMARY
          echo "${{ needs.ultra-task-decomposition.outputs.detected_capabilities }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 📚 参考にしたオーケストレーター" >> $GITHUB_STEP_SUMMARY
          if [ "${{ needs.ultra-task-decomposition.outputs.orchestrator_used }}" = "true" ]; then
            echo "以下のオーケストレーターパターンを参考に最適化しました：" >> $GITHUB_STEP_SUMMARY
            echo "- ${{ needs.ultra-task-decomposition.outputs.orchestrator_sources }}" | sed 's/,/\n- /g' >> $GITHUB_STEP_SUMMARY
          else
            echo "既存のオーケストレーターパターンがマッチしなかったため、専門家視点のロジックで構築しました。" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 🔄 ジョブ実行順序" >> $GITHUB_STEP_SUMMARY
          
          # Mermaid図があれば表示
          if [ -n "${{ needs.ultra-task-decomposition.outputs.mermaid_diagram }}" ]; then
            echo "#### 📊 実行フロー図" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`mermaid" >> $GITHUB_STEP_SUMMARY
            echo "${{ needs.ultra-task-decomposition.outputs.mermaid_diagram }}" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "#### 📝 実行順序詳細" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "${{ needs.ultra-task-decomposition.outputs.job_sequence }}" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # 細粒度タスク分解があれば表示
          if [ -n "${{ needs.ultra-task-decomposition.outputs.fine_grained_tasks }}" ]; then
            echo "### 🎯 細粒度タスク分解" >> $GITHUB_STEP_SUMMARY
            echo "複雑なタスクは以下のサブタスクに分解されました：" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            echo "${{ needs.ultra-task-decomposition.outputs.fine_grained_tasks }}" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "## 📊 実行統計" >> $GITHUB_STEP_SUMMARY
          echo "- **総ユニット数**: ${{ needs.ultra-task-decomposition.outputs.task_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **実行パターン**: ${{ needs.ultra-task-decomposition.outputs.execution_phases }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## 🔄 実行フェーズ" >> $GITHUB_STEP_SUMMARY
          echo "| フェーズ | ステータス |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-----------|" >> $GITHUB_STEP_SUMMARY
          echo "| 🔍 Issue検証 | ${{ needs.validate-trigger.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| 🧠 タスク分解 | ${{ needs.ultra-task-decomposition.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| 🚀 ワークフロー生成 | ${{ needs.dynamic-workflow-generation.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| 📦 デプロイ | ${{ needs.deploy-workflow.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.deploy-workflow.outputs.deployment_status }}" = "success" ]; then
            echo "## ✅ 実行結果: 成功" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "動的ワークフローが正常に生成・デプロイされました：" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 📁 生成されたワークフロー" >> $GITHUB_STEP_SUMMARY
            echo "- **保存場所**: \`${{ needs.deploy-workflow.outputs.deployed_path }}\`" >> $GITHUB_STEP_SUMMARY
            echo "- **ステータス**: .disabled拡張子付き（安全のため）" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🚀 アクティベーション方法" >> $GITHUB_STEP_SUMMARY
            echo "1. 生成されたワークフローをレビュー" >> $GITHUB_STEP_SUMMARY
            echo "2. \`.disabled\`拡張子を削除" >> $GITHUB_STEP_SUMMARY
            echo "3. コミット・プッシュして有効化" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ⚠️ 実行結果: 問題検出" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "エラーの詳細はログを確認してください。" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Meta Workflow v10 with Claude SDK & Orchestrator Integration により生成*" >> $GITHUB_STEP_SUMMARY
          echo "*実行時刻: $(date -u '+%Y-%m-%d %H:%M:%S UTC')*" >> $GITHUB_STEP_SUMMARY