name: "ðŸŽ¯ Dynamic Workflow - Issue #62"
run-name: "ðŸ“Š Dynamic | rossy8417 | Issue #62"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: "Source issue number"
        required: true
        default: "62"
      branch_name:
        description: "Working branch name"
        required: false
        default: "issue-62"

permissions:
  contents: write
  actions: write
  issues: write
  pull-requests: write

env:
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  setup:
    name: "ðŸš€ Setup"
    runs-on: ubuntu-latest
    outputs:
      project_dir: ${{ steps.create_structure.outputs.project_dir }}
      timestamp: ${{ steps.create_structure.outputs.timestamp }} 
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Create Project Structure
        id: create_structure
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          PROJECT_DIR="projects/issue-62-$TIMESTAMP"
          mkdir -p "$PROJECT_DIR"/{logs,metadata,temp,final,media}
          echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "âœ… Project structure created: $PROJECT_DIR"
          
          # Debug output
          echo "::notice::PROJECT_DIR=$PROJECT_DIR"
          echo "::notice::TIMESTAMP=$TIMESTAMP"

  planning_1:
    name: "ðŸ“‹ Planning: content-planning"
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      completed: ${{ steps.execute.outputs.completed }}
      plan_path: ${{ steps.execute.outputs.plan_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Claude Code SDK
        run: |
          npm init -y
          npm install @anthropic-ai/claude-code
          # Install additional dependencies for file processing
          npm install js-yaml
      
      - name: Create output directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/metadata"
          echo "âœ… Created metadata directory"
      
      - name: Execute Planning Agent
        id: execute
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
          GH_TOKEN: ${{ github.token }}
        run: |
          # Get issue details
          ISSUE_TITLE=$(gh issue view 62 --json title -q .title)
          ISSUE_BODY=$(gh issue view 62 --json body -q .body)
          
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
          PROMPT="ã‚ãªãŸã¯æ•™è‚²å‹•ç”»åˆ¶ä½œã®å°‚é–€ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã‹ã‚‰æ•™è‚²å‹•ç”»ã®è©³ç´°ãªè¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚
          
          **Issue #62**: $ISSUE_TITLE
          **è©³ç´°**: $ISSUE_BODY
          
          **ã‚¿ã‚¹ã‚¯**:
          1. æ•™è‚²ç”¨AIè§£èª¬å‹•ç”»ã®æ§‹æˆã‚’ä¼ç”»
          2. æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤Žã‚’èª¬æ˜Žã™ã‚‹å†…å®¹ã‚’è¨­è¨ˆ
          3. è¦–è¦šçš„ã«åˆ†ã‹ã‚Šã‚„ã™ã„ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆè‹±èªžï¼‰
          4. ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆï¼ˆæ—¥æœ¬èªžï¼‰
          5. è¨ˆç”»æ›¸ã‚’ã€Œ$PROJECT_DIR/metadata/education-plan.mdã€ã«ä¿å­˜
          
          **æˆæžœç‰©**:
          - education-plan.mdï¼ˆå…¨ä½“è¨ˆç”»ï¼‰
          - scene-prompts.txtï¼ˆã‚·ãƒ¼ãƒ³åˆ¥ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€è‹±èªžï¼‰
          - narration-script.txtï¼ˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŽŸç¨¿ã€æ—¥æœ¬èªžï¼‰"
          
          # Claude Code CLIã®å®Ÿè¡Œ
          npx @anthropic-ai/claude-code \
            -p "$PROMPT" \
            --allowedTools "Read,Write,Edit" \
            --permission-mode "acceptEdits"
          
          # å‡ºåŠ›ã®ç¢ºèª
          if [ -f "$PROJECT_DIR/metadata/education-plan.md" ]; then
            echo "completed=true" >> $GITHUB_OUTPUT
            echo "plan_path=$PROJECT_DIR/metadata/education-plan.md" >> $GITHUB_OUTPUT
            echo "::notice::Planning completed successfully"
          else
            echo "completed=false" >> $GITHUB_OUTPUT
            echo "::error::Planning failed - education-plan.md not found"
          fi


  image_generation:
    name: "ðŸŽ¨ Image Generation"
    runs-on: ubuntu-latest
    needs: [setup, planning_1]
    outputs:
      images_generated: ${{ steps.generate.outputs.count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup MCP Environment
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/media/images"
          echo "âœ… Created images directory"
      
      - name: Generate Educational Images
        id: generate
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Create Node.js script for MCP image generation
          cat > generate_images.js << 'EOF'
          const { ClaudeCode } = require('@anthropic-ai/claude-code');
          const fs = require('fs');
          const path = require('path');
          
          async function generateEducationalImages() {
            const projectDir = process.env.PROJECT_DIR;
            const client = new ClaudeCode();
            
            // Define educational image prompts
            const imagePrompts = [
              "Colorful educational infographic showing the basic concept of machine learning with simple icons and arrows, bright colors, clean design",
              "Visual diagram of neural network architecture with nodes and connections, educational style, vibrant blue and orange colors",
              "Illustrated examples of machine learning applications in daily life - recommendation systems, voice assistants, image recognition",
              "Summary slide with key takeaways about machine learning basics, modern design with icons and bullet points"
            ];
            
            let count = 0;
            for (let i = 0; i < imagePrompts.length; i++) {
              const prompt = imagePrompts[i];
              const outputPath = path.join(projectDir, 'media', 'images', `scene-${i+1}.png`);
              
              try {
                // Use MCP to generate image
                const result = await client.mcp.callTool('mcp__t2i-google-imagen3__imagen_t2i', {
                  prompt: prompt,
                  aspect_ratio: "16:9",
                  num_images: 1,
                  output_directory: path.dirname(outputPath),
                  auto_download: true,
                  auto_open: false
                });
                
                console.log(`âœ… Generated scene-${i+1}.png`);
                count++;
              } catch (error) {
                console.error(`Failed to generate scene-${i+1}:`, error.message);
              }
            }
            
            // Output the count
            fs.writeFileSync(process.env.GITHUB_OUTPUT, `count=${count}\n`, { flag: 'a' });
          }
          
          generateEducationalImages().catch(console.error);
          EOF
          
          # Install dependencies and run
          npm init -y
          npm install @anthropic-ai/claude-code
          PROJECT_DIR="$PROJECT_DIR" node generate_images.js

  text_to_speech:
    name: "ðŸ”Š Text to Speech"
    runs-on: ubuntu-latest
    needs: [setup, planning_1]
    outputs:
      audio_path: ${{ steps.generate.outputs.audio_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Audio Directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/media/audio"
          echo "âœ… Created audio directory"
      
      - name: Generate Narration Audio
        id: generate
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Create Node.js script for TTS generation
          cat > generate_narration.js << 'EOF'
          const { ClaudeCode } = require('@anthropic-ai/claude-code');
          const fs = require('fs');
          const path = require('path');
          
          async function generateNarration() {
            const projectDir = process.env.PROJECT_DIR;
            const client = new ClaudeCode();
            
            // Educational narration script in Japanese
            const narrationText = `
            ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã¯æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤Žã«ã¤ã„ã¦å­¦ã‚“ã§ã„ãã¾ã—ã‚‡ã†ã€‚
            
            æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•çš„ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€
            äºˆæ¸¬ã‚„åˆ¤æ–­ã‚’è¡Œã†æŠ€è¡“ã§ã™ã€‚
            
            èº«è¿‘ãªä¾‹ã§ã¯ã€ãƒ¡ãƒ¼ãƒ«ã®ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€
            å‹•ç”»ã‚µã‚¤ãƒˆã®ãŠã™ã™ã‚æ©Ÿèƒ½ã€éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãªã©ãŒã‚ã‚Šã¾ã™ã€‚
            
            æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬çš„ãªä»•çµ„ã¿ã¯ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦
            ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã•ã›ã‚‹ã“ã¨ã§ã™ã€‚
            
            ä»Šå›žå­¦ã‚“ã ã“ã¨ã‚’æ´»ç”¨ã—ã¦ã€AIã®ä¸–ç•Œã‚’ã•ã‚‰ã«æŽ¢æ±‚ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
            ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚
            `;
            
            try {
              // Use MCP to generate audio
              const result = await client.mcp.callTool('mcp__t2s-fal-minimax-speech-02-turbo__minimax_speech_02_turbo_submit', {
                text: narrationText,
                voice_id: "Wise_Woman",
                language_boost: "Japanese",
                speed: 0.9,
                emotion: "neutral",
                format: "mp3"
              });
              
              // Poll for result
              if (result.request_id) {
                let status = 'processing';
                while (status === 'processing') {
                  await new Promise(resolve => setTimeout(resolve, 3000));
                  const statusResult = await client.mcp.callTool('mcp__t2s-fal-minimax-speech-02-turbo__minimax_speech_02_turbo_status', {
                    request_id: result.request_id
                  });
                  status = statusResult.status;
                }
                
                // Download result
                const audioResult = await client.mcp.callTool('mcp__t2s-fal-minimax-speech-02-turbo__minimax_speech_02_turbo_result', {
                  request_id: result.request_id,
                  output_directory: path.join(projectDir, 'media', 'audio'),
                  filename_prefix: 'narration',
                  auto_open: false
                });
                
                console.log('âœ… Generated narration.mp3');
                fs.writeFileSync(process.env.GITHUB_OUTPUT, `audio_path=${path.join(projectDir, 'media', 'audio', 'narration.mp3')}\n`, { flag: 'a' });
              }
            } catch (error) {
              console.error('Failed to generate narration:', error.message);
              // Create fallback empty file
              fs.writeFileSync(path.join(projectDir, 'media', 'audio', 'narration.mp3'), '');
              fs.writeFileSync(process.env.GITHUB_OUTPUT, `audio_path=${path.join(projectDir, 'media', 'audio', 'narration.mp3')}\n`, { flag: 'a' });
            }
          }
          
          generateNarration().catch(console.error);
          EOF
          
          # Install dependencies and run
          npm init -y
          npm install @anthropic-ai/claude-code
          PROJECT_DIR="$PROJECT_DIR" node generate_narration.js

  video_generation:
    name: "ðŸŽ¬ Video Generation"
    runs-on: ubuntu-latest
    needs: [setup, planning_1, image_generation]
    outputs:
      video_path: ${{ steps.generate.outputs.video_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Video Directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/media/videos"
          echo "âœ… Created videos directory"
      
      - name: Generate Video from Images
        id: generate
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Create Node.js script for video generation
          cat > generate_video.js << 'EOF'
          const { ClaudeCode } = require('@anthropic-ai/claude-code');
          const fs = require('fs');
          const path = require('path');
          
          async function generateVideo() {
            const projectDir = process.env.PROJECT_DIR;
            const client = new ClaudeCode();
            
            try {
              // Use first image as base for I2V generation
              const firstImagePath = path.join(projectDir, 'media', 'images', 'scene-1.png');
              
              // Generate video from image using Hailuo
              const result = await client.mcp.callTool('mcp__i2v-fal-hailuo-02-pro__hailuo_02_submit', {
                image_url: `file://${firstImagePath}`,
                prompt: "Educational video showing machine learning concepts with smooth animations and transitions, clean and professional style",
                prompt_optimizer: true
              });
              
              if (result.request_id) {
                console.log('Video generation started, request_id:', result.request_id);
                
                // Poll for result
                let status = 'processing';
                while (status === 'processing') {
                  await new Promise(resolve => setTimeout(resolve, 5000));
                  const statusResult = await client.mcp.callTool('mcp__i2v-fal-hailuo-02-pro__hailuo_02_status', {
                    request_id: result.request_id
                  });
                  status = statusResult.status;
                  console.log('Status:', status);
                }
                
                // Download result
                const videoResult = await client.mcp.callTool('mcp__i2v-fal-hailuo-02-pro__hailuo_02_result', {
                  request_id: result.request_id,
                  output_directory: path.join(projectDir, 'media', 'videos'),
                  filename: 'base-video.mp4',
                  auto_open: false
                });
                
                console.log('âœ… Generated base-video.mp4');
              }
            } catch (error) {
              console.error('Failed to generate video:', error.message);
              // Fallback: Try text-to-video with Veo3
              try {
                const result = await client.mcp.callTool('mcp__t2v-fal-veo3-fast__veo3_fast_submit', {
                  prompt: "Educational animation about machine learning basics with colorful graphics and smooth transitions",
                  aspect_ratio: "16:9",
                  duration: "8s",
                  generate_audio: false
                });
                
                if (result.request_id) {
                  // Poll and download similar to above
                  console.log('Using Veo3 fallback...');
                }
              } catch (fallbackError) {
                console.error('Fallback also failed:', fallbackError.message);
                // Create empty file
                fs.writeFileSync(path.join(projectDir, 'media', 'videos', 'base-video.mp4'), '');
              }
            }
            
            fs.writeFileSync(process.env.GITHUB_OUTPUT, `video_path=${path.join(projectDir, 'media', 'videos', 'base-video.mp4')}\n`, { flag: 'a' });
          }
          
          generateVideo().catch(console.error);
          EOF
          
          # Install dependencies and run
          npm init -y
          npm install @anthropic-ai/claude-code
          PROJECT_DIR="$PROJECT_DIR" node generate_video.js

  final_assembly:
    name: "ðŸŽ¬ Final Assembly"
    runs-on: ubuntu-latest
    needs: [setup, text_to_speech, video_generation]
    outputs:
      final_video: ${{ steps.assemble.outputs.final_video }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Final Directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/final"
          echo "âœ… Created final directory"
      
      - name: Install FFmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          
      - name: Assemble Final Video
        id: assemble
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Check if video and audio exist
          VIDEO_FILE="$PROJECT_DIR/media/videos/base-video.mp4"
          AUDIO_FILE="$PROJECT_DIR/media/audio/narration.mp3"
          FINAL_VIDEO="$PROJECT_DIR/final/ai-education-video.mp4"
          
          if [ -f "$VIDEO_FILE" ] && [ -f "$AUDIO_FILE" ] && [ -s "$VIDEO_FILE" ] && [ -s "$AUDIO_FILE" ]; then
            echo "Combining video and audio with FFmpeg..."
            ffmpeg -i "$VIDEO_FILE" -i "$AUDIO_FILE" -c:v copy -c:a aac -shortest "$FINAL_VIDEO" || {
              echo "FFmpeg failed, copying video as final output"
              cp "$VIDEO_FILE" "$FINAL_VIDEO"
            }
          elif [ -f "$VIDEO_FILE" ] && [ -s "$VIDEO_FILE" ]; then
            echo "Audio not available, using video only"
            cp "$VIDEO_FILE" "$FINAL_VIDEO"
          else
            echo "Creating placeholder video"
            # Create a simple video with images if base video is empty
            if ls "$PROJECT_DIR/media/images/"*.png 1> /dev/null 2>&1; then
              ffmpeg -framerate 0.5 -pattern_type glob -i "$PROJECT_DIR/media/images/*.png" \
                -c:v libx264 -pix_fmt yuv420p -vf "scale=1280:720" "$FINAL_VIDEO" || {
                echo "Image slideshow failed"
                touch "$FINAL_VIDEO"
              }
            else
              touch "$FINAL_VIDEO"
            fi
          fi
          
          echo "âœ… Created final video: ai-education-video.mp4"
          
          # æˆæžœç‰©ã‚µãƒžãƒªãƒ¼ã‚’ä½œæˆ
          cat > "$PROJECT_DIR/final/summary.md" << EOF
          # æ•™è‚²ç”¨AIè§£èª¬å‹•ç”» - å®Œæˆãƒ¬ãƒãƒ¼ãƒˆ
          
          ## Issue #62: æ•™è‚²ç”¨AIè§£èª¬å‹•ç”»ã®ä½œæˆ - æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤Žã‚’èª¬æ˜Ž
          
          ### ç”Ÿæˆã•ã‚ŒãŸæˆæžœç‰©:
          - æ•™è‚²ç”¨ç”»åƒ: $(ls "$PROJECT_DIR/media/images/"*.png 2>/dev/null | wc -l)æžš
          - ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°: $([ -s "$AUDIO_FILE" ] && echo "1ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ—¥æœ¬èªžï¼‰" || echo "ç”Ÿæˆå¤±æ•—")
          - ãƒ™ãƒ¼ã‚¹å‹•ç”»: $([ -s "$VIDEO_FILE" ] && echo "1æœ¬" || echo "ç”Ÿæˆå¤±æ•—")
          - æœ€çµ‚å‹•ç”»: $([ -s "$FINAL_VIDEO" ] && echo "1æœ¬" || echo "ç”Ÿæˆå¤±æ•—")
          
          ### å‹•ç”»ã®æ§‹æˆ:
          1. ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ30ç§’ï¼‰
          2. æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬æ¦‚å¿µï¼ˆ2åˆ†ï¼‰
          3. å®Ÿä¾‹ã®ç´¹ä»‹ï¼ˆ1åˆ†ï¼‰
          4. ã¾ã¨ã‚ï¼ˆ30ç§’ï¼‰
          
          ### ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:
          - æœ€çµ‚å‹•ç”»: $([ -f "$FINAL_VIDEO" ] && ls -lh "$FINAL_VIDEO" | awk '{print $5}' || echo "N/A")
          
          ### ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: $([ -s "$FINAL_VIDEO" ] && echo "âœ… å®Œæˆ" || echo "âš ï¸ éƒ¨åˆ†çš„å®Œæˆ")
          EOF
          
          echo "final_video=$PROJECT_DIR/final/ai-education-video.mp4" >> $GITHUB_OUTPUT
      
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-education-video-${{ needs.setup.outputs.timestamp }}
          path: ${{ needs.setup.outputs.project_dir }}/

  summary:
    name: "ðŸ“Š Summary"
    runs-on: ubuntu-latest
    if: always()
    needs: [setup, planning_1, image_generation, text_to_speech, video_generation, final_assembly]
    steps:
      - name: Generate Summary
        run: |
          echo "# ðŸŽ¯ æ•™è‚²ç”¨AIè§£èª¬å‹•ç”» ç”Ÿæˆã‚µãƒžãƒªãƒ¼" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Issue #62: æ•™è‚²ç”¨AIè§£èª¬å‹•ç”»ã®ä½œæˆ - æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤Žã‚’èª¬æ˜Ž" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæžœ" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… ä¼ç”»ãƒ»è¨ˆç”»: å®Œäº†" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… ç”»åƒç”Ÿæˆ: ${{ needs.image_generation.outputs.images_generated }}æžš" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… éŸ³å£°ç”Ÿæˆ: å®Œäº†" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… ãƒ“ãƒ‡ã‚ªç”Ÿæˆ: å®Œäº†" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… æœ€çµ‚çµ„ã¿ç«‹ã¦: å®Œäº†" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### æˆæžœç‰©" >> $GITHUB_STEP_SUMMARY
          echo "- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ${{ needs.setup.outputs.project_dir }}" >> $GITHUB_STEP_SUMMARY
          echo "- æœ€çµ‚å‹•ç”»: ${{ needs.final_assembly.outputs.final_video }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: ${{ needs.setup.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
