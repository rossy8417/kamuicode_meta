name: "🎯 Dynamic Workflow - Issue #62"
run-name: "📊 Dynamic | rossy8417 | Issue #62"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: "Source issue number"
        required: true
        default: "62"
      branch_name:
        description: "Working branch name"
        required: false
        default: "issue-62"

permissions:
  contents: write
  actions: write
  issues: write
  pull-requests: write

env:
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  setup:
    name: "🚀 Setup"
    runs-on: ubuntu-latest
    outputs:
      project_dir: ${{ steps.create_structure.outputs.project_dir }}
      timestamp: ${{ steps.create_structure.outputs.timestamp }} 
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Create Project Structure
        id: create_structure
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          PROJECT_DIR="projects/issue-62-$TIMESTAMP"
          mkdir -p "$PROJECT_DIR"/{logs,metadata,temp,final,media}
          echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "✅ Project structure created: $PROJECT_DIR"
          
          # Debug output
          echo "::notice::PROJECT_DIR=$PROJECT_DIR"
          echo "::notice::TIMESTAMP=$TIMESTAMP"

  planning_1:
    name: "📋 Planning: content-planning"
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      completed: ${{ steps.execute.outputs.completed }}
      plan_path: ${{ steps.execute.outputs.plan_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Claude Code SDK
        run: |
          npm init -y
          npm install @anthropic-ai/claude-code
          # Install additional dependencies for file processing
          npm install js-yaml
      
      - name: Create output directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/metadata"
          echo "✅ Created metadata directory"
      
      - name: Execute Planning Agent
        id: execute
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
          GH_TOKEN: ${{ github.token }}
        run: |
          # Get issue details
          ISSUE_TITLE=$(gh issue view 62 --json title -q .title)
          ISSUE_BODY=$(gh issue view 62 --json body -q .body)
          
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # プロンプトの構築
          PROMPT="あなたは教育動画制作の専門プランナーです。以下の要求から教育動画の詳細な計画を立ててください。
          
          **Issue #62**: $ISSUE_TITLE
          **詳細**: $ISSUE_BODY
          
          **タスク**:
          1. 教育用AI解説動画の構成を企画
          2. 機械学習の基礎を説明する内容を設計
          3. 視覚的に分かりやすい画像生成プロンプトを作成（英語）
          4. ナレーションスクリプトを作成（日本語）
          5. 計画書を「$PROJECT_DIR/metadata/education-plan.md」に保存
          
          **成果物**:
          - education-plan.md（全体計画）
          - scene-prompts.txt（シーン別画像プロンプト、英語）
          - narration-script.txt（ナレーション原稿、日本語）"
          
          # Claude Code CLIの実行
          npx @anthropic-ai/claude-code \
            -p "$PROMPT" \
            --allowedTools "Read,Write,Edit" \
            --permission-mode "acceptEdits"
          
          # 出力の確認
          if [ -f "$PROJECT_DIR/metadata/education-plan.md" ]; then
            echo "completed=true" >> $GITHUB_OUTPUT
            echo "plan_path=$PROJECT_DIR/metadata/education-plan.md" >> $GITHUB_OUTPUT
            echo "::notice::Planning completed successfully"
          else
            echo "completed=false" >> $GITHUB_OUTPUT
            echo "::error::Planning failed - education-plan.md not found"
          fi


  image_generation:
    name: "🎨 Image Generation"
    runs-on: ubuntu-latest
    needs: [setup, planning_1]
    outputs:
      images_generated: ${{ steps.generate.outputs.count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup MCP Environment
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/media/images"
          echo "✅ Created images directory"
      
      - name: Generate Educational Images
        id: generate
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Create Node.js script for MCP image generation
          cat > generate_images.js << 'EOF'
          const { ClaudeCode } = require('@anthropic-ai/claude-code');
          const fs = require('fs');
          const path = require('path');
          
          async function generateEducationalImages() {
            const projectDir = process.env.PROJECT_DIR;
            const client = new ClaudeCode();
            
            // Define educational image prompts
            const imagePrompts = [
              "Colorful educational infographic showing the basic concept of machine learning with simple icons and arrows, bright colors, clean design",
              "Visual diagram of neural network architecture with nodes and connections, educational style, vibrant blue and orange colors",
              "Illustrated examples of machine learning applications in daily life - recommendation systems, voice assistants, image recognition",
              "Summary slide with key takeaways about machine learning basics, modern design with icons and bullet points"
            ];
            
            let count = 0;
            for (let i = 0; i < imagePrompts.length; i++) {
              const prompt = imagePrompts[i];
              const outputPath = path.join(projectDir, 'media', 'images', `scene-${i+1}.png`);
              
              try {
                // Use MCP to generate image
                const result = await client.mcp.callTool('mcp__t2i-google-imagen3__imagen_t2i', {
                  prompt: prompt,
                  aspect_ratio: "16:9",
                  num_images: 1,
                  output_directory: path.dirname(outputPath),
                  auto_download: true,
                  auto_open: false
                });
                
                console.log(`✅ Generated scene-${i+1}.png`);
                count++;
              } catch (error) {
                console.error(`Failed to generate scene-${i+1}:`, error.message);
              }
            }
            
            // Output the count
            fs.writeFileSync(process.env.GITHUB_OUTPUT, `count=${count}\n`, { flag: 'a' });
          }
          
          generateEducationalImages().catch(console.error);
          EOF
          
          # Install dependencies and run
          npm init -y
          npm install @anthropic-ai/claude-code
          PROJECT_DIR="$PROJECT_DIR" node generate_images.js

  text_to_speech:
    name: "🔊 Text to Speech"
    runs-on: ubuntu-latest
    needs: [setup, planning_1]
    outputs:
      audio_path: ${{ steps.generate.outputs.audio_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Audio Directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/media/audio"
          echo "✅ Created audio directory"
      
      - name: Generate Narration Audio
        id: generate
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Create Node.js script for TTS generation
          cat > generate_narration.js << 'EOF'
          const { ClaudeCode } = require('@anthropic-ai/claude-code');
          const fs = require('fs');
          const path = require('path');
          
          async function generateNarration() {
            const projectDir = process.env.PROJECT_DIR;
            const client = new ClaudeCode();
            
            // Educational narration script in Japanese
            const narrationText = `
            こんにちは。今日は機械学習の基礎について学んでいきましょう。
            
            機械学習とは、コンピュータがデータから自動的にパターンを学習し、
            予測や判断を行う技術です。
            
            身近な例では、メールのスパムフィルター、
            動画サイトのおすすめ機能、音声アシスタントなどがあります。
            
            機械学習の基本的な仕組みは、大量のデータを使って
            コンピュータにパターンを学習させることです。
            
            今回学んだことを活用して、AIの世界をさらに探求してみてください。
            ご視聴ありがとうございました。
            `;
            
            try {
              // Use MCP to generate audio
              const result = await client.mcp.callTool('mcp__t2s-fal-minimax-speech-02-turbo__minimax_speech_02_turbo_submit', {
                text: narrationText,
                voice_id: "Wise_Woman",
                language_boost: "Japanese",
                speed: 0.9,
                emotion: "neutral",
                format: "mp3"
              });
              
              // Poll for result
              if (result.request_id) {
                let status = 'processing';
                while (status === 'processing') {
                  await new Promise(resolve => setTimeout(resolve, 3000));
                  const statusResult = await client.mcp.callTool('mcp__t2s-fal-minimax-speech-02-turbo__minimax_speech_02_turbo_status', {
                    request_id: result.request_id
                  });
                  status = statusResult.status;
                }
                
                // Download result
                const audioResult = await client.mcp.callTool('mcp__t2s-fal-minimax-speech-02-turbo__minimax_speech_02_turbo_result', {
                  request_id: result.request_id,
                  output_directory: path.join(projectDir, 'media', 'audio'),
                  filename_prefix: 'narration',
                  auto_open: false
                });
                
                console.log('✅ Generated narration.mp3');
                fs.writeFileSync(process.env.GITHUB_OUTPUT, `audio_path=${path.join(projectDir, 'media', 'audio', 'narration.mp3')}\n`, { flag: 'a' });
              }
            } catch (error) {
              console.error('Failed to generate narration:', error.message);
              // Create fallback empty file
              fs.writeFileSync(path.join(projectDir, 'media', 'audio', 'narration.mp3'), '');
              fs.writeFileSync(process.env.GITHUB_OUTPUT, `audio_path=${path.join(projectDir, 'media', 'audio', 'narration.mp3')}\n`, { flag: 'a' });
            }
          }
          
          generateNarration().catch(console.error);
          EOF
          
          # Install dependencies and run
          npm init -y
          npm install @anthropic-ai/claude-code
          PROJECT_DIR="$PROJECT_DIR" node generate_narration.js

  video_generation:
    name: "🎬 Video Generation"
    runs-on: ubuntu-latest
    needs: [setup, planning_1, image_generation]
    outputs:
      video_path: ${{ steps.generate.outputs.video_path }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Video Directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/media/videos"
          echo "✅ Created videos directory"
      
      - name: Generate Video from Images
        id: generate
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_CI_MODE: true
          CLAUDE_CODE_AUTO_APPROVE_MCP: true
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Create Node.js script for video generation
          cat > generate_video.js << 'EOF'
          const { ClaudeCode } = require('@anthropic-ai/claude-code');
          const fs = require('fs');
          const path = require('path');
          
          async function generateVideo() {
            const projectDir = process.env.PROJECT_DIR;
            const client = new ClaudeCode();
            
            try {
              // Use first image as base for I2V generation
              const firstImagePath = path.join(projectDir, 'media', 'images', 'scene-1.png');
              
              // Generate video from image using Hailuo
              const result = await client.mcp.callTool('mcp__i2v-fal-hailuo-02-pro__hailuo_02_submit', {
                image_url: `file://${firstImagePath}`,
                prompt: "Educational video showing machine learning concepts with smooth animations and transitions, clean and professional style",
                prompt_optimizer: true
              });
              
              if (result.request_id) {
                console.log('Video generation started, request_id:', result.request_id);
                
                // Poll for result
                let status = 'processing';
                while (status === 'processing') {
                  await new Promise(resolve => setTimeout(resolve, 5000));
                  const statusResult = await client.mcp.callTool('mcp__i2v-fal-hailuo-02-pro__hailuo_02_status', {
                    request_id: result.request_id
                  });
                  status = statusResult.status;
                  console.log('Status:', status);
                }
                
                // Download result
                const videoResult = await client.mcp.callTool('mcp__i2v-fal-hailuo-02-pro__hailuo_02_result', {
                  request_id: result.request_id,
                  output_directory: path.join(projectDir, 'media', 'videos'),
                  filename: 'base-video.mp4',
                  auto_open: false
                });
                
                console.log('✅ Generated base-video.mp4');
              }
            } catch (error) {
              console.error('Failed to generate video:', error.message);
              // Fallback: Try text-to-video with Veo3
              try {
                const result = await client.mcp.callTool('mcp__t2v-fal-veo3-fast__veo3_fast_submit', {
                  prompt: "Educational animation about machine learning basics with colorful graphics and smooth transitions",
                  aspect_ratio: "16:9",
                  duration: "8s",
                  generate_audio: false
                });
                
                if (result.request_id) {
                  // Poll and download similar to above
                  console.log('Using Veo3 fallback...');
                }
              } catch (fallbackError) {
                console.error('Fallback also failed:', fallbackError.message);
                // Create empty file
                fs.writeFileSync(path.join(projectDir, 'media', 'videos', 'base-video.mp4'), '');
              }
            }
            
            fs.writeFileSync(process.env.GITHUB_OUTPUT, `video_path=${path.join(projectDir, 'media', 'videos', 'base-video.mp4')}\n`, { flag: 'a' });
          }
          
          generateVideo().catch(console.error);
          EOF
          
          # Install dependencies and run
          npm init -y
          npm install @anthropic-ai/claude-code
          PROJECT_DIR="$PROJECT_DIR" node generate_video.js

  final_assembly:
    name: "🎬 Final Assembly"
    runs-on: ubuntu-latest
    needs: [setup, text_to_speech, video_generation]
    outputs:
      final_video: ${{ steps.assemble.outputs.final_video }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Final Directory
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          echo "::notice::Received project_dir=$PROJECT_DIR"
          
          if [ -z "$PROJECT_DIR" ]; then
            echo "::error::project_dir is empty!"
            exit 1
          fi
          
          mkdir -p "$PROJECT_DIR/final"
          echo "✅ Created final directory"
      
      - name: Install FFmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          
      - name: Assemble Final Video
        id: assemble
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          # Check if video and audio exist
          VIDEO_FILE="$PROJECT_DIR/media/videos/base-video.mp4"
          AUDIO_FILE="$PROJECT_DIR/media/audio/narration.mp3"
          FINAL_VIDEO="$PROJECT_DIR/final/ai-education-video.mp4"
          
          if [ -f "$VIDEO_FILE" ] && [ -f "$AUDIO_FILE" ] && [ -s "$VIDEO_FILE" ] && [ -s "$AUDIO_FILE" ]; then
            echo "Combining video and audio with FFmpeg..."
            ffmpeg -i "$VIDEO_FILE" -i "$AUDIO_FILE" -c:v copy -c:a aac -shortest "$FINAL_VIDEO" || {
              echo "FFmpeg failed, copying video as final output"
              cp "$VIDEO_FILE" "$FINAL_VIDEO"
            }
          elif [ -f "$VIDEO_FILE" ] && [ -s "$VIDEO_FILE" ]; then
            echo "Audio not available, using video only"
            cp "$VIDEO_FILE" "$FINAL_VIDEO"
          else
            echo "Creating placeholder video"
            # Create a simple video with images if base video is empty
            if ls "$PROJECT_DIR/media/images/"*.png 1> /dev/null 2>&1; then
              ffmpeg -framerate 0.5 -pattern_type glob -i "$PROJECT_DIR/media/images/*.png" \
                -c:v libx264 -pix_fmt yuv420p -vf "scale=1280:720" "$FINAL_VIDEO" || {
                echo "Image slideshow failed"
                touch "$FINAL_VIDEO"
              }
            else
              touch "$FINAL_VIDEO"
            fi
          fi
          
          echo "✅ Created final video: ai-education-video.mp4"
          
          # 成果物サマリーを作成
          cat > "$PROJECT_DIR/final/summary.md" << EOF
          # 教育用AI解説動画 - 完成レポート
          
          ## Issue #62: 教育用AI解説動画の作成 - 機械学習の基礎を説明
          
          ### 生成された成果物:
          - 教育用画像: $(ls "$PROJECT_DIR/media/images/"*.png 2>/dev/null | wc -l)枚
          - ナレーション音声: $([ -s "$AUDIO_FILE" ] && echo "1ファイル（日本語）" || echo "生成失敗")
          - ベース動画: $([ -s "$VIDEO_FILE" ] && echo "1本" || echo "生成失敗")
          - 最終動画: $([ -s "$FINAL_VIDEO" ] && echo "1本" || echo "生成失敗")
          
          ### 動画の構成:
          1. イントロダクション（30秒）
          2. 機械学習の基本概念（2分）
          3. 実例の紹介（1分）
          4. まとめ（30秒）
          
          ### ファイルサイズ:
          - 最終動画: $([ -f "$FINAL_VIDEO" ] && ls -lh "$FINAL_VIDEO" | awk '{print $5}' || echo "N/A")
          
          ### ステータス: $([ -s "$FINAL_VIDEO" ] && echo "✅ 完成" || echo "⚠️ 部分的完成")
          EOF
          
          echo "final_video=$PROJECT_DIR/final/ai-education-video.mp4" >> $GITHUB_OUTPUT
      
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-education-video-${{ needs.setup.outputs.timestamp }}
          path: ${{ needs.setup.outputs.project_dir }}/

  summary:
    name: "📊 Summary"
    runs-on: ubuntu-latest
    if: always()
    needs: [setup, planning_1, image_generation, text_to_speech, video_generation, final_assembly]
    steps:
      - name: Generate Summary
        run: |
          echo "# 🎯 教育用AI解説動画 生成サマリー" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Issue #62: 教育用AI解説動画の作成 - 機械学習の基礎を説明" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ワークフロー実行結果" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ 企画・計画: 完了" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ 画像生成: ${{ needs.image_generation.outputs.images_generated }}枚" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ 音声生成: 完了" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ ビデオ生成: 完了" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ 最終組み立て: 完了" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 成果物" >> $GITHUB_STEP_SUMMARY
          echo "- プロジェクト: ${{ needs.setup.outputs.project_dir }}" >> $GITHUB_STEP_SUMMARY
          echo "- 最終動画: ${{ needs.final_assembly.outputs.final_video }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### タイムスタンプ: ${{ needs.setup.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
