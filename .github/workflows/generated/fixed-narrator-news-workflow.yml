name: "üì∫ Fixed Narrator News Video Workflow"

on:
  workflow_dispatch:
    inputs:
      topic:
        description: "„Éã„É•„Éº„Çπ„Éà„Éî„ÉÉ„ÇØ"
        required: true
        default: "ÊúÄÊñ∞„ÅÆAIÊäÄË°ìÂãïÂêë"
      narrator_seed:
        description: "„Éä„É¨„Éº„Çø„Éº„ÅÆÂõ∫ÂÆöseedÂÄ§ÔºàÂêå„Åò‰∫∫Áâ©„ÇíÁ∂≠ÊåÅÔºâ"
        required: false
        default: "japanese-female-announcer-2024"
      duration:
        description: "ÂãïÁîª„ÅÆÈï∑„ÅïÔºàÁßíÔºâ"
        required: false
        default: "60"

env:
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  # Phase 1: Setup and Generate Fixed Narrator
  setup-and-narrator:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    outputs:
      project_dir: ${{ steps.setup.outputs.project_dir }}
      narrator_image_path: ${{ steps.narrator.outputs.image_path }}
      scene_count: ${{ steps.calculate.outputs.scene_count }}
      scene_list: ${{ steps.calculate.outputs.scene_list }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup project directory
        id: setup
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          PROJECT_DIR="projects/fixed-narrator-news-${TIMESTAMP}"
          mkdir -p "${PROJECT_DIR}"/{metadata,logs,media/{images,videos,audio},final,temp}
          echo "project_dir=${PROJECT_DIR}" >> $GITHUB_OUTPUT
          echo "‚úÖ Project directory: ${PROJECT_DIR}"

      - name: Calculate scene count
        id: calculate
        run: |
          DURATION="${{ inputs.duration }}"
          SCENE_COUNT=$((DURATION / 5))
          echo "scene_count=${SCENE_COUNT}" >> $GITHUB_OUTPUT
          
          # Generate scene list
          SCENE_LIST="["
          for i in $(seq 1 $SCENE_COUNT); do
            [ $i -gt 1 ] && SCENE_LIST="${SCENE_LIST},"
            SCENE_LIST="${SCENE_LIST}${i}"
          done
          SCENE_LIST="${SCENE_LIST}]"
          echo "scene_list=${SCENE_LIST}" >> $GITHUB_OUTPUT
          echo "‚úÖ Calculated ${SCENE_COUNT} scenes for ${DURATION} seconds"

      - name: Generate fixed Japanese female narrator
        id: narrator
        run: |
          PROJECT_DIR="${{ steps.setup.outputs.project_dir }}"
          SEED="${{ inputs.narrator_seed }}"
          
          # Generate consistent Japanese female news anchor
          NARRATOR_PROMPT="„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Å™Êó•Êú¨‰∫∫Â•≥ÊÄß„Éã„É•„Éº„Çπ„Ç≠„É£„Çπ„Çø„Éº„ÅÆÁîªÂÉè„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

          ÈáçË¶Å„Å™Ë¶Å‰ª∂:
          - Âπ¥ÈΩ¢: 28-35Ê≠≥„ÅÆÁü•ÁöÑ„Å™Êó•Êú¨‰∫∫Â•≥ÊÄß
          - ÊúçË£Ö: „ÉÄ„Éº„ÇØ„Éñ„É´„Éº„Åæ„Åü„ÅØ„Ç∞„É¨„Éº„ÅÆ„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Å™„Ç∏„É£„Ç±„ÉÉ„Éà
          - È´™Âûã: Ê∏ÖÊΩîÊÑü„ÅÆ„ÅÇ„Çã„Ç∑„Éß„Éº„Éà„Éú„Éñ„Åæ„Åü„ÅØ„Çª„Éü„É≠„É≥„Ç∞ÔºàÈªíÈ´™Ôºâ
          - Ë°®ÊÉÖ: Á©è„ÇÑ„Åã„Åß‰ø°È†ºÊÑü„ÅÆ„ÅÇ„ÇãÂæÆÁ¨ë„Åø
          - ËÉåÊôØ: „Éã„É•„Éº„Çπ„Çπ„Çø„Ç∏„Ç™È¢®Ôºà„Åº„Åã„ÅóÊ∞óÂë≥Ôºâ
          - „Éù„Éº„Ç∫: Ê≠£Èù¢Âêë„Åç„ÄÅ„Ç´„É°„É©ÁõÆÁ∑ö
          - „É°„Ç§„ÇØ: „Éä„ÉÅ„É•„É©„É´„ÅßÂìÅ„ÅÆ„ÅÇ„Çã„É°„Ç§„ÇØ
          
          ÊäÄË°ìË¶Å‰ª∂:
          - seedÂÄ§: ${SEED}Ôºà‰∏ÄË≤´ÊÄß„ÅÆ„Åü„ÇÅÂõ∫ÂÆöÔºâ
          - Ëß£ÂÉèÂ∫¶: 1920x1080
          - „Çπ„Çø„Ç§„É´: „Éï„Ç©„Éà„É™„Ç¢„É™„Çπ„ÉÜ„Ç£„ÉÉ„ÇØ„ÄÅÊîæÈÄÅÂìÅË≥™
          
          Âá∫Âäõ„Éï„Ç°„Ç§„É´: japanese_female_narrator.png"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2i-kamui-imagen3__imagen_t2i,Write" \
            --max-turns 20 \
            --permission-mode "acceptEdits" \
            -p "$NARRATOR_PROMPT"

          # Move to project directory
          if [ -f "japanese_female_narrator.png" ]; then
            mv japanese_female_narrator.png "$PROJECT_DIR/media/images/"
            echo "image_path=$PROJECT_DIR/media/images/japanese_female_narrator.png" >> $GITHUB_OUTPUT
            echo "‚úÖ Fixed narrator image generated with seed: ${SEED}"
          else
            echo "‚ùå Failed to generate narrator image"
            exit 1
          fi

      - name: Upload narrator artifact
        uses: actions/upload-artifact@v4
        with:
          name: narrator-image
          path: ${{ steps.setup.outputs.project_dir }}/media/images/japanese_female_narrator.png

  # Phase 2: Information Gathering
  gather-information:
    runs-on: ubuntu-latest
    needs: setup-and-narrator
    timeout-minutes: 8
    outputs:
      script_path: ${{ steps.script.outputs.path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Research and create script
        id: script
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          TOPIC="${{ inputs.topic }}"
          SCENE_COUNT="${{ needs.setup-and-narrator.outputs.scene_count }}"
          
          RESEARCH_PROMPT="„Äå${TOPIC}„Äç„Å´„Å§„ÅÑ„Å¶ÊúÄÊñ∞ÊÉÖÂ†±„ÇíË™øÊüª„Åó„ÄÅ${SCENE_COUNT}„Ç∑„Éº„É≥ÊßãÊàê„ÅÆ60Áßí„Éã„É•„Éº„ÇπÂéüÁ®ø„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

          Ë¶Å‰ª∂:
          1. WebSearch„Çí‰ΩøÁî®„Åó„Å¶ÊúÄÊñ∞ÊÉÖÂ†±„ÇíÂèéÈõÜ
          2. ‰ø°È†º„Åß„Åç„ÇãË§áÊï∞„ÅÆÊÉÖÂ†±Ê∫ê„Åã„Çâ‰∫ãÂÆüÁ¢∫Ë™ç
          3. ÂêÑ„Ç∑„Éº„É≥5Áßí„ÄÅË®à${SCENE_COUNT}„Ç∑„Éº„É≥„ÅÆÊßãÊàê
          4. Êó•Êú¨‰∫∫Â•≥ÊÄß„Ç¢„Éä„Ç¶„É≥„Çµ„Éº„ÅåË™≠„Åø‰∏ä„Åí„ÇãËá™ÁÑ∂„Å™ÂéüÁ®ø
          
          Âá∫ÂäõÂΩ¢Âºè:
          - news_script.json: „Ç∑„Éº„É≥„Åî„Å®„ÅÆÂéüÁ®ø„Å®„Éì„Ç∏„É•„Ç¢„É´ÊåáÁ§∫
          - narration_full.txt: ÂÆåÂÖ®„Å™„Éä„É¨„Éº„Ç∑„Éß„É≥ÂéüÁ®ø
          
          ÂéüÁ®ø„ÅÆ„Éà„Éº„É≥:
          - „Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Åß‰ø°È†ºÊÑü„ÅÆ„ÅÇ„ÇãÂè£Ë™ø
          - ÂàÜ„Åã„Çä„ÇÑ„Åô„ÅèÁ∞°ÊΩî„Å™Ë°®Áèæ
          - Ë¶ñËÅ¥ËÄÖ„Å´ÂØÑ„ÇäÊ∑ª„ÅÜÊ∏©„Åã„Åø„ÅÆ„ÅÇ„ÇãË™û„Çä"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "WebSearch,Write" \
            --max-turns 30 \
            --permission-mode "acceptEdits" \
            -p "$RESEARCH_PROMPT"

          # Move files to project
          mkdir -p "$PROJECT_DIR/metadata"
          [ -f "news_script.json" ] && mv news_script.json "$PROJECT_DIR/metadata/"
          [ -f "narration_full.txt" ] && mv narration_full.txt "$PROJECT_DIR/metadata/"
          
          echo "path=$PROJECT_DIR/metadata/news_script.json" >> $GITHUB_OUTPUT
          echo "‚úÖ Script created for ${SCENE_COUNT} scenes"

      - name: Upload script artifact
        uses: actions/upload-artifact@v4
        with:
          name: news-script
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/metadata/

  # Phase 3: Generate Narration Audio
  generate-narration:
    runs-on: ubuntu-latest
    needs: [setup-and-narrator, gather-information]
    timeout-minutes: 8
    outputs:
      audio_path: ${{ steps.narration.outputs.path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download script
        uses: actions/download-artifact@v4
        with:
          name: news-script
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/metadata/

      - name: Generate narration audio
        id: narration
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          
          # Read narration text
          if [ -f "$PROJECT_DIR/metadata/narration_full.txt" ]; then
            NARRATION_TEXT=$(cat "$PROJECT_DIR/metadata/narration_full.txt")
          else
            NARRATION_TEXT="Êú¨Êó•„ÅÆ„Éã„É•„Éº„Çπ„Çí„Åä‰ºù„Åà„Åó„Åæ„Åô„ÄÇ${{ inputs.topic }}„Å´„Å§„ÅÑ„Å¶„ÄÅÊúÄÊñ∞„ÅÆÊÉÖÂ†±„Çí„Åæ„Å®„ÇÅ„Åæ„Åó„Åü„ÄÇ"
          fi
          
          TTS_PROMPT="‰ª•‰∏ã„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊó•Êú¨‰∫∫Â•≥ÊÄß„Ç¢„Éä„Ç¶„É≥„Çµ„Éº„ÅÆÂ£∞„ÅßË™≠„Åø‰∏ä„Åí„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

          „ÉÜ„Ç≠„Çπ„Éà:
          ${NARRATION_TEXT}
          
          Èü≥Â£∞Ë¶Å‰ª∂:
          - Â£∞Ë≥™: „Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Å™Â•≥ÊÄß„Ç¢„Éä„Ç¶„É≥„Çµ„ÉºÔºàËêΩ„Å°ÁùÄ„ÅÑ„Åü„ÄÅ‰ø°È†ºÊÑü„ÅÆ„ÅÇ„ÇãÂ£∞Ôºâ
          - ÈÄüÂ∫¶: „Éã„É•„Éº„ÇπÁï™ÁµÑ„Å´ÈÅ©„Åó„ÅüÊ®ôÊ∫ñÁöÑ„Å™ÈÄüÂ∫¶
          - ÊäëÊèö: ÈáçË¶ÅÈÉ®ÂàÜ„Åß„ÅÆÈÅ©Âàá„Å™Âº∑Ë™ø
          - ÂÖ®‰Ωì„ÅÆÈï∑„Åï: 60Áßí‰ª•ÂÜÖ
          
          Âá∫Âäõ: narration_audio.mp3"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__t2s-kamui-minimax-speech__minimax_speech_02_turbo_submit,mcp__t2s-kamui-minimax-speech__minimax_speech_02_turbo_status,mcp__t2s-kamui-minimax-speech__minimax_speech_02_turbo_result,Write" \
            --max-turns 40 \
            --permission-mode "acceptEdits" \
            -p "$TTS_PROMPT"

          # Move audio to project
          if [ -f "narration_audio.mp3" ]; then
            mv narration_audio.mp3 "$PROJECT_DIR/media/audio/"
            echo "path=$PROJECT_DIR/media/audio/narration_audio.mp3" >> $GITHUB_OUTPUT
            echo "‚úÖ Narration audio generated"
          else
            echo "‚ùå Failed to generate narration audio"
          fi

      - name: Upload audio artifact
        uses: actions/upload-artifact@v4
        with:
          name: narration-audio
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/media/audio/

  # Phase 4: Generate Scene Videos with Lip-sync
  generate-scenes:
    runs-on: ubuntu-latest
    needs: [setup-and-narrator, gather-information, generate-narration]
    timeout-minutes: 20
    strategy:
      matrix:
        scene: ${{ fromJson(needs.setup-and-narrator.outputs.scene_list) }}
      max-parallel: 6
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/

      - name: Generate scene with lip-sync
        id: scene
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          SCENE_ID="${{ matrix.scene }}"
          NARRATOR_IMAGE="$PROJECT_DIR/narrator-image/japanese_female_narrator.png"
          AUDIO_FILE="$PROJECT_DIR/narration-audio/narration_audio.mp3"
          
          # Calculate time offsets for this scene
          START_TIME=$(( (SCENE_ID - 1) * 5 ))
          END_TIME=$(( SCENE_ID * 5 ))
          
          # Extract audio segment for this scene
          ffmpeg -i "$AUDIO_FILE" -ss ${START_TIME} -t 5 -acodec copy "$PROJECT_DIR/temp/scene_${SCENE_ID}_audio.mp3"
          
          SCENE_PROMPT="„Ç∑„Éº„É≥${SCENE_ID}„ÅÆ„É™„ÉÉ„Éó„Ç∑„É≥„ÇØÂãïÁîª„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

          ÂÖ•Âäõ:
          - „Éä„É¨„Éº„Çø„ÉºÁîªÂÉè: ${NARRATOR_IMAGE}
          - Èü≥Â£∞„Çª„Ç∞„É°„É≥„Éà: $PROJECT_DIR/temp/scene_${SCENE_ID}_audio.mp3
          - ÊôÇÈñì: ${START_TIME}Áßí„Åã„Çâ${END_TIME}ÁßíÔºà5ÁßíÈñìÔºâ
          
          Âá¶ÁêÜË¶Å‰ª∂:
          1. Êó•Êú¨‰∫∫Â•≥ÊÄß„Éä„É¨„Éº„Çø„Éº„ÅÆÁîªÂÉè„Çí‰ΩøÁî®
          2. Èü≥Â£∞„Å´Âêà„Çè„Åõ„ÅüËá™ÁÑ∂„Å™„É™„ÉÉ„Éó„Ç∑„É≥„ÇØ
          3. „Éã„É•„Éº„Çπ„Ç≠„É£„Çπ„Çø„ÉºÈ¢®„ÅÆËªΩÂæÆ„Å™È†≠„ÅÆÂãï„Åç
          4. 5Áßí„ÅÆÂãïÁîª„Å®„Åó„Å¶Âá∫Âäõ
          
          ‰ΩøÁî®„ÉÑ„Éº„É´ÂÑ™ÂÖàÈ†Ü‰Ωç:
          1. mcp__v2v-kamui-pixverse-lipsyncÔºàÊé®Â•®Ôºâ
          2. mcp__v2v-kamui-creatify-lipsyncÔºà‰ª£ÊõøÔºâ
          
          Âá∫Âäõ: scene_${SCENE_ID}_lipsync.mp4"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "mcp__v2v-kamui-pixverse-lipsync__pixverse_lipsync_submit,mcp__v2v-kamui-pixverse-lipsync__pixverse_lipsync_status,mcp__v2v-kamui-pixverse-lipsync__pixverse_lipsync_result,mcp__v2v-kamui-creatify-lipsync__lipsync_submit,mcp__v2v-kamui-creatify-lipsync__lipsync_status,mcp__v2v-kamui-creatify-lipsync__lipsync_result,Write,Read" \
            --max-turns 50 \
            --permission-mode "acceptEdits" \
            -p "$SCENE_PROMPT"

          # Move to project directory
          if [ -f "scene_${SCENE_ID}_lipsync.mp4" ]; then
            mv "scene_${SCENE_ID}_lipsync.mp4" "$PROJECT_DIR/media/videos/"
            echo "‚úÖ Scene ${SCENE_ID} with lip-sync completed"
          else
            echo "‚ö†Ô∏è Scene ${SCENE_ID} generation failed, creating fallback"
            # Fallback: Create simple video from image
            ffmpeg -loop 1 -i "$NARRATOR_IMAGE" -i "$PROJECT_DIR/temp/scene_${SCENE_ID}_audio.mp3" \
              -c:v libx264 -c:a aac -shortest -t 5 \
              "$PROJECT_DIR/media/videos/scene_${SCENE_ID}_lipsync.mp4"
          fi

      - name: Upload scene artifact
        uses: actions/upload-artifact@v4
        with:
          name: scene-${{ matrix.scene }}
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/media/videos/scene_${{ matrix.scene }}_lipsync.mp4

  # Phase 5: Final Composition
  final-composition:
    runs-on: ubuntu-latest
    needs: [setup-and-narrator, generate-scenes]
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all scenes
        uses: actions/download-artifact@v4
        with:
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/

      - name: Compose final video
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          SCENE_COUNT="${{ needs.setup-and-narrator.outputs.scene_count }}"
          
          # Create scene list file for concatenation
          echo "# Scene list for concatenation" > "$PROJECT_DIR/temp/scene_list.txt"
          for i in $(seq 1 $SCENE_COUNT); do
            SCENE_FILE="$PROJECT_DIR/scene-${i}/scene_${i}_lipsync.mp4"
            if [ -f "$SCENE_FILE" ]; then
              echo "file '$SCENE_FILE'" >> "$PROJECT_DIR/temp/scene_list.txt"
            fi
          done
          
          # Concatenate all scenes
          ffmpeg -f concat -safe 0 -i "$PROJECT_DIR/temp/scene_list.txt" \
            -c:v libx264 -c:a aac -movflags +faststart \
            "$PROJECT_DIR/final/news_video_complete.mp4"
          
          # Add news overlay graphics (optional)
          OVERLAY_PROMPT="ÊúÄÁµÇ„Éã„É•„Éº„ÇπÂãïÁîª„Å´„ÉÜ„É≠„ÉÉ„Éó„Å®„Ç∞„É©„Éï„Ç£„ÉÉ„ÇØ„ÇíËøΩÂä†„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

          ÂÖ•ÂäõÂãïÁîª: $PROJECT_DIR/final/news_video_complete.mp4
          
          ËøΩÂä†Ë¶ÅÁ¥†:
          1. „Éã„É•„Éº„ÇπÁï™ÁµÑÈ¢®„ÅÆ„É≠„Ç¥ÔºàÂ∑¶‰∏äÔºâ
          2. „Éà„Éî„ÉÉ„ÇØ„Çø„Ç§„Éà„É´Ôºà‰∏ãÈÉ®„ÉÜ„É≠„ÉÉ„ÉóÔºâ
          3. ÊôÇÂàªË°®Á§∫ÔºàÂè≥‰∏äÔºâ
          
          Âá∫Âäõ: news_video_final.mp4"

          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Read,Write,Bash" \
            --max-turns 20 \
            --permission-mode "acceptEdits" \
            -p "$OVERLAY_PROMPT"

          # Final check
          if [ -f "news_video_final.mp4" ]; then
            mv news_video_final.mp4 "$PROJECT_DIR/final/"
            echo "‚úÖ Final news video created with fixed narrator"
          elif [ -f "$PROJECT_DIR/final/news_video_complete.mp4" ]; then
            echo "‚úÖ Final news video created (without overlays)"
          else
            echo "‚ùå Failed to create final video"
            exit 1
          fi

      - name: Upload final video
        uses: actions/upload-artifact@v4
        with:
          name: final-news-video
          path: ${{ needs.setup-and-narrator.outputs.project_dir }}/final/

      - name: Create summary
        run: |
          PROJECT_DIR="${{ needs.setup-and-narrator.outputs.project_dir }}"
          
          echo "# üì∫ Fixed Narrator News Video Generation Complete" > "$PROJECT_DIR/final/summary.md"
          echo "" >> "$PROJECT_DIR/final/summary.md"
          echo "## Details:" >> "$PROJECT_DIR/final/summary.md"
          echo "- Topic: ${{ inputs.topic }}" >> "$PROJECT_DIR/final/summary.md"
          echo "- Duration: ${{ inputs.duration }} seconds" >> "$PROJECT_DIR/final/summary.md"
          echo "- Narrator: Japanese female announcer (fixed)" >> "$PROJECT_DIR/final/summary.md"
          echo "- Scenes: ${{ needs.setup-and-narrator.outputs.scene_count }}" >> "$PROJECT_DIR/final/summary.md"
          echo "- Timestamp: $(date)" >> "$PROJECT_DIR/final/summary.md"
          echo "" >> "$PROJECT_DIR/final/summary.md"
          echo "## Output Files:" >> "$PROJECT_DIR/final/summary.md"
          ls -la "$PROJECT_DIR/final/" >> "$PROJECT_DIR/final/summary.md"
          
          cat "$PROJECT_DIR/final/summary.md"