name: "Video Content Creation Production V3"
run-name: "🎥 Production V3: ${{ github.event.inputs.video_concept }}"

on:
  workflow_dispatch:
    inputs:
      video_concept:
        description: '動画コンセプト・テーマ'
        required: true
        default: 'AIとロボットが協力する未来の製品紹介動画'
        type: string
      target_audience:
        description: 'ターゲット視聴者'
        required: true
        default: 'professional'
        type: choice
        options:
        - general
        - business
        - young_adult
        - professional
        - creative
      video_length:
        description: '動画尺 (秒)'
        required: true
        default: '30'
        type: choice
        options:
        - '15'
        - '30'
        - '60'
      video_style:
        description: '動画スタイル'
        required: true
        default: 'cinematic'
        type: choice
        options:
        - cinematic
        - commercial
        - documentary
        - educational
        - artistic
      quality_setting:
        description: '画質設定'
        required: true
        default: 'high'
        type: choice
        options:
        - ultra
        - high
        - standard

permissions:
  contents: write
  actions: read

jobs:
  # Phase 1: 初期設定
  setup:
    runs-on: ubuntu-latest
    outputs:
      ready: ${{ steps.check.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Verify MCP config exists
        id: check
        run: |
          echo "🔍 Checking MCP configuration..."
          if [ -f ".claude/mcp-kamuicode.json" ]; then
            echo "✅ MCP config found"
            echo "ready=true" >> $GITHUB_OUTPUT
          else
            echo "❌ MCP config not found"
            exit 1
          fi
          
      - name: Setup directories
        run: |
          mkdir -p generated/{concept,images,audio,video,final}
          
  # Phase 2: コンセプト作成 (Claude Code SDK Node)
  concept-planning:
    needs: setup
    runs-on: ubuntu-latest
    if: needs.setup.outputs.ready == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Install Claude Code CLI
        run: |
          npm install -g @anthropic-ai/claude-code@latest
          
      - name: Create concept with Claude Code SDK
        run: |
          mkdir -p generated/concept
          
          claude -p "Create a detailed video concept plan for: '${{ github.event.inputs.video_concept }}'
          Target audience: ${{ github.event.inputs.target_audience }}
          Duration: ${{ github.event.inputs.video_length }} seconds
          Style: ${{ github.event.inputs.video_style }}
          
          Save the plan to generated/concept/plan.json with:
          - scenes: array of scene descriptions with dialogue/narration
          - prompts: specific prompts for each scene
          - timing: scene durations and transitions
          - dialogue: array of dialogue/narration for each scene
          - audio_cues: background music and sound effects timing
          
          IMPORTANT: 
          - Each scene should have specific dialogue or narration text
          - Include timing for when dialogue should play
          - Consider the total duration of ${{ github.event.inputs.video_length }} seconds
          - Plan smooth transitions between scenes
          - Generate appropriate number of scenes based on duration (roughly 3-5 seconds per scene)" \
          --output-format json
          
          # Verify generated plan
          echo "📋 Generated concept plan:"
          cat generated/concept/plan.json | jq '.'
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          
      - name: Upload concept
        uses: actions/upload-artifact@v4
        with:
          name: concept-${{ github.run_number }}
          path: generated/concept/
          
  # Phase 3: 画像生成
  image-generation:
    needs: concept-planning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download concept
        uses: actions/download-artifact@v4
        with:
          name: concept-${{ github.run_number }}
          path: generated/concept/
          
      - name: Read MCP permissions from settings
        id: mcp_permissions
        run: |
          echo "📖 Reading MCP permissions..."
          # Extract MCP-only settings for GitHub Actions
          FULL_SETTINGS=$(cat .claude/settings.github-actions.json | jq -c .)
          echo "FULL_SETTINGS=$FULL_SETTINGS" >> $GITHUB_OUTPUT
          
      - name: Generate images with MCP
        uses: anthropics/claude-code-base-action@beta
        with:
          prompt: |
            1. Read the concept from generated/concept/plan.json
            2. For each scene, generate an image using t2i-google-imagen3
            3. Use aspect ratio 1:1 (default) and quality: ${{ github.event.inputs.quality_setting }}
            4. IMPORTANT: Download each image IMMEDIATELY to current directory after generation
            5. Save all results to generated/images/results.json with:
               - scene_name
               - prompt_used
               - local_file (downloaded file name) - THIS IS CRITICAL
               - generation_time
            6. DO NOT store URLs in results.json - only local file paths
            7. Verify all image files exist locally before completing
          system_prompt: |
            You are Claude Code in CI/CD with pre-configured MCP permissions.
            IMPORTANT: Always use FULL authenticated URLs for downloads.
          mcp_config: ".claude/mcp-kamuicode.json"
          settings: ${{ steps.mcp_permissions.outputs.FULL_SETTINGS }}
          allowed_tools: "Read,Write,Bash,mcp__t2i-google-imagen3__*"
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          max_turns: "20"
          
      - name: Upload images
        uses: actions/upload-artifact@v4
        with:
          name: images-${{ github.run_number }}
          path: |
            generated/images/
            *.png
            *.jpg
            
  # Phase 4: 音楽生成
  audio-generation:
    needs: concept-planning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download concept
        uses: actions/download-artifact@v4
        with:
          name: concept-${{ github.run_number }}
          path: generated/concept/
          
      - name: Read MCP permissions from settings
        id: mcp_permissions
        run: |
          echo "📖 Reading MCP permissions..."
          # Extract MCP-only settings for GitHub Actions
          FULL_SETTINGS=$(cat .claude/settings.github-actions.json | jq -c .)
          echo "FULL_SETTINGS=$FULL_SETTINGS" >> $GITHUB_OUTPUT
          
      - name: Generate audio assets
        uses: anthropics/claude-code-base-action@beta
        with:
          prompt: |
            1. Read concept from generated/concept/plan.json including dialogue/narration
            2. For each scene with dialogue:
               a. Generate narration/dialogue using t2s-fal-minimax-speech-02-turbo
               b. Use appropriate voice style for the content
               c. Save each audio file as scene_X_dialogue.wav
            3. Generate background music using t2m-google-lyria:
               - Style: ${{ github.event.inputs.video_style }}
               - Duration: ${{ github.event.inputs.video_length }} seconds
               - Save as background_music.wav
            4. Save all audio metadata to generated/audio/audio_assets.json with:
               - dialogue files and their scene mappings
               - background music file
               - timing information for each audio element
          system_prompt: |
            You are Claude Code in CI/CD with pre-configured MCP permissions.
            Generate both dialogue/narration and background music as specified.
          mcp_config: ".claude/mcp-kamuicode.json"
          settings: ${{ steps.mcp_permissions.outputs.FULL_SETTINGS }}
          allowed_tools: "View,mcp__t2m-google-lyria__*,mcp__t2s-fal-minimax-speech-02-turbo__*,Bash,Write,Read"
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          max_turns: "30"
          
      - name: Upload audio
        uses: actions/upload-artifact@v4
        with:
          name: audio-${{ github.run_number }}
          path: |
            generated/audio/
            *.mp3
            *.wav
            
  # Phase 5: 動画生成準備
  video-generation-prep:
    needs: [image-generation, audio-generation]
    runs-on: ubuntu-latest
    outputs:
      scene_count: ${{ steps.count.outputs.scene_count }}
      scene_matrix: ${{ steps.count.outputs.scene_matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download concept
        uses: actions/download-artifact@v4
        with:
          name: concept-${{ github.run_number }}
          path: generated/concept/
          
      - name: Count scenes and create matrix
        id: count
        run: |
          echo "🔍 Analyzing scene count..."
          SCENE_COUNT=$(jq '.scenes | length' generated/concept/plan.json)
          echo "Found $SCENE_COUNT scenes"
          echo "scene_count=$SCENE_COUNT" >> $GITHUB_OUTPUT
          
          # Create matrix for parallel processing
          MATRIX_JSON=$(jq -c '[range(0; .scenes | length) | {scene: (. + 1)}]' generated/concept/plan.json)
          echo "scene_matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT
          echo "Matrix JSON: $MATRIX_JSON"
          
  # Phase 6: 動画生成（動的マトリックス）
  video-generation:
    needs: video-generation-prep
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Timeout for each scene
    strategy:
      matrix:
        scene: ${{ fromJson(needs.video-generation-prep.outputs.scene_matrix) }}
      max-parallel: 1  # Process scenes sequentially to avoid resource conflicts
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download all assets
        uses: actions/download-artifact@v4
        with:
          pattern: "*-${{ github.run_number }}"
          merge-multiple: true
          
      - name: Read MCP permissions from settings
        id: mcp_permissions
        run: |
          echo "📖 Reading MCP permissions..."
          # Extract MCP-only settings for GitHub Actions
          FULL_SETTINGS=$(cat .claude/settings.github-actions.json | jq -c .)
          echo "FULL_SETTINGS=$FULL_SETTINGS" >> $GITHUB_OUTPUT
          
      - name: Generate video for scene ${{ matrix.scene.scene }}
        uses: anthropics/claude-code-base-action@beta
        with:
          prompt: |
            STEPS for scene ${{ matrix.scene.scene }}:
            1. Read generated/images/results.json and find scene ${{ matrix.scene.scene }} info
            2. Find the corresponding PNG file for scene ${{ matrix.scene.scene }}
            3. CRITICAL Base64 conversion steps:
               a. Use bash command: base64 -i <image_file> to convert PNG to base64
               b. Remove ALL newlines/whitespace from base64 output with tr -d '\n\r '
               c. Create proper data URI: "data:image/png;base64," + clean_base64_string
               d. Verify base64 string contains only valid characters [A-Za-z0-9+/=]
            4. Submit to i2v-fal-hailuo-02-pro with validated data URI
            5. Poll hailuo_02_result until COMPLETED status
            6. Download video to scene_${{ matrix.scene.scene }}_video.mp4
            7. Create scene_${{ matrix.scene.scene }}_info.json with metadata
            
            IMPORTANT: Ensure base64 data is clean and properly formatted before MCP submission
          system_prompt: |
            You are Claude Code in CI/CD with pre-configured MCP permissions.
            Generate video clip for scene ${{ matrix.scene.scene }} only.
          mcp_config: ".claude/mcp-kamuicode.json"
          settings: ${{ steps.mcp_permissions.outputs.FULL_SETTINGS }}
          allowed_tools: "Read,Write,Bash,mcp__i2v-fal-hailuo-02-pro__*"
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          max_turns: "25"
          timeout_minutes: 12
          
      - name: Upload scene video
        uses: actions/upload-artifact@v4
        with:
          name: video-scene-${{ matrix.scene.scene }}-${{ github.run_number }}
          path: |
            scene_${{ matrix.scene.scene }}_video.mp4
            generated/video/scene_${{ matrix.scene.scene }}_info.json
            
  # Phase 7: 動画・音声結合 (Claude Code SDK Node)
  video-assembly:
    needs: video-generation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download all assets
        uses: actions/download-artifact@v4
        with:
          pattern: "*-${{ github.run_number }}"
          merge-multiple: true
          
      - name: Install FFmpeg and Claude Code CLI
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          npm install -g @anthropic-ai/claude-code@latest
          ffmpeg -version
          
      - name: Analyze and prepare video files
        run: |
          echo "🎥 Analyzing available video files..."
          mkdir -p videos generated/assembly
          
          # Find all scene video files
          find . -name "scene_*_video.mp4" -type f
          for file in scene_*_video.mp4; do
            if [ -f "$file" ]; then
              echo "Found: $file"
              mv "$file" videos/
            fi
          done
          
          ls -la videos/
          
      - name: Assemble final video with Claude Code SDK
        run: |
          claude -p "You are an expert video editor working with FFmpeg. 
          
          TASK: Create a comprehensive FFmpeg workflow to assemble a final video from multiple scene videos.
          
          CURRENT SITUATION:
          - Scene video files are in the videos/ directory (scene_1_video.mp4, scene_2_video.mp4, etc.)
          - Background music file may be available as background_music.wav
          - Audio dialogue files may be available as scene_*_dialogue.wav
          
          REQUIREMENTS:
          1. Create a bash script that:
             a. Lists all available scene videos in proper order (scene_1, scene_2, etc.)
             b. Creates an FFmpeg concat file for video concatenation
             c. Concatenates all scene videos into one video
             d. Mixes background music and dialogue audio if available
             e. Applies final video optimization (H.264, AAC audio, web-optimized)
             f. Outputs final_video.mp4
          
          2. Handle missing files gracefully (if some scenes are missing)
          3. Use proper FFmpeg flags for web-optimized output
          4. Include error checking and logging
          
          Save the complete bash script as assemble_video.sh and make it executable.
          
          IMPORTANT: Generate a complete, working bash script that I can execute directly." \
          --output-format text
          
          # Make the script executable and run it
          chmod +x assemble_video.sh
          ./assemble_video.sh
          
          echo "✅ Video assembly complete!"
          if [ -f "final_video.mp4" ]; then
            ls -lh final_video.mp4
          else
            echo "❌ final_video.mp4 not found"
            ls -la
          fi
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          
      - name: Upload final video
        uses: actions/upload-artifact@v4
        with:
          name: final-video-${{ github.run_number }}
          path: |
            final_video.mp4
            generated/assembly/
            
  # Phase 7: 最終パッケージ
  final-package:
    needs: video-assembly
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: "*-${{ github.run_number }}"
          merge-multiple: true
          
      - name: Create final package
        run: |
          echo "📦 Creating final package..."
          
          # ディレクトリ作成
          mkdir -p generated/final
          
          # 最終動画をコピー
          if [ -f "final_video.mp4" ]; then
            cp final_video.mp4 generated/final/
            echo "✅ Final video included in package"
          fi
          
          # パッケージ情報
          cat > generated/final/package.json << EOF
          {
            "project": "Video Content Creation V2",
            "concept": "${{ github.event.inputs.video_concept }}",
            "duration": ${{ github.event.inputs.video_length }},
            "style": "${{ github.event.inputs.video_style }}",
            "audience": "${{ github.event.inputs.target_audience }}",
            "quality": "${{ github.event.inputs.quality_setting }}",
            "features": {
              "multiple_scenes": true,
              "dialogue_narration": true,
              "background_music": true,
              "ffmpeg_assembly": true
            },
            "generated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "workflow_run": ${{ github.run_number }}
          }
          EOF
          
          # ファイルサイズ情報
          echo "📁 Final package contents:"
          ls -lh generated/final/
          if [ -f "generated/final/final_video.mp4" ]; then
            echo ""
            echo "🎥 Final video size: $(ls -lh generated/final/final_video.mp4 | awk '{print $5}')"
          fi
          
      - name: Upload final package
        uses: actions/upload-artifact@v4
        with:
          name: final-package-v3-${{ github.run_number }}
          path: |
            generated/final/
          retention-days: 90
          
      - name: Upload production video
        uses: actions/upload-artifact@v4
        with:
          name: production-video-v3-${{ github.run_number }}
          path: |
            final_video.mp4
          retention-days: 90
          if-no-files-found: warn
          
      - name: Summary
        run: |
          echo "## 🎉 Video Content Creation V3 Complete!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🎥 Production Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Concept**: ${{ github.event.inputs.video_concept }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration**: ${{ github.event.inputs.video_length }} seconds" >> $GITHUB_STEP_SUMMARY
          echo "- **Style**: ${{ github.event.inputs.video_style }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Quality**: ${{ github.event.inputs.quality_setting }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📦 Deliverables" >> $GITHUB_STEP_SUMMARY
          echo "- **Final Video**: production-video-v3-${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Full Package**: final-package-v3-${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ✨ New Features in V3" >> $GITHUB_STEP_SUMMARY
          echo "- Dynamic scene count support (5-20 scenes)" >> $GITHUB_STEP_SUMMARY
          echo "- Parallel video generation with matrix strategy" >> $GITHUB_STEP_SUMMARY
          echo "- Individual scene processing (no timeout issues)" >> $GITHUB_STEP_SUMMARY
          echo "- Improved scalability and performance" >> $GITHUB_STEP_SUMMARY