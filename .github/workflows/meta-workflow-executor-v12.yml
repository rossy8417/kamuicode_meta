name: "Meta Workflow Executor v12 with Domain Templates"
run-name: "üöÄ Meta Workflow v12 | Issue #${{ inputs.issue_number || github.event.issue.number }} | ${{ github.actor }}"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number for workflow generation request'
        required: true
        default: '66'
  
  issue_comment:
    types: [created]

permissions:
  contents: write
  issues: write
  actions: write
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  bootstrap:
    name: "üß© Bootstrap Diagnostics"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'issue_comment' && github.event.issue.pull_request == null && contains(github.event.comment.body, '/execute'))
    steps:
      - name: Print event context
        run: |
          echo "event_name=${{ github.event_name }}"
          echo "actor=${{ github.actor }}"
          echo "ref=${{ github.ref }}"
          echo "issue_number_from_dispatch=${{ inputs.issue_number }}"
          echo "is_issue_comment=$([ "${{ github.event_name }}" = "issue_comment" ] && echo true || echo false)"
          if [ "${{ github.event_name }}" = "issue_comment" ]; then
            echo "comment_body<<EOT"
            echo "${{ github.event.comment.body }}"
            echo "EOT"
          fi
          echo "Bootstrap OK"
  
  # ===========================================
  # PHASE 1: ISSUE VALIDATION & DOMAIN DETECTION
  # ===========================================
  
  validate-and-detect:
    name: "üîç Issue Validation & Domain Detection"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'issue_comment' && github.event.issue.pull_request == null && contains(github.event.comment.body, '/execute'))
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
      issue_title: ${{ steps.extract.outputs.issue_title }}
      primary_domain: ${{ steps.detect.outputs.primary_domain }}
      detected_domains: ${{ steps.detect.outputs.detected_domains }}
      domain_count: ${{ steps.detect.outputs.domain_count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
        
      - name: Extract Issue Information
        id: extract
        run: |
          # Check if this is a valid trigger
          if [ "${{ github.event_name }}" == "issue_comment" ]; then
            # Use printf to safely handle quotes in comment body
            COMMENT_BODY=$(printf '%s' '${{ github.event.comment.body }}')
            # For issue comments, check if it's a start command
            if ! echo "$COMMENT_BODY" | grep -qE '(/start|/execute|^start$|^ÂÆüË°å$|^execute$)'; then
              echo "::notice::Skipping - Comment does not contain start command"
              echo "issue_number=skip" >> $GITHUB_OUTPUT
              exit 0
            fi
            ISSUE_NUMBER="${{ github.event.issue.number }}"
          else
            # workflow_dispatch always proceeds
            ISSUE_NUMBER="${{ inputs.issue_number }}"
          fi
          
          echo "üîç Analyzing Issue #$ISSUE_NUMBER..."
          
          # Get issue details using GitHub CLI
          ISSUE_DATA=$(gh issue view $ISSUE_NUMBER --json title,body,number --jq '{title: .title, body: .body, number: .number}')
          
          ISSUE_TITLE=$(echo "$ISSUE_DATA" | jq -r '.title')
          ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body')
          ISSUE_NUMBER=$(echo "$ISSUE_DATA" | jq -r '.number')
          
          # Save to artifacts for next jobs
          mkdir -p artifacts
          echo "$ISSUE_TITLE" > artifacts/issue_title.txt
          echo "$ISSUE_BODY" > artifacts/issue_body.txt
          echo "$ISSUE_NUMBER" > artifacts/issue_number.txt
          
          # Combine title and body for domain detection
          echo -e "$ISSUE_TITLE\n\n$ISSUE_BODY" > artifacts/issue_content.txt
          
          # Output minimal data
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          echo "issue_title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Issue #$ISSUE_NUMBER validated: $ISSUE_TITLE"
          
          # Initialize Progressive Report in GitHub Actions Summary
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # üéØ Meta Workflow v12 ÂÆüË°å„É¨„Éù„Éº„Éà
          
          ## üìã ÂÆüË°åÊ¶ÇË¶Å
          EOF
          
          echo "- **IssueÁï™Âè∑**: #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
          echo "- **Issue „Çø„Ç§„Éà„É´**: ${ISSUE_TITLE}" >> $GITHUB_STEP_SUMMARY  
          echo "- **ÂÆüË°åÈñãÂßãÊôÇÂàª**: $(date '+%YÂπ¥%mÊúà%dÊó• %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          echo "- **ÂÆüË°åÁä∂Ê≥Å**: üîÑ ÈÄ≤Ë°å‰∏≠..." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## üîç Phase 1: IssueÊ§úË®º & „Éâ„É°„Ç§„É≥Ê§úÂá∫" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Issue #${ISSUE_NUMBER} ÂÜÖÂÆπÂèñÂæóÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ „Éâ„É°„Ç§„É≥Ê§úÂá∫: (pending)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Detect Domain from Issue
        id: detect
        run: |
          echo "üéØ Detecting domain from issue content..."
          
          python scripts/domain-template-loader.py \
            --action detect \
            --issue artifacts/issue_content.txt \
            --output artifacts/domain_detection.json
          
          # Extract results
          PRIMARY_DOMAIN=$(jq -r '.primary_domain' artifacts/domain_detection.json)
          DETECTED_DOMAINS=$(jq -c '.detected_domains' artifacts/domain_detection.json)
          DOMAIN_COUNT=$(jq '.detected_domains | length' artifacts/domain_detection.json)
          
          echo "primary_domain=$PRIMARY_DOMAIN" >> $GITHUB_OUTPUT
          echo "detected_domains=$DETECTED_DOMAINS" >> $GITHUB_OUTPUT
          echo "domain_count=$DOMAIN_COUNT" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Primary domain detected: $PRIMARY_DOMAIN"
          echo "üìä Total domains detected: $DOMAIN_COUNT"
          
      - name: Upload Issue and Domain Data
        uses: actions/upload-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/

      - name: Report Detected Domain
        run: |
          PRIMARY_DOMAIN="${{ steps.detect.outputs.primary_domain }}"
          COUNT="${{ steps.detect.outputs.domain_count }}"
          echo "- ‚úÖ „Éâ„É°„Ç§„É≥Ê§úÂá∫: ${PRIMARY_DOMAIN} (${COUNT} detected)" >> $GITHUB_STEP_SUMMARY

  # ===========================================
  # PHASE 2: DOMAIN TEMPLATE LOADING
  # ===========================================
  
  load-domain-templates:
    name: "üìö Load Domain Templates"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect']
    if: |
      needs.validate-and-detect.outputs.issue_number != 'skip' &&
      needs.validate-and-detect.outputs.primary_domain != 'null'
    outputs:
      template_summary: ${{ steps.load.outputs.template_summary }}
      chunk_count: ${{ steps.load.outputs.chunk_count }}
      input_schema: ${{ steps.inputs.outputs.input_schema }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download Issue Data
        uses: actions/download-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/
          
      - name: Load Primary Domain Template
        id: load
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          echo "üìö Loading template for domain: $PRIMARY_DOMAIN"
          
          # Get domain summary for task decomposition
          python scripts/domain-template-loader.py \
            --action summary-for-decomposition \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_decomposition_data.json
          
          # Also get standard summary for reference
          python scripts/domain-template-loader.py \
            --action summary \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_summary.json
          
          # Split template into chunks
          python scripts/domain-template-loader.py \
            --action split \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/template_chunks.json
          
          # Extract basic info only (not full JSON)
          DOMAIN_NAME=$(jq -r '.domain_info.name' artifacts/domain_decomposition_data.json)
          EXPERT_ROLE=$(jq -r '.domain_info.expert' artifacts/domain_decomposition_data.json)
          CHUNK_COUNT=$(jq '.total_chunks' artifacts/template_chunks.json)
          
          echo "domain_name=$DOMAIN_NAME" >> $GITHUB_OUTPUT
          echo "expert_role=$EXPERT_ROLE" >> $GITHUB_OUTPUT
          echo "chunk_count=$CHUNK_COUNT" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Template loaded: $DOMAIN_NAME ($CHUNK_COUNT chunks)"
          
          # Add Phase 2 Report
          echo "## üìö Phase 2: „Éâ„É°„Ç§„É≥„ÉÜ„É≥„Éó„É¨„Éº„ÉàË™≠„ÅøËæº„Åø" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ „Éâ„É°„Ç§„É≥: ${DOMAIN_NAME}" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Â∞ÇÈñÄÂÆ∂ÂΩπÂâ≤: ${EXPERT_ROLE}" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ „ÉÜ„É≥„Éó„É¨„Éº„Éà„ÉÅ„É£„É≥„ÇØÊï∞: ${CHUNK_COUNT}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Locate and Copy Domain Input Schema
        id: inputs
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          SCHEMA_PATH="meta/domain-templates/$PRIMARY_DOMAIN/input-schema.yaml"
          mkdir -p artifacts/domain-input-schema
          if [ -f "$SCHEMA_PATH" ]; then
            cp "$SCHEMA_PATH" artifacts/domain-input-schema/input-schema.yaml
            echo "input_schema=artifacts/domain-input-schema/input-schema.yaml" >> $GITHUB_OUTPUT
            echo "‚úÖ Input schema found: $SCHEMA_PATH"
            echo "- ‚úÖ ÂÖ•Âäõ„Çπ„Ç≠„Éº„ÉûÊ§úÂá∫: $PRIMARY_DOMAIN/input-schema.yaml" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Input schema not found for domain: $PRIMARY_DOMAIN"
            echo "input_schema=" >> $GITHUB_OUTPUT
            echo "- ‚ùå ÂÖ•Âäõ„Çπ„Ç≠„Éº„ÉûÊú™Ê§úÂá∫" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Locate Domain Checklists
        id: checklists
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          LIST=$(ls -1 "meta/domain-templates/$PRIMARY_DOMAIN"/checklist-*-specific.md 2>/dev/null || true)
          mkdir -p artifacts
          if [ -n "$LIST" ]; then
            echo "$LIST" > artifacts/domain-checklists.txt
            COUNT=$(echo "$LIST" | wc -l | tr -d ' ')
            echo "checklist_count=$COUNT" >> $GITHUB_OUTPUT
            echo "- ‚úÖ „Éâ„É°„Ç§„É≥„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„ÉàÊ§úÂá∫ ($COUNT ‰ª∂):" >> $GITHUB_STEP_SUMMARY
            echo "$LIST" | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
            echo "üìö Using domain checklists (detected $COUNT):"
            echo "$LIST" | sed 's/^/- /'
          else
            echo "checklist_count=0" >> $GITHUB_OUTPUT
            echo "- ‚ùå „Éâ„É°„Ç§„É≥„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„ÉàÊú™Ê§úÂá∫" >> $GITHUB_STEP_SUMMARY
            echo "üìö Using domain checklists: (none found)"
          fi
          
      - name: Upload Template Data
        uses: actions/upload-artifact@v4
        with:
          name: domain-template-data
          path: artifacts/

  # ===========================================
  # PHASE 3: PROFESSIONAL TASK DECOMPOSITION
  # ===========================================
  
  professional-task-decomposition:
    name: "üß† Professional Task Decomposition"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates']
    outputs:
      task_count: ${{ steps.decompose.outputs.task_count }}
      dependency_groups: ${{ steps.decompose.outputs.dependency_groups }}
      estimated_duration: ${{ steps.decompose.outputs.estimated_duration }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download and Merge Previous Artifacts
        run: |
          echo "üì• Downloading artifacts from previous jobs..."
          
          # Download artifacts selectively
          mkdir -p artifacts
          
          # Download issue-domain-data
          echo "Downloading issue-domain-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "issue-domain-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/issue-domain-data.zip
            unzip -q -o artifacts/issue-domain-data.zip -d artifacts/issue-domain-data/
            rm artifacts/issue-domain-data.zip
          done
          
          # Download domain-template-data
          echo "Downloading domain-template-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "domain-template-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/domain-template-data.zip
            unzip -q -o artifacts/domain-template-data.zip -d artifacts/domain-template-data/
            rm artifacts/domain-template-data.zip
          done
          
          # Merge artifacts to flat structure
          echo "Merging artifacts..."
          find artifacts -type f -name "*.json" -o -name "*.txt" -o -name "*.yaml" | while read -r file; do
            filename=$(basename "$file")
            if [ ! -f "artifacts/$filename" ]; then
              cp "$file" "artifacts/$filename"
            fi
          done
          
          echo "‚úÖ Artifacts downloaded and merged"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Professional Task Decomposition with Domain Knowledge
        id: decompose
        run: |
          echo "üß† Starting professional task decomposition..."
          
          # Create decomposition prompt using file references
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          EXPERT_ROLE="${{ needs.load-domain-templates.outputs.expert_role }}"
          
          cat > decomposition_prompt.txt << 'EOF'
          Â∞ÇÈñÄÁöÑ„Å™„Çø„Çπ„ÇØÂàÜËß£„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
          
          ‰ª•‰∏ã„ÅÆ„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„Çì„Åß„Çø„Çπ„ÇØÂàÜËß£„ÇíË°å„Å£„Å¶„Åè„Å†„Åï„ÅÑÔºö
          1. „Éâ„É°„Ç§„É≥Â∞ÇÈñÄÁü•Ë≠ò: artifacts/domain-template-data/domain_decomposition_data.json
          2. „É¶„Éº„Ç∂„Éº„É™„ÇØ„Ç®„Çπ„Éà: artifacts/issue-domain-data/issue_content.txt
          
          „Éâ„É°„Ç§„É≥Â∞ÇÈñÄÁü•Ë≠ò„Éï„Ç°„Ç§„É´„Å´„ÅØ‰ª•‰∏ã„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Åæ„ÅôÔºö
          - expert_context: Â∞ÇÈñÄÂÆ∂„ÅÆÂÆåÂÖ®„Å™Áü•Ë≠ò
          - task_decomposition_context: „ÉØ„Éº„ÇØ„Éï„É≠„Éº„Éë„Çø„Éº„É≥„Å®ÊúÄÈÅ©ÂåñÊÉÖÂ†±
          - constraints_and_requirements: „Åô„Åπ„Å¶„ÅÆÂà∂Á¥Ñ‰∫ãÈ†Ö
          - implementation_resources: Âà©Áî®ÂèØËÉΩ„Å™„É™„ÇΩ„Éº„Çπ
          - complex_thinking_guide: ÊÄùËÄÉ„Éó„É≠„Çª„Çπ„ÅÆ„Ç¨„Ç§„Éâ
          
          „Çø„Çπ„ÇØÂàÜËß£„ÅÆÊâãÈ†ÜÔºö
          1. domain_decomposition_data.json„ÅÆexpert_context„ÇíÂÆåÂÖ®„Å´ÁêÜËß£
          2. task_decomposition_context„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Éë„Çø„Éº„É≥„ÇíÂèÇÁÖß
          3. constraints_and_requirements„ÅÆ„Åô„Åπ„Å¶„ÅÆÂà∂Á¥Ñ„ÇíËÄÉÊÖÆ
          4. complex_thinking_guide„Å´Âæì„Å£„Å¶Ë§áÈõë„Å™ÊÄùËÄÉ„Éó„É≠„Çª„Çπ„ÇíÂÆüË°å
          5. implementation_resources„Åã„ÇâÊúÄÈÅ©„Å™„É™„ÇΩ„Éº„Çπ„ÇíÈÅ∏Êäû
          
          Âá∫Âäõ„Çíartifacts/professional_task_decomposition.json„Å´‰øùÂ≠ò„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
          
          Âá∫ÂäõÂΩ¢ÂºèÔºö
          {
            "professional_analysis": {
              "understanding": "„É™„ÇØ„Ç®„Çπ„Éà„ÅÆÂ∞ÇÈñÄÁöÑÁêÜËß£ÔºàË©≥Á¥∞Ôºâ",
              "considerations": ["ËÄÉÊÖÆ‰∫ãÈ†Ö„ÅÆ„É™„Çπ„Éà"],
              "thinking_process": "ÊÄùËÄÉ„Éó„É≠„Çª„Çπ„ÅÆË©≥Á¥∞„Å™Ë®òÈå≤"
            },
            "tasks": [
              {
                "id": "task-1",
                "name": "„Çø„Çπ„ÇØÂêç",
                "description": "Ë©≥Á¥∞„Å™Ë™¨Êòé",
                "reasoning": "„Å™„Åú„Åì„ÅÆ„Çø„Çπ„ÇØ„ÅåÂøÖË¶Å„Åã",
                "minimal_units": ["unit1", "unit2"],
                "dependencies": [],
                "estimated_duration": "5-10ÂàÜ",
                "professional_notes": "Â∞ÇÈñÄÁöÑ„Å™Ê≥®ÊÑèÁÇπ",
                "quality_criteria": "ÂìÅË≥™Âü∫Ê∫ñ"
              }
            ],
            "workflow_optimization": {
              "parallel_groups": [],
              "critical_path": [],
              "optimization_rationale": "ÊúÄÈÅ©Âåñ„ÅÆÁêÜÁî±"
            },
            "workflow_generation_parameters": {
              "calculated_scene_count": "constraints.yaml„ÅÆscene_calculation„Å´Âü∫„Å•„ÅÑ„Å¶Ë®àÁÆó„Åó„ÅüÊï∞ÂÄ§",
              "matrix_scene_list": "[1, 2, 3, ...]„ÅÆÂΩ¢Âºè„ÅßË®àÁÆó„Åï„Çå„Åü„Ç∑„Éº„É≥„É™„Çπ„Éà",
              "max_parallel": "calculated_scene_count„Å®Âêå„ÅòÂÄ§",
              "assumed_scene_duration": "Ë®àÁÆó„Åß‰ΩøÁî®„Åó„Åü1„Ç∑„Éº„É≥„ÅÇ„Åü„Çä„ÅÆÁßíÊï∞",
              "per_scene_job_structure": "CRITICAL: T2I‚ÜíI2V must be in SAME job (prevents URL expiry)"
            },
            "total_estimated_duration": "30ÂàÜ",
            "domain_specific_constraints": []
          }
          EOF
          
          # Add expert role context
          echo "„ÅÇ„Å™„Åü„ÅØ${EXPERT_ROLE}„Åß„Åô„ÄÇ" > final_prompt.txt
          echo "" >> final_prompt.txt
          cat decomposition_prompt.txt >> final_prompt.txt
          
          # Execute Claude Code for task decomposition
          npx @anthropic-ai/claude-code \
            -p "$(cat final_prompt.txt)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            > claude_output.log 2>&1
          
          # Check if execution was successful
          if [ $? -eq 0 ]; then
            echo "‚úÖ Claude Code execution completed"
            
            # Try multiple methods to find the generated file
            if [ -f "artifacts/professional_task_decomposition.json" ]; then
              echo "‚úÖ Found file at expected location"
            elif [ -f "professional_task_decomposition.json" ]; then
              echo "üìÅ Found file in current directory, moving to artifacts"
              mv professional_task_decomposition.json artifacts/
            else
              # Search for any JSON file that might contain the task decomposition
              echo "üîç Searching for generated JSON files..."
              find . -name "*.json" -type f -newer final_prompt.txt -exec grep -l "professional_analysis" {} \; | while read -r file; do
                echo "üìÅ Found potential task decomposition at: $file"
                cp "$file" artifacts/professional_task_decomposition.json
                break
              done
            fi
            
            # Final check
            if [ ! -f "artifacts/professional_task_decomposition.json" ]; then
              echo "‚ùå Could not find task decomposition file"
              echo "üìã Claude output:"
              cat claude_output.log
              exit 1
            fi
          else
            echo "‚ùå Claude Code execution failed"
            cat claude_output.log
            exit 1
          fi
          
          # Extract results
          if [ -f "artifacts/professional_task_decomposition.json" ]; then
            TASK_COUNT=$(jq '.tasks | length' artifacts/professional_task_decomposition.json)
            DEPENDENCY_GROUPS=$(jq -c '.dependency_groups' artifacts/professional_task_decomposition.json)
            ESTIMATED_DURATION=$(jq -r '.total_estimated_duration' artifacts/professional_task_decomposition.json)
            
            echo "task_count=$TASK_COUNT" >> $GITHUB_OUTPUT
            echo "dependency_groups=$DEPENDENCY_GROUPS" >> $GITHUB_OUTPUT
            echo "estimated_duration=$ESTIMATED_DURATION" >> $GITHUB_OUTPUT
            
            echo "‚úÖ Decomposed into $TASK_COUNT tasks"
            echo "‚è±Ô∏è Estimated duration: $ESTIMATED_DURATION"
            
            # Add Phase 3 Report
            echo "## üß† Phase 3: „Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Çø„Çπ„ÇØÂàÜËß£" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ „Çø„Çπ„ÇØÊï∞: ${TASK_COUNT}ÂÄã" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ Êé®ÂÆöÂÆüË°åÊôÇÈñì: ${ESTIMATED_DURATION}" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ ‰æùÂ≠òÈñ¢‰øÇ„Ç∞„É´„Éº„ÉóÂàÜÊûêÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Task decomposition failed"
            exit 1
          fi
          
      - name: Upload Task Decomposition
        uses: actions/upload-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/professional_task_decomposition.json

  # ===========================================
  # PHASE 4: TASK ORDER OPTIMIZATION
  # ===========================================
  
  optimize-task-order:
    name: "üîÑ Optimize Task Execution Order"
    runs-on: ubuntu-latest
    needs: ['professional-task-decomposition']
    outputs:
      optimized_order: ${{ steps.optimize.outputs.order }}
      mermaid_available: ${{ steps.optimize.outputs.mermaid_available }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Task Decomposition
        uses: actions/download-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/
          
      - name: Analyze and Optimize Task Order
        id: optimize
        run: |
          echo "üîÑ „Çø„Çπ„ÇØÂÆüË°åÈ†ÜÂ∫è„ÅÆÊúÄÈÅ©Âåñ..."
          
          # Create artifacts directory
          mkdir -p artifacts
          
          # Run Claude Code SDK with specialized prompt file for reliable Mermaid generation
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            -p "$(cat meta/prompts/task-order-optimization-with-mermaid.md)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits"
          
          # ÁµêÊûú„ÇíÁ¢∫Ë™ç
          if [ -f "artifacts/optimized_task_order.json" ]; then
            echo "order=true" >> $GITHUB_OUTPUT
            
            # Add Phase 4 Report with Task Order
            echo "## üîÑ Phase 4: „Çø„Çπ„ÇØÂÆüË°åÈ†ÜÂ∫è„ÅÆÊúÄÈÅ©Âåñ" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ ‰æùÂ≠òÈñ¢‰øÇÂàÜÊûêÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ ‰∏¶ÂàóÂá¶ÁêÜ„Ç∞„É´„Éº„ÉóÁâπÂÆö" >> $GITHUB_STEP_SUMMARY
            
            # ÂãïÁöÑ„ÉÜ„Ç≠„Çπ„ÉàÂõ≥„ÇíÁîüÊàêÔºàÊúÄÈÅ©Âåñ„Åï„Çå„Åü„Çø„Çπ„ÇØ„Åã„ÇâËá™ÂãïÁîüÊàêÔºâ
            if [ -f "artifacts/optimized_task_order.json" ]; then
              echo "- ‚úÖ ÊúÄÈÅ©Âåñ„Åï„Çå„ÅüÂÆüË°åÈ†ÜÂ∫èÁîüÊàêÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### üìä ÂÆüË°å„Éï„É≠„ÉºÂõ≥ÔºàÂãïÁöÑÁîüÊàêÔºâ" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              
              # JSON„Åã„ÇâÂãïÁöÑ„Å´„Çø„Çπ„ÇØ„Éï„É≠„Éº„ÇíÁîüÊàêÔºàÂçò‰∏ÄË°å„ÅßÂÆüË°åÔºâ
              if [ -f "artifacts/optimized_task_order.json" ]; then
                python3 -c "import json; data=json.load(open('artifacts/optimized_task_order.json')); print('„Çø„Çπ„ÇØÂÆüË°å„Éï„É≠„ÉºÔºàÂãïÁöÑÁîüÊàê„Éª‰∏¶ÂàóÂá¶ÁêÜÊúÄÈÅ©ÂåñÊ∏à„ÅøÔºâ:'); print(); [print(f\"‚ö° {phase.get('phase', f'Phase {i+1}')} [{phase.get('execution_type', 'sequential').upper()}]\") if phase.get('execution_type') == 'parallel' else print(f\"üìã {phase.get('phase', f'Phase {i+1}')} [{phase.get('execution_type', 'sequential').upper()}]\") for i, phase in enumerate(data.get('optimized_execution_order', []))]" >> $GITHUB_STEP_SUMMARY
                echo "‚è±Ô∏è ÊúÄÈÅ©Âåñ„Å´„Çà„Çä‰∏¶ÂàóÂá¶ÁêÜ„ÇíÊ¥ªÁî®„Åó„ÅüÂäπÁéáÁöÑ„Å™ÂÆüË°åÈ†ÜÂ∫è„ÇíÁîüÊàê" >> $GITHUB_STEP_SUMMARY
              else
                echo "„Çø„Çπ„ÇØ„Éï„É≠„ÉºÊÉÖÂ†±„ÅåÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì" >> $GITHUB_STEP_SUMMARY
              fi
              
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "mermaid_available=true" >> $GITHUB_OUTPUT
            else
              echo "- ‚ùå ÊúÄÈÅ©ÂåñÈ†ÜÂ∫è„ÅÆÁîüÊàê„Å´Â§±Êïó" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "mermaid_available=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "order=false" >> $GITHUB_OUTPUT
          fi
          
      # Summary display moved to final report for better organization
          
      - name: Upload Optimized Order
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: optimized-task-order
          path: artifacts/
          if-no-files-found: warn

  # ===========================================
  # PHASE 5: CONSTRAINT-AWARE WORKFLOW GENERATION
  # ===========================================
  
  generate-professional-workflow:
    name: "‚ö° Generate Professional Workflow"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order']
    outputs:
      workflow_path: ${{ steps.generate.outputs.workflow_path }}
      workflow_name: ${{ steps.generate.outputs.workflow_name }}
      project_dir: ${{ steps.generate.outputs.project_dir }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Environment
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
          
      - name: Generate Professional Workflow
        id: generate
        run: |
          echo "‚ö° Generating professional workflow..."
          
          # Prepare all necessary data
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Create generation directory with absolute path
          # Use GITHUB_WORKSPACE for consistency across jobs
          if [ -n "$GITHUB_WORKSPACE" ]; then
            BASE_DIR="$GITHUB_WORKSPACE"
          else
            BASE_DIR="$(pwd)"
          fi
          PROJECT_DIR="${BASE_DIR}/projects/issue-${ISSUE_NUMBER}-${TIMESTAMP}"
          mkdir -p "$PROJECT_DIR/generated-workflow"
          
          echo "üìÅ Project directory: $PROJECT_DIR"
          
          # Load template chunks progressively
          CHUNKS=$(jq -r '.chunks[].id' artifacts/domain-template-data/template_chunks.json)
          
          # Create comprehensive generation prompt (domain-agnostic with strict domain enforcement when provided)
          # Copy the template prompt and replace PROJECT_DIR_PLACEHOLDER
          cp meta/prompts/generation-prompt-template.txt generation_prompt.txt
          sed -i "s|PROJECT_DIR_PLACEHOLDER|$PROJECT_DIR|g" generation_prompt.txt
          
          # Add visibility in logs: which checklists will be referenced
          echo "üìö Using domain checklists:" >> $GITHUB_STEP_SUMMARY
          if [ -f artifacts/domain-template-data/domain-checklists.txt ]; then
            cat artifacts/domain-template-data/domain-checklists.txt | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
          elif [ -f artifacts/domain-checklists.txt ]; then
            cat artifacts/domain-checklists.txt | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
          else
            echo "- (none found)" >> $GITHUB_STEP_SUMMARY
          fi

          # Also list rule references if present in constraints
          if [ -f artifacts/domain-template-data/domain_summary.json ]; then
            echo "### Domain Rule References" >> $GITHUB_STEP_SUMMARY
            jq -r '.constraints.rule_references[]?.path' artifacts/domain-template-data/domain_summary.json 2>/dev/null | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY || true
          fi
          
          # Note: do not inject domain-specific helper jobs inline. All domain rules are enforced via referenced checklists during validation/auto-fix.
          
          # Execute workflow generation with explicit output
          echo "üìù Generating workflow with Claude Code SDK..."
          echo "Target: $PROJECT_DIR/generated-workflow/workflow.yml"
          
          npx @anthropic-ai/claude-code \
            -p "$(cat generation_prompt.txt)" \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Write,Read,MultiEdit,Bash" \
            --permission-mode "acceptEdits" \
            --max-turns 50 \
            > /dev/null 2>&1 || echo "Claude Code execution completed"
          
          # Verify workflow was created
          WORKFLOW_PATH="$PROJECT_DIR/generated-workflow/workflow.yml"
          if [ -f "$WORKFLOW_PATH" ]; then
            echo "üìã Post-processing generated workflow..."
            
            # Clean up any function call artifacts that might have been included
            if grep -q "<function_calls>" "$WORKFLOW_PATH" 2>/dev/null; then
              echo "‚ö†Ô∏è Found function call artifacts, cleaning up..."
              # Remove everything from <function_calls> onwards
              sed -i '/<function_calls>/,$d' "$WORKFLOW_PATH"
            fi
            
            # Note: Do NOT quote the "on" field - GitHub Actions requires it unquoted
            # Make sure it's unquoted (in case Claude Code quoted it)
            sed -i 's/^"on":$/on:/' "$WORKFLOW_PATH"
            
            # Replace SECRETS_PLACEHOLDER or actual token values with the proper secrets reference
            if grep -q "SECRETS_PLACEHOLDER" "$WORKFLOW_PATH" 2>/dev/null; then
              echo "‚ö†Ô∏è Replacing SECRETS_PLACEHOLDER with actual secrets reference..."
              sed -i 's/SECRETS_PLACEHOLDER/${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}/g' "$WORKFLOW_PATH"
            fi
            
            # Also check for actual token patterns and replace them
            if grep -E "sk-ant-oat[0-9]{2}-[A-Za-z0-9_-]{80,}" "$WORKFLOW_PATH" 2>/dev/null; then
              echo "‚ö†Ô∏è WARNING: Actual OAuth token detected! Replacing with secrets reference..."
              sed -i -E 's/sk-ant-oat[0-9]{2}-[A-Za-z0-9_-]{80,}/${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}/g' "$WORKFLOW_PATH"
            fi
            
            # Replace full-width quotes with half-width quotes
            if grep -q '[""'']' "$WORKFLOW_PATH" 2>/dev/null; then
              echo "‚ö†Ô∏è Replacing full-width quotes with half-width quotes..."
              sed -i 's/"/"/g; s/"/"/g; s/'/'"'"'/g; s/'/'"'"'/g' "$WORKFLOW_PATH"
            fi
            
            # CRITICAL: Remove any actual OAUTH_TOKEN values that were directly inserted
            if grep -q "sk-ant-" "$WORKFLOW_PATH" 2>/dev/null; then
              echo "üö® CRITICAL: Found exposed OAUTH_TOKEN value, replacing with secrets reference..."
              sed -i 's/sk-ant-[^[:space:]]*/${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}/g' "$WORKFLOW_PATH"
            fi
            
            # Remove invalid matrix references in outputs section
            # GitHub Actions doesn't allow ${{ matrix.* }} in job outputs
            if grep -q 'outputs:.*matrix\.' "$WORKFLOW_PATH" 2>/dev/null; then
              echo "‚ö†Ô∏è Found invalid matrix references in outputs, removing..."
              # Remove lines with matrix references in outputs sections
              sed -i '/^\s*outputs:/,/^\s*steps:/{/matrix\./d}' "$WORKFLOW_PATH"
            fi
            
            # Fix GCS URL handling - proper solution
            if grep -q 'gs://' "$WORKFLOW_PATH" 2>/dev/null; then
              echo "‚ö†Ô∏è Found GCS URLs, converting to HTTPS URLs..."
              
              # Simple replacement: gs://bucket/path -> https://storage.googleapis.com/bucket/path
              sed -i 's|gs://\([^/]*\)/|https://storage.googleapis.com/\1/|g' "$WORKFLOW_PATH" 2>/dev/null || true
              
              echo "  ‚úÖ Converted GCS URLs to HTTPS format"
            fi
            
            # Fix common YAML syntax issues with simple sed commands
            echo "‚ö†Ô∏è Fixing common YAML syntax issues..."
            
            # Remove max-parallel to allow unlimited parallelization
            sed -i '/^\s*max-parallel:/d' "$WORKFLOW_PATH" 2>/dev/null || true
            echo "  ‚úÖ Removed max-parallel to allow dynamic parallelization"
            
            # Fix heredoc issues - escape $(date) in cat << EOF blocks
            sed -i 's/Generated: $(date)/Generated: \\$(date)/g' "$WORKFLOW_PATH" 2>/dev/null || true
            echo "  ‚úÖ Fixed heredoc syntax issues"
            
            # Ensure workflow ends properly (no trailing content)
            # Add a newline at the end if missing
            if [ -n "$(tail -c 1 "$WORKFLOW_PATH")" ]; then
              echo "" >> "$WORKFLOW_PATH"
            fi
            
            WORKFLOW_NAME="professional-workflow-${PRIMARY_DOMAIN}-${TIMESTAMP}"
            
            echo "workflow_path=$WORKFLOW_PATH" >> $GITHUB_OUTPUT
            echo "workflow_name=$WORKFLOW_NAME" >> $GITHUB_OUTPUT
            echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
            
            echo "‚úÖ Workflow generated and cleaned: $WORKFLOW_NAME"
            
            # Add Phase 5 Report
            echo "## ‚ö° Phase 5: „Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÁîüÊàê" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ „ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂêç: ${WORKFLOW_NAME}" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ „Éâ„É°„Ç§„É≥: ${PRIMARY_DOMAIN}" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ GitHub ActionsÂΩ¢Âºè„ÅßÁîüÊàêÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Workflow generation failed"
            exit 1
          fi
          
      - name: Upload Generated Workflow
        uses: actions/upload-artifact@v4
        with:
          name: generated-workflow
          path: |
            projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-*

  # ===========================================
  # PHASE 6: VALIDATION & DEPLOYMENT
  # ==========================================
  
  validate-workflow:
    name: "üîç Validate Workflow"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect','generate-professional-workflow']
    outputs:
      validation_passed: ${{ steps.validate.outputs.passed }}
      validation_report: ${{ steps.validate.outputs.report_path }}
      error_count: ${{ steps.validate.outputs.error_count }}
      warning_count: ${{ steps.validate.outputs.warning_count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Generated Workflow
        uses: actions/download-artifact@v4
        with:
          name: generated-workflow
          path: projects/

      - name: Download Domain Template Data (for input schema)
        uses: actions/download-artifact@v4
        with:
          name: domain-template-data
          path: artifacts/

      - name: Validate Startup Requirements
        id: startup-validation
        run: |
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          echo "üîç Startup validation..."
          ERRORS=0
          
          # Check for push event handling
          if ! grep -q "paths-ignore:" "$WORKFLOW_PATH" 2>/dev/null; then
            if ! grep -q "push:" "$WORKFLOW_PATH" 2>/dev/null; then
              echo "‚ùå ERROR: No push event handling - workflow will fail on git push"
              ERRORS=$((ERRORS + 1))
            fi
          fi
          
          # Check for default values on required inputs
          if grep -q "required: true" "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ö†Ô∏è Checking for defaults on required inputs..."
          fi
          
          # Check for environment variables
          if ! grep -q "^env:" "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ùå ERROR: No environment variables defined at workflow level"
            ERRORS=$((ERRORS + 1))
          fi
          
          # Check for timeout on jobs
          if ! grep -q "timeout-minutes:" "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ö†Ô∏è WARNING: No timeout-minutes defined for jobs"
          fi
          
          echo "startup_errors=$ERRORS" >> $GITHUB_OUTPUT
          
      - name: Validate Data Flow Pattern
        run: |
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          echo "üîç „Éá„Éº„Çø„Éï„É≠„ÉºÊ§úË®º..."
          
          # Claude CodeÂÆüË°åÈÉ®ÂàÜ„ÅÆÊ§úË®º
          if ! grep -q "Write.*media/images" "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ö†Ô∏è WARNING: ÊòéÁ§∫ÁöÑ„Å™„Éï„Ç°„Ç§„É´‰øùÂ≠òÊåáÁ§∫„Åå‰∏çË∂≥„Åó„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô"
            echo "  Êé®Â•®: Write„ÉÑ„Éº„É´„ÅßÊòéÁ§∫ÁöÑ„Å´„Éë„Çπ„ÇíÊåáÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
          fi
          
          if ! grep -q "ls -la.*media" "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ö†Ô∏è WARNING: „Éï„Ç°„Ç§„É´‰øùÂ≠òÁ¢∫Ë™ç„Ç≥„Éû„É≥„Éâ„Åå‰∏çË∂≥„Åó„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô"
            echo "  Êé®Â•®: ls -la„Ç≥„Éû„É≥„Éâ„Åß‰øùÂ≠ò„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
          fi
          
          if ! grep -q "curl.*-[Lo].*url" "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ö†Ô∏è WARNING: URL„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÂá¶ÁêÜ„Åå‰∏çË∂≥„Åó„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô"
            echo "  Êé®Â•®: URL„Éï„Ç°„Ç§„É´Ê§úÂá∫ÊôÇ„ÅØcurl„ÅßÂç≥Â∫ß„Å´„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
          fi
          
          # find„Ç≥„Éû„É≥„Éâ„ÅÆ„Éë„Çø„Éº„É≥Êï∞„ÇíÁ¢∫Ë™ç
          FIND_COUNT=$(grep -c "find.*PROJECT_DIR" "$WORKFLOW_PATH" 2>/dev/null || echo 0)
          if [ "$FIND_COUNT" -lt 3 ]; then
            echo "‚ö†Ô∏è WARNING: „Éï„Ç°„Ç§„É´Ê§úÁ¥¢„Éë„Çø„Éº„É≥„ÅåÂ∞ë„Å™„ÅÑÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„ÅôÔºàÁèæÂú®: $FIND_COUNTÂõûÔºâ"
            echo "  Êé®Â•®: ÊúÄ‰Ωé3„Éë„Çø„Éº„É≥„ÅßÊ§úÁ¥¢ÔºàÁâπÂÆöÂêç„ÄÅÊôÇÈñì„Éô„Éº„Çπ„ÄÅÊ±éÁî®Ôºâ"
          fi
          
          # Check for invalid matrix references in outputs
          if grep -q 'outputs:.*matrix\.' "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ùå ERROR: Invalid matrix references found in outputs section"
            echo "  GitHub Actions does not allow \${{ matrix.* }} in job outputs"
            echo "  Found: $(grep 'outputs:.*matrix\.' "$WORKFLOW_PATH")"
          fi
          
          # Check for GCS URL handling
          if grep -q 'curl.*gs://' "$WORKFLOW_PATH" 2>/dev/null; then
            echo "‚ùå ERROR: Direct curl of GCS URLs detected"
            echo "  curl does not support gs:// protocol"
            echo "  Use gsutil or convert to signed https:// URL"
            VALIDATION_PASSED=false
          fi
          
          # Check for URL validity checks that don't handle GCS
          if grep -q 'curl -IfsS.*URL' "$WORKFLOW_PATH" 2>/dev/null; then
            if ! grep -B2 -A2 'curl -IfsS' "$WORKFLOW_PATH" | grep -q 'if.*gs://'; then
              echo "‚ö†Ô∏è WARNING: URL validity checks may fail on GCS URLs"
              echo "  Consider adding GCS URL detection before curl checks"
            fi
          fi
          
          echo "‚úÖ „Éá„Éº„Çø„Éï„É≠„ÉºÊ§úË®ºÂÆå‰∫Ü"
          
      - name: Check for Common Syntax Errors
        run: |
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          echo "üîç Checking for common syntax errors..."
          
          ERRORS=0
          
          # Check for HEREDOC usage
          if grep -q '<<.*EOF' "$WORKFLOW_PATH"; then
            echo "‚ùå ERROR: HEREDOC detected - use echo commands instead"
            echo "  Found: $(grep -n '<<.*EOF' "$WORKFLOW_PATH" | head -3)"
            ERRORS=$((ERRORS + 1))
          fi
          
          # Check for full-width quotes
          if grep -q '[""'']' "$WORKFLOW_PATH"; then
            echo "‚ùå ERROR: Full-width quotes detected"
            echo "  Found: $(grep -n '[""'']' "$WORKFLOW_PATH" | head -3)"
            ERRORS=$((ERRORS + 1))
          fi
          
          # Check for incorrect bash arithmetic
          if grep -E '\$\{[A-Z_]+\s*-\s*[0-9]+\}' "$WORKFLOW_PATH"; then
            echo "‚ùå ERROR: Invalid bash arithmetic detected"
            echo "  Use \$((VAR - N)) instead of \${VAR - N}"
            echo "  Found: $(grep -En '\$\{[A-Z_]+\s*-\s*[0-9]+\}' "$WORKFLOW_PATH" | head -3)"
            ERRORS=$((ERRORS + 1))
          fi
          
          # Check for exposed credentials
          if grep -E 'ghp_|sk-|key-[A-Za-z0-9]{32}' "$WORKFLOW_PATH"; then
            echo "‚ùå ERROR: Potential credential exposure detected"
            echo "  Use GitHub Secrets instead"
            ERRORS=$((ERRORS + 1))
          fi
          
          if [ $ERRORS -gt 0 ]; then
            echo "‚ùå Found $ERRORS syntax errors - these MUST be fixed"
            exit 1
          else
            echo "‚úÖ No common syntax errors detected"
          fi
          
      - name: Comprehensive Workflow Validation and Auto-Fix
        run: |
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          
          echo "üîç Running comprehensive validation..."
          
          # Use unified validator with auto-fix
          if python3 scripts/workflow-validator.py "$WORKFLOW_PATH" --auto-fix; then
            echo "‚úÖ Workflow validation passed"
          else
            echo "‚ö†Ô∏è Validation failed, checking report..."
            
            # Check if critical errors remain
            if [ -f "$(dirname "$WORKFLOW_PATH")/validation_report.json" ]; then
              CRITICAL_ERRORS=$(jq -r '.errors | length' "$(dirname "$WORKFLOW_PATH")/validation_report.json")
              if [ "$CRITICAL_ERRORS" -gt 0 ]; then
                echo "‚ùå Critical errors remain after auto-fix"
                jq -r '.errors[]' "$(dirname "$WORKFLOW_PATH")/validation_report.json" | while read error; do
                  echo "  ‚Ä¢ $error"
                done
                exit 1
              fi
            fi
          fi
          
      - name: Inject required inputs into generated workflow from schema
        run: |
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          # Schema file downloaded from 'domain-template-data' artifact into artifacts/
          SCHEMA_PATH="artifacts/domain-input-schema/input-schema.yaml"
          if [ -f "$SCHEMA_PATH" ] && [ -f "$WORKFLOW_PATH" ]; then
            python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; schema_path='$SCHEMA_PATH'; wf=yaml.safe_load(open(wf_path)) or {}; schema=yaml.safe_load(open(schema_path)) or {}; req=(schema.get('inputs') or {}).get('required') or {}; on=wf.setdefault('on',{}); wd=on.setdefault('workflow_dispatch',{}); inputs=wd.setdefault('inputs',{}); [ (inputs.setdefault(k,{}).update({'description':(v.get('description',k)), 'required':True}) or (inputs[k].update({'default':v['default']}) if 'default' in v else None) or (inputs[k].update({'type':'choice','options':v['enum']}) if 'enum' in v else inputs[k].pop('type', None)) ) for k,v in req.items() ]; open(wf_path,'w').write(yaml.safe_dump(wf, sort_keys=False))"
            echo "‚úÖ Injected required inputs into workflow_dispatch"
          else
            echo "::warning::Schema or workflow file not found; skip injection"
          fi

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Validate Workflow
        id: validate
        run: |
          echo "‚úÖ Validating generated workflow..."
          
          # Use generated workflow path
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          
          # üîí SECURITY VALIDATION FIRST (CRITICAL)
          echo "üîí Checking for security issues..."
          SECURITY_ISSUES=0
          
          # Check for exposed OAuth tokens
          if grep -q 'CLAUDE_CODE_OAUTH_TOKEN:\s*sk-ant-' "$WORKFLOW_PATH" 2>/dev/null; then
            echo "üö® CRITICAL: OAuth token exposed! Should use secrets.CLAUDE_CODE_OAUTH_TOKEN"
            SECURITY_ISSUES=$((SECURITY_ISSUES + 1))
          fi
          
          # Check for HEREDOC with GitHub Actions variables (causes YAML parsing errors)
          if awk '/cat.*<<.*EOF/,/^EOF$/' "$WORKFLOW_PATH" 2>/dev/null | grep -qE '\$\{\{'; then
            echo "üö® CRITICAL: HEREDOC with GitHub Actions variables detected! This causes YAML parsing errors"
            echo "  Lines with issues:"
            awk '/cat.*<<.*EOF/,/^EOF$/' "$WORKFLOW_PATH" | grep -n '\$\{\{' | head -5
            SECURITY_ISSUES=$((SECURITY_ISSUES + 1))
          fi
          
          # Check for any exposed tokens or API keys (not using secrets)
          if grep -E '(api[_-]key|token|bearer|secret)\s*:\s*["\047]?[A-Za-z0-9_-]{20,}' "$WORKFLOW_PATH" 2>/dev/null | grep -v 'secrets\.' >/dev/null; then
            echo "üö® CRITICAL: Exposed API keys or tokens detected!"
            SECURITY_ISSUES=$((SECURITY_ISSUES + 1))
          fi
          
          # Check for hardcoded passwords
          if grep -Ei 'password\s*:\s*["\047]' "$WORKFLOW_PATH" 2>/dev/null | grep -v 'secrets\.' >/dev/null; then
            echo "üö® CRITICAL: Hardcoded passwords detected!"
            SECURITY_ISSUES=$((SECURITY_ISSUES + 1))
          fi
          
          # If security issues found, fail immediately
          if [ "$SECURITY_ISSUES" -gt 0 ]; then
            echo "‚ùå SECURITY VALIDATION FAILED - $SECURITY_ISSUES critical issues found"
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "security_failed=true" >> $GITHUB_OUTPUT
            echo "error_count=$SECURITY_ISSUES" >> $GITHUB_OUTPUT
            echo "warning_count=0" >> $GITHUB_OUTPUT
            
            # Create security failure report
            echo '{' > validation_result.json
            echo '  "overall_result": "FAILED",' >> validation_result.json
            echo '  "security_validation": "FAILED",' >> validation_result.json
            echo '  "critical_security_issues": true,' >> validation_result.json
            echo '  "failed_items": [' >> validation_result.json
            echo '    "Exposed OAuth token - must use secrets.CLAUDE_CODE_OAUTH_TOKEN",' >> validation_result.json
            echo '    "Hardcoded credentials detected - use GitHub Secrets"' >> validation_result.json
            echo '  ],' >> validation_result.json
            echo '  "details": {' >> validation_result.json
            echo '    "security_validation": {' >> validation_result.json
            echo '      "status": "FAILED",' >> validation_result.json
            echo '      "message": "Critical security vulnerabilities detected. Workflow must not contain exposed tokens or credentials."' >> validation_result.json
            echo '    }' >> validation_result.json
            echo '  }' >> validation_result.json
            echo '}' >> validation_result.json
            exit 0
          fi
          
          echo "‚úÖ Security validation passed"
          
          # YAML syntax validation
          python -c "import yaml; yaml.safe_load(open('$WORKFLOW_PATH'))"
          echo "‚úÖ YAML syntax valid"
          
          # GitHub Actions structure validation (robust against quoted keys)
          python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; wf=yaml.safe_load(open(wf_path)) or {}; sys.exit(0 if isinstance(wf, dict) and 'name' in wf and 'on' in wf and 'jobs' in wf else 1)"
          if [ $? -eq 0 ]; then
            echo "‚úÖ GitHub Actions structure valid"

            # Input schema compliance validation (file-referenced, no inline duplication)
            if [ -f "artifacts/domain-input-schema/input-schema.yaml" ]; then
              python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; schema_path='artifacts/domain-input-schema/input-schema.yaml'; wf=yaml.safe_load(open(wf_path)) or {}; schema=yaml.safe_load(open(schema_path)) or {}; wf_inputs=(((wf.get('on') or {}).get('workflow_dispatch') or {}).get('inputs') or {}); groups=(schema.get('inputs') or {}); required=(groups.get('required') or {}); missing=[k for k in required.keys() if k not in wf_inputs]; (print('Missing inputs in workflow:', missing) or sys.exit(1)) if missing else None"
              echo "‚úÖ Input schema alignment (required): OK"
            else
              echo "::warning::No input schema file found for validation"
            fi

            # Static structural checks (non-domain specific)
            echo "üîé Static structural checks..."
            python3 -c "import os, re, sys, yaml; wf_path='$WORKFLOW_PATH'; text=open(wf_path,'r',encoding='utf-8').read(); data=yaml.safe_load(text) or {}; jobs=data.get('jobs') or {}; warnings=[]; [warnings.append(f\"Local action reference detected in job '{job_name}': uses={uses}\") if uses.startswith(('./','../')) else warnings.append(f\"Suspicious action reference (missing @) in job '{job_name}': uses={uses}\") if '@' not in uses and not uses.startswith('docker://') else None for job_name,job in (jobs or {}).items() for step in (job or {}).get('steps',[]) or [] if isinstance(step,dict) and 'uses' in step for uses in [str(step['uses']).strip()]]; warnings.append('No \${PROJECT_DIR}/ occurrences found') if '\${PROJECT_DIR}/' not in text else None; warnings.append('actions/upload-artifact not found') if not re.search(r'actions/upload-artifact@',text) else None; warnings.append('actions/download-artifact not found') if not re.search(r'actions/download-artifact@',text) else None; [print(f'::warning ::{w}') for w in warnings]; print(f'Static checks: {len(warnings)} warning(s)')"
            
            # Domain-aware validation (generic, non-specialized)
            echo "üîç Executing domain-aware validation (generic)..."
            DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
            CONSTRAINTS_PATH="meta/domain-templates/$DOMAIN/constraints.yaml"
            {
              echo "Âü∫Êú¨Ê§úË®º„Å®ÔºàÂ≠òÂú®„Åô„ÇãÂ†¥ÂêàÔºâ„Éâ„É°„Ç§„É≥Âà∂Á¥Ñ„ÅÆÊ§úË®º„ÇíË°å„ÅÑ„ÄÅvalidation_result.json „Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ";
              echo;
              echo "ÂØæË±°„ÉØ„Éº„ÇØ„Éï„É≠„Éº: $WORKFLOW_PATH";
              echo "Âà∂Á¥Ñ„Éï„Ç°„Ç§„É´: $CONSTRAINTS_PATH (Â≠òÂú®„Åô„ÇãÂ†¥Âêà„ÅÆ„Åø)";
              echo;
              echo "Âü∫Êú¨Ê§úË®º:";
              echo "- uses: „Åß„É≠„Éº„Ç´„É´„Éë„ÇπÂèÇÁÖß„ÅåÁÑ°„ÅÑ„Åì„Å®";
              echo "- ÁîüÊàêÁâ©„ÅØ projects/ ÈÖç‰∏ã„Å´‰øùÂ≠ò„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®";
              echo "- „Ç∏„Éß„ÉñÈñìÂÖ±Êúâ„Å´ artifacts „Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Çã„Åì„Å®";
              echo "- „Éè„Éº„Éâ„Ç≥„Éº„Éâ„Åï„Çå„Åü„Éë„Çπ„ÅåÁÑ°„ÅÑ„Åì„Å®ÔºàÂãïÁöÑÂèÇÁÖß„Çí‰ΩøÁî®Ôºâ";
              echo "- „Ç∑„Çß„É´„Çπ„ÇØ„É™„Éó„Éà„ÅßË§áÊï∞Ë°åÊñáÂ≠óÂàó„ÅåÊ≠£„Åó„ÅèÂá¶ÁêÜ„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®";
              echo "- video-production„Éâ„É°„Ç§„É≥„ÅÆÂ†¥Âêà:";
              echo "  * ÂêÑ„Ç∑„Éº„É≥ÁîªÂÉèÁîüÊàê„ÅåÁã¨Á´ã„Ç∏„Éß„ÉñÔºàphase3-scene-N-imageÔºâ„Å®„Åó„Å¶Â≠òÂú®";
              echo "  * ÂêÑ„Ç∑„Éº„É≥ÂãïÁîªÂ§âÊèõ„ÅåÁã¨Á´ã„Ç∏„Éß„ÉñÔºàphase4-scene-N-videoÔºâ„Å®„Åó„Å¶Â≠òÂú®";
              echo "  * phase4„Ååphase3„ÅÆÂØæÂøú„Åô„Çã„Ç∑„Éº„É≥„Å´‰æùÂ≠òÔºàneedsÔºâ„Åó„Å¶„ÅÑ„Çã„Åì„Å®";
              echo "  * „Éã„É•„Éº„Çπ„Ç≠„É£„Çπ„Çø„ÉºÁî®„ÅÆÂõ∫ÂÆöseedÂÄ§„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®";
              echo "  * „Ç∑„Éº„É≥Êï∞„ÅåÂãïÁöÑ„Å´Ë®àÁÆó„Åï„Çå„ÅüÂÄ§„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Çã„Åì„Å®";
              echo;
              echo "Âà∂Á¥ÑÊ§úË®ºÔºà‰ªªÊÑèÔºâ:";
              echo "- constraints.composition_rules „Åå„ÅÇ„Çå„Å∞„ÄÅ„Åù„ÅÆË¶Å‰ª∂Ôºàpipeline/matrix/max_parallel/duration_allocationÔºâ„Å´Ê≤ø„Å£„Å¶„ÅÑ„Çã„Åì„Å®";
              echo "- constraints.rule_references „Å® checklist_references „ÅåÁ§∫„Åô„Éï„Ç°„Ç§„É´„ÇíÈ†Ü„Å´Ë™≠„Åø„ÄÅMUST„ÇíÂÑ™ÂÖà„Åó„Å¶Â¶•ÂΩìÊÄß„ÇíÁ¢∫Ë™ç„Åô„Çã„Åì„Å®";
              echo "- Áõ¥Âàó/‰∏¶Âàó/matrix/ÂëΩÂêç/‰∏ÄË≤´ÊÄß/ÊôÇÈñìÈÖçÂàÜ„Å™„Å©„ÅÆË¶èÂâá„Åå„ÅÇ„Çå„Å∞ÈÅ©Áî®„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®";
              echo;
              echo '{"overall_result":"PASSED","failed_items":[],"details":{}}';
            } > validation_prompt.txt
            
            # Replace placeholder with actual path
            sed -i "s|WORKFLOW_PATH_PLACEHOLDER|$WORKFLOW_PATH|g" validation_prompt.txt
            
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "Read,Write" \
              --permission-mode "acceptEdits" \
              --max-turns 30 \
              -p "$(cat validation_prompt.txt)"
            
            # Ensure validation_result.json exists (create minimal PASSED if missing)
            if [ ! -f "validation_result.json" ]; then
              echo "‚ö†Ô∏è validation_result.json not created - creating minimal PASSED report"
              echo '{"overall_result":"PASSED","failed_items":[],"details":{}}' > validation_result.json
            fi

            # Domain rule structural checks (non-blocking warnings)
            echo "üîé Domain rule structural checks..."
            python3 -c "import os, re, sys, yaml, json; wf_path='$WORKFLOW_PATH'; domain='${{ needs.validate-and-detect.outputs.primary_domain }}'; constraints_path=f'meta/domain-templates/{domain}/constraints.yaml'; constraints=yaml.safe_load(open(constraints_path, 'r', encoding='utf-8')) if os.path.exists(constraints_path) else {}; rule_refs=constraints.get('rule_references') or []; rules_by_name={}; [rules_by_name.update({p: yaml.safe_load(open(p, 'r', encoding='utf-8')) if os.path.exists(p) and p.endswith(('.yaml','.yml')) else None}) for ref in rule_refs if (p:=(ref or {}).get('path'))]; text=open(wf_path, 'r', encoding='utf-8').read(); data=yaml.safe_load(text) or {}; jobs=data.get('jobs') or {}; warns=[]; orc=next((v for k,v in rules_by_name.items() if k.endswith('/rules/orchestration.yaml') and isinstance(v, dict)), None); matrix_key=(((orc.get('matrix') or {}).get('key')) or 'scene') if orc else 'scene'; max_parallel_lim=((orc.get('matrix') or {}).get('max_parallel')) if orc else None; found=any(matrix_key in ((job or {}).get('strategy') or {}).get('matrix', {}) for job in (jobs or {}).values() if isinstance(((job or {}).get('strategy') or {}).get('matrix'), dict)); warns.append(f\"No job with strategy.matrix containing key '{matrix_key}' found\") if orc and not found else None; cons=next((v for k,v in rules_by_name.items() if k.endswith('/rules/consistency.yaml') and isinstance(v, dict)), None); img_pat=((cons.get('naming') or {}).get('image_pattern')) if cons else None; vid_pat=((cons.get('naming') or {}).get('video_pattern')) if cons else None; warns.append('Scene image naming pattern not referenced in workflow text (scene_)') if img_pat and 'scene_' not in text else None; warns.append('Scene video naming pattern not referenced in workflow text (scene_)') if vid_pat and 'scene_' not in text else None; [print(f'::warning ::{w}') for w in warns]; print(f'Domain rule checks: {len(warns)} warning(s)')"
            
            # Check validation result from JSON
            if [ -f "validation_result.json" ]; then
              VALIDATION_RESULT=$(jq -r '.overall_result' validation_result.json 2>/dev/null || echo "FAILED")
              CRITICAL_PASS=$(jq -r '.critical_pass_count' validation_result.json 2>/dev/null || echo "0/10")
              FAILED_ITEMS=$(jq -r '.failed_items[]' validation_result.json 2>/dev/null || echo "Unknown")
              
              echo "üìä Validation Result: $VALIDATION_RESULT"
              echo "üìä Critical Requirements: $CRITICAL_PASS"
              
              if [ "$VALIDATION_RESULT" = "PASSED" ]; then
                echo "‚úÖ STRICT validation PASSED - All critical requirements met"
                echo "passed=true" >> $GITHUB_OUTPUT
                
                # Add detailed validation report to summary
                echo "### üéØ Strict Validation Report" >> $GITHUB_STEP_SUMMARY
                echo "- **Result**: ‚úÖ PASSED" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical Requirements**: $CRITICAL_PASS" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              else
                echo "‚ùå STRICT validation FAILED - Critical requirements not met"
                echo "‚ùå Failed items: $FAILED_ITEMS"
                
                # Add failure report to summary
                echo "### üö® Strict Validation Report" >> $GITHUB_STEP_SUMMARY
                echo "- **Result**: ‚ùå FAILED" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical Requirements**: $CRITICAL_PASS" >> $GITHUB_STEP_SUMMARY
                echo "- **Failed Items**:" >> $GITHUB_STEP_SUMMARY
                echo "$FAILED_ITEMS" | while read item; do
                  echo "  - $item" >> $GITHUB_STEP_SUMMARY
                done
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "- **Action**: Attempting auto-fix..." >> $GITHUB_STEP_SUMMARY

                echo "üîß Attempting generic auto-fix based on domain constraints..."

                # Build rule file list from constraints (if any) for precise autofix
                RULE_FILES=$(jq -r '.constraints.rule_references[]?.path' artifacts/domain-template-data/domain_summary.json 2>/dev/null || true)
                CHECKLIST_FILES=$(jq -r '.constraints.checklist_references[]?.path' artifacts/domain-template-data/domain_summary.json 2>/dev/null || true)

                echo "üîß AI auto-fix with explicit domain rule inputs..."
                npx @anthropic-ai/claude-code \
                  --mcp-config ".claude/mcp-kamuicode.json" \
                  --allowedTools "Read,Write" \
                  --permission-mode "acceptEdits" \
                  --max-turns 40 \
                  -p "Ê¨°„ÅÆ„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„Åø„ÄÅÊ§úË®ºÂ§±Êïó„Çí‰øÆÊ≠£„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

                  ÂØæË±°„ÉØ„Éº„ÇØ„Éï„É≠„Éº: $WORKFLOW_PATH
                  Ê§úË®ºÁµêÊûú: validation_result.json
                  „Éâ„É°„Ç§„É≥: $DOMAIN
                  Âà∂Á¥Ñ: $CONSTRAINTS_PATH
                  „É´„Éº„É´„Éï„Ç°„Ç§„É´‰∏ÄË¶ß:\n$RULE_FILES
                  „ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà‰∏ÄË¶ß:\n$CHECKLIST_FILES

                  ÂøÖÈ†à‰øÆÊ≠£ÔºàMUSTÔºâ:
                  1) „É≠„Éº„Ç´„É´ uses „ÅÆÊéíÈô§ / „Åô„Åπ„Å¶„ÅÆÂá∫Âäõ„Çí ${PROJECT_DIR} ÈÖç‰∏ã„Å∏ / artifacts „Å´„Çà„ÇãÂÖ±Êúâ
                  2) constraints.composition_rules / rules/orchestration.yaml „Å´Âæì„ÅÑ„ÄÅË©≤ÂΩì„Çø„Çπ„ÇØ„Åå„ÅÇ„ÇãÂ†¥Âêà:
                     - per-item/perscene Áõ¥Âàó„ÉÅ„Çß„Éº„É≥Ôºà‰æã: generate_image -> image_to_videoÔºâ„ÇíÂêå‰∏Ä„Ç∏„Éß„ÉñÂÜÖ„ÅßÂÆüË°å
                     - strategy.matrix „ÇíÂ∞éÂÖ•„Åó„ÄÅmatrix.keyÔºàrules„ÅÆmatrix.keyÔºâ„Åß‰∏¶ÂàóÂåñ
                     - strategy.max-parallel „Çí rules„ÅÆ max_parallel ‰ª•‰∏ã„Å´Ë®≠ÂÆö
                  3) rules/consistency.yaml „ÅÆÂëΩÂêçË¶èÁ¥ÑÔºàimage_pattern / video_patternÔºâ„Å®Ëß£ÂÉèÂ∫¶/Èü≥Â£∞Âü∫Ê∫ñ„ÇíÊ∫Ä„Åü„Åô„Çà„ÅÜÂëΩÂêç„ÉªË®≠ÂÆö
                  4) paths: ${PROJECT_DIR}/media/{images|videos|audio}/ „Åä„Çà„Å≥ ${PROJECT_DIR}/metadata/ „Å´Êï¥„Åà„Çã

                  Êé®Â•®‰øÆÊ≠£ÔºàSHOULDÔºâ:
                  - checklist „ÅÆ MUST/SHOULD „ÅÆ„ÅÜ„Å°„ÄÅÂÆüË£ÖÂèØËÉΩ„Å™È†ÖÁõÆ„ÅØÈÅ©Áî®

                  Â§âÊõ¥„ÅØ $WORKFLOW_PATH „Å´‰∏äÊõ∏„Åç‰øùÂ≠ò„ÄÇfix_summary.txt „Å´‰øÆÊ≠£ÁÇπ„ÅÆË¶ÅÁ¥ÑÔºàÈÅ©Áî®„Åó„Åü„É´„Éº„É´„ÄÅÂ§âÊõ¥ÁÆáÊâÄÔºâ„ÇíË®òÈå≤„ÄÇ"

                # Safety cap for max-parallel if still exceeding rule limit
                echo "Applying safety cap for max-parallel..."
              
                if [ $? -eq 0 ]; then
                  echo "‚úÖ Auto-fix completed - Re-validating..."
                  
                  # Re-validate after fix
                npx @anthropic-ai/claude-code \
                  --mcp-config ".claude/mcp-kamuicode.json" \
                  --allowedTools "Read,Write" \
                  --permission-mode "acceptEdits" \
                  --max-turns 10 \
                  -p "‰øÆÊ≠£Âæå„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÂÜçÊ§úË®º„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

                  ÂØæË±°: $WORKFLOW_PATH
                  „Éâ„É°„Ç§„É≥: $DOMAIN
                  Âà∂Á¥Ñ: $CONSTRAINTS_PATHÔºàÂ≠òÂú®„Åô„Çå„Å∞Ôºâ
                  
                  1) Âü∫Êú¨Ê§úË®ºÔºà„É≠„Éº„Ç´„É´usesÁ¶ÅÊ≠¢„ÄÅartifactsÂà©Áî®„ÄÅÊßãÈÄ†Â¶•ÂΩìÊÄßÔºâ
                  2) Âà∂Á¥Ñ„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅÆ„Åø composition_rules „ÅÆÈÅ©Áî®Á¢∫Ë™ç
                  ÁµêÊûú„Çí revalidation_result.json „Å´‰øùÂ≠ò"
                  
                  if [ -f "revalidation_result.json" ]; then
                    REVALIDATION_RESULT=$(jq -r '.overall_result' revalidation_result.json 2>/dev/null || echo "FAILED")
                    if [ "$REVALIDATION_RESULT" = "PASSED" ]; then
                      echo "‚úÖ Re-validation PASSED - All issues fixed"
                      echo "passed=true" >> $GITHUB_OUTPUT
                    else
                      echo "‚ùå Re-validation FAILED - Some issues remain"
                      echo "passed=false" >> $GITHUB_OUTPUT
                    fi
                  else
                    echo "‚ùå Re-validation failed to complete"
                    echo "passed=false" >> $GITHUB_OUTPUT
                  fi
                else
                  echo "‚ùå Auto-fix failed - manual intervention required"
                  echo "passed=false" >> $GITHUB_OUTPUT
                fi
              fi
            else
              echo "‚ùå Validation result file not found"
              echo "passed=false" >> $GITHUB_OUTPUT
            fi
            
            # Add Phase 6 Report with detailed validation results
            echo "## üîç Phase 6: Ë©≥Á¥∞Ê§úË®º„É¨„Éù„Éº„Éà" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ YAMLÊßãÊñáÊ§úË®º: Ê≠£Â∏∏" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ GitHub ActionsÊßãÈÄ†Ê§úË®º: Ê≠£Â∏∏" >> $GITHUB_STEP_SUMMARY
            echo "- üìä „Éâ„É°„Ç§„É≥ÁâπÂåñÊ§úË®º: ÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
            
            # Add detailed error/warning counts
            if [ -f "validation_result.json" ]; then
              ERROR_COUNT=$(jq -r '.errors | length' validation_result.json 2>/dev/null || echo "0")
              WARNING_COUNT=$(jq -r '.warnings | length' validation_result.json 2>/dev/null || echo "0")
              echo "- üö® „Ç®„É©„ÉºÊï∞: $ERROR_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "- ‚ö†Ô∏è Ë≠¶ÂëäÊï∞: $WARNING_COUNT" >> $GITHUB_STEP_SUMMARY
              
              # Output counts for next job
              echo "error_count=$ERROR_COUNT" >> $GITHUB_OUTPUT
              echo "warning_count=$WARNING_COUNT" >> $GITHUB_OUTPUT
              echo "report_path=validation_result.json" >> $GITHUB_OUTPUT
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Invalid GitHub Actions structure"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Upload Validation Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: |
            validation_result.json
            revalidation_result.json
          if-no-files-found: warn
          
      - name: Generate Detailed Validation Report
        id: detailed-report
        if: always()
        run: |
          echo "üìä Generating detailed validation report..."
          
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          
          # Create comprehensive validation report
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            --max-turns 20 \
            -p "Ë©≥Á¥∞„Å™Ê§úË®º„É¨„Éù„Éº„Éà„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
            
            ÂØæË±°„ÉØ„Éº„ÇØ„Éï„É≠„Éº: $WORKFLOW_PATH
            „Éâ„É°„Ç§„É≥: $DOMAIN
            
            Ê§úË®ºÈ†ÖÁõÆ:
            1. Ê±éÁî®ÁöÑ„Å™ÂïèÈ°å:
               - HEREDOC + GitHub ActionsÂ§âÊï∞„ÅÆÊ∑∑Âú®
               - „É≠„Éº„Ç´„É´ uses: ÂèÇÁÖß
               - „Éè„Éº„Éâ„Ç≥„Éº„Éâ„Åï„Çå„Åü„Éë„Çπ
               - artifact„ÅÆ‰∏çÈÅ©Âàá„Å™‰ΩøÁî®
            
            2. „Éâ„É°„Ç§„É≥ÁâπÂåñ„ÅÆÂïèÈ°å ($DOMAIN):
               - „Ç≠„É£„Çπ„Çø„ÉºÂàÜÈõ¢„Ç∑„Çπ„ÉÜ„É†„ÅÆÂÆüË£Ö
               - 5Áßí„Çª„Ç∞„É°„É≥„Éà„É™„ÉÉ„Éó„Ç∑„É≥„ÇØ
               - ËÉåÊôØ„Å´‰∫∫Áâ©„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åã
            
            3. ÊßãÈÄ†ÁöÑ„Å™ÂïèÈ°å:
               - „Ç∏„Éß„Éñ‰æùÂ≠òÈñ¢‰øÇ„ÅÆÊ≠£„Åó„Åï
               - matrix„ÅÆ‰ΩøÁî®ÊñπÊ≥ï
               - „Éë„É©„É¨„É´ÂÆüË°å„ÅÆÊúÄÈÅ©ÊÄß
            
            „É¨„Éù„Éº„Éà„Çí detailed_validation_report.json „Å´‰øùÂ≠ò:
            {
              \"total_errors\": 0,
              \"total_warnings\": 0,
              \"critical_issues\": [],
              \"generic_issues\": [],
              \"domain_specific_issues\": [],
              \"structural_issues\": [],
              \"fix_priority\": [],
              \"auto_fixable\": [],
              \"manual_fix_required\": []
            }"
          
      - name: Post Validation Summary to Issue
        if: always()
        run: |
          # Use input parameter for workflow_dispatch, or job output for issue_comment
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            ISSUE_NUMBER="${{ inputs.issue_number }}"
          else
            ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          fi
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          VALIDATION_RESULT="${{ steps.validate.outputs.passed }}"
          
          if [ "$VALIDATION_RESULT" = "true" ]; then
            gh issue comment "$ISSUE_NUMBER" --body "## ‚úÖ Workflow Generation & Validation Complete!
            
            **Workflow**: \`$WORKFLOW_NAME\`
            **Domain**: $DOMAIN
            **Validation**: ‚úÖ PASSED
            
            ### üéØ All checks passed:
            - YAML syntax valid
            - GitHub Actions structure correct
            - Domain-specific requirements met
            
            ### üì¶ Download:
            Download the validated workflow from run artifacts.
            
            ---
            *Meta Workflow v12*"
          else
            ERROR_COUNT="${{ steps.validate.outputs.error_count }}"
            WARNING_COUNT="${{ steps.validate.outputs.warning_count }}"
            
            gh issue comment "$ISSUE_NUMBER" --body "## ‚ö†Ô∏è Workflow Validation Failed
            
            **Workflow**: \`$WORKFLOW_NAME\`
            **Domain**: $DOMAIN
            **Validation**: ‚ùå FAILED
            
            ### üí° Issues Found:
            - **Errors**: $ERROR_COUNT
            - **Warnings**: $WARNING_COUNT
            
            ### üîÑ Next Action:
            Triggering automatic regeneration with fixes...
            
            ---
            *Check the regeneration job for updated workflow*"
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ===========================================
  # PHASE 7: ERROR FIX LOOP (IF NEEDED)
  # ===========================================
  
  regeneration-loop:
    name: "üîß „Ç®„É©„Éº‰øÆÊ≠£„É´„Éº„Éó"
    runs-on: ubuntu-latest
    needs: ['validate-workflow', 'validate-and-detect', 'load-domain-templates']
    if: |
      always() && 
      needs.validate-workflow.result == 'success' &&
      needs.validate-workflow.outputs.validation_passed == 'false'
    outputs:
      regeneration_attempt: ${{ steps.attempt.outputs.regeneration_attempt }}
      regeneration_success: ${{ steps.fix-workflow.outputs.success }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Environment
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml
          
      - name: Download All Previous Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Record Fix Attempt
        id: attempt
        run: |
          echo "üîß Ê§úË®ºÂ§±Êïó„Å´„Çà„Çã„Ç®„É©„Éº‰øÆÊ≠£„ÇíÈñãÂßã..."
          ATTEMPT_COUNT=1
          echo "regeneration_attempt=$ATTEMPT_COUNT" >> $GITHUB_OUTPUT
          
          echo "## üîß Phase 7: „Ç®„É©„Éº‰øÆÊ≠£„É´„Éº„Éó" >> $GITHUB_STEP_SUMMARY
          echo "- üö® ÂàùÂõûÁîüÊàê„ÅÆÊ§úË®ºÂ§±Êïó„ÇíÊ§úÂá∫" >> $GITHUB_STEP_SUMMARY
          echo "- üîß „Éî„É≥„Éù„Ç§„É≥„Éà‰øÆÊ≠£„ÇíÂÆüË°å‰∏≠..." >> $GITHUB_STEP_SUMMARY
          
      - name: Analyze Validation Failures
        id: analyze
        run: |
          echo "üîç Ê§úË®ºÂ§±Êïó„ÅÆË©≥Á¥∞ÂàÜÊûê..."
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          
          # Extract specific failure reasons from previous validation
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            --max-turns 20 \
            -p "Ê§úË®ºÂ§±Êïó„ÅÆÂéüÂõ†„ÇíË©≥Á¥∞ÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
            
          ÂèÇÁÖß„Éï„Ç°„Ç§„É´:
          1. artifacts/validation-report/detailed_validation_report.json (Ë©≥Á¥∞Ê§úË®º„É¨„Éù„Éº„Éà)
          2. artifacts/validation-report/validation_result.json (Âü∫Êú¨Ê§úË®ºÁµêÊûú)
          3. projects/workflow-execution-logs/meta-workflow-construction-checklist.md (Ê±éÁî®Â§±Êïó„Éë„Çø„Éº„É≥)
          4. meta/domain-templates/$DOMAIN/checklists/ („Éâ„É°„Ç§„É≥ÁâπÂåñ„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà)
          5. docs/CLAUDE_CODE_DATA_PERSISTENCE_GUIDE.md („Éá„Éº„ÇøÊ∞∏Á∂öÂåñ„Éë„Çø„Éº„É≥)
          6. docs/YAML_CONSTRUCTION_GUIDELINES.md (YAMLÊßãÁØâ„Ç¨„Ç§„Éâ„É©„Ç§„É≥)
          
          ÂàÜÊûêÈ†ÖÁõÆ:
          - HEREDOC„Å®GitHub ActionsÂ§âÊï∞„ÅÆÊ∑∑Âú®ÂïèÈ°å
          - „É≠„Éº„Ç´„É´uses:ÂèÇÁÖß„ÅÆÂïèÈ°å
          - „Éï„Ç°„Ç§„É´„Éë„Çπ„ÅÆ„Éè„Éº„Éâ„Ç≥„Éº„ÉâÂïèÈ°å
          - „Ç¢„Éº„ÉÜ„Ç£„Éï„Ç°„ÇØ„ÉàÂÖ±Êúâ„ÅÆÂïèÈ°å
          - „Éâ„É°„Ç§„É≥ÁâπÊúâ„ÅÆË¶Å‰ª∂ÈÅïÂèçÔºà„Ç≠„É£„Çπ„Çø„ÉºÂàÜÈõ¢„ÄÅ„É™„ÉÉ„Éó„Ç∑„É≥„ÇØÁ≠âÔºâ
          
          ÂàÜÊûêÁµêÊûú„Çíartifacts/failure_analysis.json„Å´‰øùÂ≠ò„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
          {
            \"failure_reasons\": [\"ÂéüÂõ†1\", \"ÂéüÂõ†2\"],
            \"critical_issues\": [\"ÈáçË¶Å„Å™ÂïèÈ°å1\", \"ÈáçË¶Å„Å™ÂïèÈ°å2\"],
            \"improvement_strategy\": \"ÊîπÂñÑÊà¶Áï•„ÅÆË©≥Á¥∞\",
            \"regeneration_focus\": [\"ÂÜçÁîüÊàê„ÅßÁâπ„Å´Ê≥®ÊÑè„Åô„Åπ„ÅçÁÇπ1\", \"ÁÇπ2\"],
            \"heredoc_issues\": [\"HEREDOCÂïèÈ°å„ÅÆ„ÅÇ„ÇãË°åÁï™Âè∑\"],
            \"local_uses_issues\": [\"„É≠„Éº„Ç´„É´usesÂèÇÁÖß„ÅÆÂ†¥ÊâÄ\"],
            \"domain_specific_issues\": [\"„Éâ„É°„Ç§„É≥ÁâπÊúâ„ÅÆÂïèÈ°å\"]
          }"
          
          if [ -f "artifacts/failure_analysis.json" ]; then
            echo "‚úÖ Â§±ÊïóÂàÜÊûêÂÆå‰∫Ü"
            echo "- ‚úÖ Â§±ÊïóÂéüÂõ†„ÅÆÁâπÂÆöÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Â§±ÊïóÂàÜÊûê„Å´Â§±Êïó - Fallback„Çí‰ΩúÊàê"
            # Fallback: use validation report to craft minimal analysis
            REPORT_DIR="artifacts/validation-report"
            REPORT_FILE=""
            if [ -f "$REPORT_DIR/validation_result.json" ]; then
              REPORT_FILE="$REPORT_DIR/validation_result.json"
            elif [ -f "validation_result.json" ]; then
              REPORT_FILE="validation_result.json"
            fi
            mkdir -p artifacts
            if [ -n "$REPORT_FILE" ]; then
              jq -n --argjson failed "$(jq -r '.failed_items // []' "$REPORT_FILE" 2>/dev/null || echo '[]')" '{failure_reasons:$failed, critical_issues:$failed, improvement_strategy:"Auto-fallback from validation_result.json", regeneration_focus:$failed}' > artifacts/failure_analysis.json || echo '{"failure_reasons":[],"critical_issues":[],"improvement_strategy":"fallback","regeneration_focus":[]}' > artifacts/failure_analysis.json
              echo "- ‚ö†Ô∏è Fallback failure_analysis.json „Çí‰ΩúÊàê" >> $GITHUB_STEP_SUMMARY
            else
              echo '{"failure_reasons":[],"critical_issues":[],"improvement_strategy":"no-report","regeneration_focus":[]}' > artifacts/failure_analysis.json
              echo "- ‚ö†Ô∏è Ê§úË®º„É¨„Éù„Éº„ÉàÊú™Ê§úÂá∫„ÅÆ„Åü„ÇÅÁ©∫„ÅÆÂàÜÊûê„Çí‰ΩúÊàê" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
      - name: Fix Workflow Errors (Pinpoint Fixes)
        id: fix-workflow
        run: |
          echo "üîß „Ç®„É©„ÉºÁÆáÊâÄ„ÅÆ„Éî„É≥„Éù„Ç§„É≥„Éà‰øÆÊ≠£„ÇíÂÆüË°å..."
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          PROJECT_DIR="${{ needs.generate-professional-workflow.outputs.project_dir }}"
          
          # Get the previously generated workflow path
          PREVIOUS_WORKFLOW=$(find artifacts/generated-workflow -name "*.yml" -type f | head -1)
          
          if [ -z "$PREVIOUS_WORKFLOW" ]; then
            echo "‚ùå ÂâçÂõûÁîüÊàê„Åó„Åü„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì"
            exit 1
          fi
          
          echo "üìù ‰øÆÊ≠£ÂØæË±°„ÉØ„Éº„ÇØ„Éï„É≠„Éº: $PREVIOUS_WORKFLOW"
          
          # Create fix directory
          FIX_DIR="projects/issue-$ISSUE_NUMBER-fixes-$(date +%Y%m%d-%H%M%S)"
          mkdir -p "$FIX_DIR/logs"
          
          # Copy original workflow for backup
          cp "$PREVIOUS_WORKFLOW" "$FIX_DIR/original-workflow.yml"
          
          # Fix loop - up to 5 iterations for thorough fixes
          MAX_FIX_ATTEMPTS=5
          FIX_SUCCESS=false
          
          for fix_attempt in $(seq 1 $MAX_FIX_ATTEMPTS); do
            echo "üîÑ ‰øÆÊ≠£Ë©¶Ë°å $fix_attempt/$MAX_FIX_ATTEMPTS"
            
            # Collect detailed error information before fix
            echo "üìã „Ç®„É©„ÉºË©≥Á¥∞„ÇíÂèéÈõÜ‰∏≠..."
            ERROR_DETAILS=""
            
            # Check for HEREDOC with GitHub Actions variables (HIGHEST PRIORITY)
            if awk '/cat.*<<.*EOF/,/^EOF$/' "$PREVIOUS_WORKFLOW" 2>/dev/null | grep -qE '\$\{\{'; then
              HEREDOC_LINES=$(awk '/cat.*<<.*EOF/,/^EOF$/' "$PREVIOUS_WORKFLOW" | grep -n '\$\{\{' | head -5)
              ERROR_DETAILS="${ERROR_DETAILS}
            HEREDOCÂÜÖ„ÅÆGitHub ActionsÂ§âÊï∞ÔºàYAMLÊßãÊñá„Ç®„É©„Éº„ÅÆÂéüÂõ†Ôºâ:
            ${HEREDOC_LINES}"
              echo "üö® HEREDOC with GitHub Actions variables detected"
            fi
            
            # Check for exposed tokens with line numbers
            if grep -n 'sk-ant-' "$PREVIOUS_WORKFLOW" 2>/dev/null; then
              TOKEN_LINES=$(grep -n 'sk-ant-' "$PREVIOUS_WORKFLOW" | head -3)
              ERROR_DETAILS="${ERROR_DETAILS}
            Èú≤Âá∫„Åó„ÅüOAuth„Éà„Éº„ÇØ„É≥:
            ${TOKEN_LINES}"
            fi
            
            # Check for hardcoded paths with line numbers
            if grep -n -E '"/home/runner/work/[^"]*"' "$PREVIOUS_WORKFLOW" 2>/dev/null | grep -vF '${' | grep -q .; then
              PATH_LINES=$(grep -n -E '"/home/runner/work/[^"]*"' "$PREVIOUS_WORKFLOW" | grep -vF '${' | head -3)
              ERROR_DETAILS="${ERROR_DETAILS}
            „Éè„Éº„Éâ„Ç≥„Éº„Éâ„Åï„Çå„Åü„Éë„Çπ:
            ${PATH_LINES}"
            fi
            
            # Apply pinpoint fixes with detailed error information
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "Read,Write,Edit,MultiEdit" \
              --permission-mode "acceptEdits" \
              --max-turns 40 \
              -p "„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÅÆ„Ç®„É©„Éº„Çí„Éî„É≥„Éù„Ç§„É≥„Éà‰øÆÊ≠£„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
              
            ÂØæË±°„ÉØ„Éº„ÇØ„Éï„É≠„Éº: $PREVIOUS_WORKFLOW
            
            Ê§úÂá∫„Åï„Çå„Åü„Ç®„É©„ÉºÔºàË°åÁï™Âè∑‰ªò„ÅçÔºâ:
            $ERROR_DETAILS
            
            „ÄêÈáçË¶Å„Äë‰øÆÊ≠£ÊâãÈ†ÜÔºàÂøÖ„Åö„Åì„ÅÆÈ†ÜÁï™„ÅßÂÆüË°åÔºâ:
            1. Read „ÉÑ„Éº„É´„Åß„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄ: $PREVIOUS_WORKFLOW
            2. ‰ª•‰∏ã„ÅÆ„Éë„Çø„Éº„É≥„Çí„Åô„Åπ„Å¶Ê§úÁ¥¢„Åó„Å¶‰øÆÊ≠£:
               - sk-ant-„ÅßÂßã„Åæ„Çã„Éà„Éº„ÇØ„É≥ ‚Üí \${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
               - /home/runner/work/kamuicode_meta/kamuicode_meta/ ‚Üí \${{ github.workspace }}/
               - HEREDOC„Å®GitHub ActionsÂ§âÊï∞ ‚Üí echo„Ç≥„Éû„É≥„Éâ„Å´Â§âÊèõ
               - uses: ./ ‚Üí „Ç§„É≥„É©„Ç§„É≥ÂÆüË£Ö
               - outputs:.*matrix\\. ‚Üí Ê≠£„Åó„ÅÑÊßãÊñá„Å´‰øÆÊ≠£
            3. MultiEdit „Åæ„Åü„ÅØ Edit „ÉÑ„Éº„É´„Åß‰øÆÊ≠£„ÇíÈÅ©Áî®
            4. Write „ÉÑ„Éº„É´„Åß‰øÆÊ≠£ÂÜÖÂÆπ„Çí‰øùÂ≠ò: $PREVIOUS_WORKFLOWÔºàÂøÖÈ†àÔºâ
            5. Write „ÉÑ„Éº„É´„Åß„Çµ„Éû„É™„Éº‰øùÂ≠ò: $FIX_DIR/logs/fix_attempt_${fix_attempt}.txt
            
            ÈáçË¶Å„Å™Âà∂Á¥Ñ:
            - Êó¢Â≠ò„ÅÆÊ©üËÉΩ„ÇÑ„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂâäÈô§„Åó„Å™„ÅÑ
            - „Ç∏„Éß„Éñ„ÅÆÊßãÈÄ†„ÇíÁ∂≠ÊåÅ„Åô„Çã
            - ÂøÖË¶Å„Å™Âá¶ÁêÜ„ÅØÂÖ®„Å¶ÊÆã„Åô
            - ÂøÖ„ÅöWrite„ÉÑ„Éº„É´„ÅßÊòéÁ§∫ÁöÑ„Å´‰øùÂ≠ò„Åô„Çã
            
            ÂèÇÁÖß„Ç¨„Ç§„Éâ„É©„Ç§„É≥ÔºàÂøÖ„ÅöË™≠„Çì„Åß„Éë„Çø„Éº„É≥„ÇíÈÅ©Áî®Ôºâ:
            - docs/WORKFLOW_FIX_PATTERNS.md Ôºà‰øÆÊ≠£„Éë„Çø„Éº„É≥ÈõÜ - ÊúÄÂÑ™ÂÖàÔºâ
            - docs/YAML_CONSTRUCTION_GUIDELINES.md
            - docs/CLAUDE_CODE_DATA_PERSISTENCE_GUIDE.md"
            CLI_STATUS=$?
            
            # Log Claude Code execution status
            echo "üìù Claude CodeÂÆüË°å„Çπ„ÉÜ„Éº„Çø„Çπ: $CLI_STATUS"
            
            if [ $CLI_STATUS -eq 0 ]; then
              echo "‚úÖ Claude CodeÂÆüË°åÊàêÂäü"
              # Don't break yet - verify fixes first
            else
              echo "‚ùå Claude CodeÂÆüË°åÂ§±Êïó"
              continue
            fi
            
            # Re-validate after fix
            echo "üîç ‰øÆÊ≠£Âæå„ÅÆÂÜçÊ§úË®º..."
            python3 -c "import yaml; yaml.safe_load(open('$PREVIOUS_WORKFLOW'))" 2>/dev/null
            if [ $? -eq 0 ]; then
              echo "‚úÖ YAMLÊßãÊñá: Ê≠£Â∏∏"
              
              # Check for common issues with more accurate patterns
              ERROR_COUNT=0
              
              # Check for HEREDOC with GitHub Actions variables (more precise check)
              # Look for HEREDOC blocks that contain dollar-brace within them
              if awk '/cat.*<<.*EOF/,/^EOF$/' "$PREVIOUS_WORKFLOW" | grep -qE '\$\{|github\.|needs\.|matrix\.'; then
                echo "‚ö†Ô∏è HEREDOC„Å®GitHub ActionsÂ§âÊï∞„ÅÆÊ∑∑Âú®„Åå„Åæ„Å†Â≠òÂú®"
                ERROR_COUNT=$((ERROR_COUNT + 1))
              fi
              
              # Check for local uses references
              if grep -q 'uses:.*\./' "$PREVIOUS_WORKFLOW"; then
                echo "‚ö†Ô∏è „É≠„Éº„Ç´„É´usesÂèÇÁÖß„Åå„Åæ„Å†Â≠òÂú®"
                ERROR_COUNT=$((ERROR_COUNT + 1))
              fi
              
              # Check for hardcoded absolute paths (more precise pattern)
              # Look for paths that are not using GitHub Actions variables
              if grep -E '"/home/runner/work/[^"]*"' "$PREVIOUS_WORKFLOW" 2>/dev/null | grep -vF '${' | grep -q .; then
                echo "‚ö†Ô∏è „Éè„Éº„Éâ„Ç≥„Éº„Éâ„Åï„Çå„ÅüÁµ∂ÂØæ„Éë„Çπ„Åå„Åæ„Å†Â≠òÂú®"
                echo "  Ê§úÂá∫„Åï„Çå„ÅüË°å:"
                grep -n -E '"/home/runner/work/[^"]*"' "$PREVIOUS_WORKFLOW" | grep -vF '${' | head -3
                ERROR_COUNT=$((ERROR_COUNT + 1))
              fi
              
              if [ $ERROR_COUNT -eq 0 ]; then
                echo "‚úÖ ‰øÆÊ≠£ÊàêÂäü - ÂÖ®„Å¶„ÅÆ„Ç®„É©„Éº„ÅåËß£Ê±∫"
                FIX_SUCCESS=true
                break
              else
                echo "‚ö†Ô∏è „Åæ„Å† $ERROR_COUNT ÂÄã„ÅÆ„Ç®„É©„Éº„ÅåÊÆã„Å£„Å¶„ÅÑ„Åæ„Åô"
                if [ $fix_attempt -lt $MAX_FIX_ATTEMPTS ]; then
                  echo "üîÑ Ê¨°„ÅÆ‰øÆÊ≠£Ë©¶Ë°å„ÇíÊ∫ñÂÇô..."
                  sleep 5
                fi
              fi
            else
              echo "‚ùå YAMLÊßãÊñá„Ç®„É©„Éº„ÅåÊÆã„Å£„Å¶„ÅÑ„Åæ„Åô"
              if [ $fix_attempt -lt $MAX_FIX_ATTEMPTS ]; then
                echo "üîÑ ÊßãÊñá„Ç®„É©„Éº„Çí‰øÆÊ≠£„Åó„Å¶ÂÜçË©¶Ë°å..."
              fi
            fi
          done
          
          # Final verification and result
          if [ "$FIX_SUCCESS" = "true" ]; then
            # Double-check that critical errors are actually fixed
            FINAL_VERIFICATION_PASSED=true
            echo "üîç ÊúÄÁµÇÊ§úË®º„ÇíÂÆüË°å‰∏≠..."
            
            # Check for exposed OAuth tokens
            if grep -q 'sk-ant-' "$PREVIOUS_WORKFLOW" 2>/dev/null; then
              echo "‚ùå ÊúÄÁµÇÊ§úË®ºÂ§±Êïó: OAuth„Éà„Éº„ÇØ„É≥„Åå„Åæ„Å†Èú≤Âá∫„Åó„Å¶„ÅÑ„Åæ„Åô"
              FINAL_VERIFICATION_PASSED=false
            fi
            
            # Check for hardcoded paths
            if grep -E '"/home/runner/work/[^"]*"' "$PREVIOUS_WORKFLOW" 2>/dev/null | grep -vF '${' | grep -q .; then
              echo "‚ùå ÊúÄÁµÇÊ§úË®ºÂ§±Êïó: „Éè„Éº„Éâ„Ç≥„Éº„Éâ„Éë„Çπ„Åå„Åæ„Å†Â≠òÂú®„Åó„Åæ„Åô"
              grep -n -E '"/home/runner/work/[^"]*"' "$PREVIOUS_WORKFLOW" | grep -vF '${' | head -3
              FINAL_VERIFICATION_PASSED=false
            fi
            
            if [ "$FINAL_VERIFICATION_PASSED" = "true" ]; then
              echo "‚úÖ „ÉØ„Éº„ÇØ„Éï„É≠„Éº‰øÆÊ≠£ÂÆå‰∫Ü"
              echo "success=true" >> $GITHUB_OUTPUT
              
              # Copy fixed workflow to output location
              cp "$PREVIOUS_WORKFLOW" "$FIX_DIR/fixed-workflow.yml"
              
              echo "- ‚úÖ „Éî„É≥„Éù„Ç§„É≥„Éà‰øÆÊ≠£ÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
              echo "- ‚úÖ ÂÖ®„Ç®„É©„ÉºËß£Ê±∫" >> $GITHUB_STEP_SUMMARY
              echo "- üìÅ ‰øÆÊ≠£Ê∏à„Åø„ÉØ„Éº„ÇØ„Éï„É≠„Éº: $FIX_DIR/fixed-workflow.yml" >> $GITHUB_STEP_SUMMARY
            else
              echo "‚ö†Ô∏è ‰øÆÊ≠£„ÅØÂÆüË°å„Åï„Çå„Åæ„Åó„Åü„Åå„ÄÅÊ§úË®º„Å´Â§±Êïó„Åó„Åæ„Åó„Åü"
              echo "success=partial" >> $GITHUB_OUTPUT
              
              # Still copy the workflow for analysis
              cp "$PREVIOUS_WORKFLOW" "$FIX_DIR/fixed-workflow.yml"
              
              echo "- ‚ö†Ô∏è ‰øÆÊ≠£Ë©¶Ë°å„ÅØÂÆüË°å„Åï„Çå„Åæ„Åó„Åü" >> $GITHUB_STEP_SUMMARY
              echo "- ‚ùå ÊúÄÁµÇÊ§úË®º„Åß‰∏ÄÈÉ®„ÅÆ„Ç®„É©„Éº„ÅåÊÆãÂ≠ò" >> $GITHUB_STEP_SUMMARY
              echo "- üìÅ ÈÉ®ÂàÜ‰øÆÊ≠£„ÉØ„Éº„ÇØ„Éï„É≠„Éº: $FIX_DIR/fixed-workflow.yml" >> $GITHUB_STEP_SUMMARY
              echo "- üîç ÊâãÂãï„Åß„ÅÆËøΩÂä†‰øÆÊ≠£„ÅåÂøÖË¶Å„Åß„Åô" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ùå ‰øÆÊ≠£„ÅåÂÆå‰∫Ü„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü"
            echo "success=false" >> $GITHUB_OUTPUT
            echo "- ‚ùå ‰∏ÄÈÉ®„ÅÆ„Ç®„É©„Éº„ÅåËß£Ê±∫„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü" >> $GITHUB_STEP_SUMMARY
            echo "- üìù ÊâãÂãï„Åß„ÅÆÁ¢∫Ë™ç„ÅåÂøÖË¶Å„Åß„Åô" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload Fixed Workflow
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: fixed-workflow
          path: |
            projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-fixes-*/fixed-workflow.yml
            projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-fixes-*/logs/
          if-no-files-found: warn

  # ===========================================
  # PHASE 8: FINAL REPORT DISPLAY
  # ===========================================
  
  display-final-report:
    name: "üìä ÂÆüË°åÂÆå‰∫Ü"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order', 'generate-professional-workflow', 'validate-workflow', 'regeneration-loop']
    if: always()
    steps:
          
      - name: Add Completion Summary
        run: |
          echo "üìä ÂÆüË°åÂÆå‰∫Ü„Çµ„Éû„É™„Éº„ÇíËøΩÂä†‰∏≠..."
          
          # Âü∫Êú¨ÊÉÖÂ†±
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          VALIDATION_STATUS="${{ needs.validate-workflow.outputs.validation_passed }}"
          
          # ÂÆüË°åÂÆå‰∫Ü„Çµ„Éû„É™„Éº„ÇíËøΩÂä†
          echo "## üéâ ÂÆüË°åÂÆå‰∫Ü" >> $GITHUB_STEP_SUMMARY
          echo "- **ÂÆå‰∫ÜÊôÇÂàª**: $(date '+%YÂπ¥%mÊúà%dÊó• %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          
          # ÂÜçÁîüÊàêÁµêÊûú„ÅÆÁ¢∫Ë™ç
          REGENERATION_SUCCESS="${{ needs.regeneration-loop.outputs.regeneration_success }}"
          REGENERATION_ATTEMPTED="${{ needs.regeneration-loop.outputs.regeneration_attempt }}"
          
          if [ "$VALIDATION_STATUS" = "true" ]; then
            echo "- **ÂÖ®‰ΩìÂÆüË°åÁµêÊûú**: ‚úÖ ÊàêÂäüÔºàÂàùÂõûÁîüÊàêÔºâ" >> $GITHUB_STEP_SUMMARY
          elif [ "$REGENERATION_SUCCESS" = "true" ]; then
            echo "- **ÂÖ®‰ΩìÂÆüË°åÁµêÊûú**: ‚úÖ ÊàêÂäüÔºàÂÜçÁîüÊàê„Å´„Çà„Çä‰øÆÊ≠£Ôºâ" >> $GITHUB_STEP_SUMMARY
            echo "- **ÂÜçÁîüÊàêÂÆüË°å**: ‚úÖ ÂÆå‰∫ÜÔºàÊ§úË®ºÂ§±Êïó„ÇíËá™Âãï‰øÆÊ≠£Ôºâ" >> $GITHUB_STEP_SUMMARY
          elif [ "$REGENERATION_ATTEMPTED" = "1" ]; then
            echo "- **ÂÖ®‰ΩìÂÆüË°åÁµêÊûú**: ‚ùå Â§±ÊïóÔºàÂÜçÁîüÊàê„Åß„ÇÇ‰øÆÊ≠£‰∏çÂèØÔºâ" >> $GITHUB_STEP_SUMMARY
            echo "- **ÂÜçÁîüÊàêÂÆüË°å**: ‚ùå Â§±ÊïóÔºàÊâãÂãïÂØæÂøú„ÅåÂøÖË¶ÅÔºâ" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **ÂÖ®‰ΩìÂÆüË°åÁµêÊûú**: ‚ö†Ô∏è ‰∏ÄÈÉ®„Ç®„É©„Éº„ÅÇ„Çä" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # „ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊÉÖÂ†±
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## üì• ÊàêÊûúÁâ©„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
          
          „É≠„Éº„Ç´„É´„Åß‰ª•‰∏ã„ÅÆ„Ç≥„Éû„É≥„Éâ„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö
          
          \`\`\`bash
          # „Åô„Åπ„Å¶„ÅÆÊàêÊûúÁâ©„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
          gh run download ${{ github.run_id }}
          
          # ÁâπÂÆö„ÅÆÊàêÊûúÁâ©„ÅÆ„Åø„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
          gh run download ${{ github.run_id }} -n generated-workflow
          EOF
          
          # ÂÜçÁîüÊàê„Åï„Çå„ÅüÂ†¥Âêà„ÅÆËøΩÂä†ÊÉÖÂ†±
          if [ "$REGENERATION_SUCCESS" = "true" ]; then
            cat >> $GITHUB_STEP_SUMMARY << EOF
          
          # ÂÜçÁîüÊàêÁâà„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇÇ„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÔºàÊé®Â•®Ôºâ
          gh run download ${{ github.run_id }} -n regenerated-workflow
          EOF
          fi
          
          cat >> $GITHUB_STEP_SUMMARY << EOF
          \`\`\`
          EOF
