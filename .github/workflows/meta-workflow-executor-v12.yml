name: "Meta Workflow Executor v12 with Domain Templates"
run-name: "ğŸš€ Meta Workflow v12 | Issue #${{ inputs.issue_number || github.event.issue.number }} | ${{ github.actor }}"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number for workflow generation request'
        required: true
        default: '60'
  
  issue_comment:
    types: [created]

permissions:
  contents: write
  issues: write
  actions: write
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  # ===========================================
  # PHASE 1: ISSUE VALIDATION & DOMAIN DETECTION
  # ===========================================
  
  validate-and-detect:
    name: "ğŸ” Issue Validation & Domain Detection"
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'workflow_dispatch') ||
      (github.event_name == 'issue_comment' && 
       github.event.issue.pull_request == null)
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
      issue_title: ${{ steps.extract.outputs.issue_title }}
      primary_domain: ${{ steps.detect.outputs.primary_domain }}
      detected_domains: ${{ steps.detect.outputs.detected_domains }}
      domain_count: ${{ steps.detect.outputs.domain_count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml
        
      - name: Extract Issue Information
        id: extract
        run: |
          # Check if this is a valid trigger
          if [ "${{ github.event_name }}" == "issue_comment" ]; then
            COMMENT_BODY="${{ github.event.comment.body }}"
            # For issue comments, check if it's a start command
            if ! echo "$COMMENT_BODY" | grep -qE '(/start|^start$|^å®Ÿè¡Œ$|^execute$)'; then
              echo "::notice::Skipping - Comment does not contain start command"
              echo "issue_number=skip" >> $GITHUB_OUTPUT
              exit 0
            fi
            ISSUE_NUMBER="${{ github.event.issue.number }}"
          else
            # workflow_dispatch always proceeds
            ISSUE_NUMBER="${{ inputs.issue_number }}"
          fi
          
          echo "ğŸ” Analyzing Issue #$ISSUE_NUMBER..."
          
          # Get issue details using GitHub CLI
          ISSUE_DATA=$(gh issue view $ISSUE_NUMBER --json title,body,number --jq '{title: .title, body: .body, number: .number}')
          
          ISSUE_TITLE=$(echo "$ISSUE_DATA" | jq -r '.title')
          ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body')
          ISSUE_NUMBER=$(echo "$ISSUE_DATA" | jq -r '.number')
          
          # Save to artifacts for next jobs
          mkdir -p artifacts
          echo "$ISSUE_TITLE" > artifacts/issue_title.txt
          echo "$ISSUE_BODY" > artifacts/issue_body.txt
          echo "$ISSUE_NUMBER" > artifacts/issue_number.txt
          
          # Combine title and body for domain detection
          echo -e "$ISSUE_TITLE\n\n$ISSUE_BODY" > artifacts/issue_content.txt
          
          # Output minimal data
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          echo "issue_title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          
          echo "âœ… Issue #$ISSUE_NUMBER validated: $ISSUE_TITLE"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Detect Domain from Issue
        id: detect
        run: |
          echo "ğŸ¯ Detecting domain from issue content..."
          
          python scripts/domain-template-loader.py \
            --action detect \
            --issue artifacts/issue_content.txt \
            --output artifacts/domain_detection.json
          
          # Extract results
          PRIMARY_DOMAIN=$(jq -r '.primary_domain' artifacts/domain_detection.json)
          DETECTED_DOMAINS=$(jq -c '.detected_domains' artifacts/domain_detection.json)
          DOMAIN_COUNT=$(jq '.detected_domains | length' artifacts/domain_detection.json)
          
          echo "primary_domain=$PRIMARY_DOMAIN" >> $GITHUB_OUTPUT
          echo "detected_domains=$DETECTED_DOMAINS" >> $GITHUB_OUTPUT
          echo "domain_count=$DOMAIN_COUNT" >> $GITHUB_OUTPUT
          
          echo "âœ… Primary domain detected: $PRIMARY_DOMAIN"
          echo "ğŸ“Š Total domains detected: $DOMAIN_COUNT"
          
      - name: Upload Issue and Domain Data
        uses: actions/upload-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/

  # ===========================================
  # PHASE 2: DOMAIN TEMPLATE LOADING
  # ===========================================
  
  load-domain-templates:
    name: "ğŸ“š Load Domain Templates"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect']
    if: |
      needs.validate-and-detect.outputs.issue_number != 'skip' &&
      needs.validate-and-detect.outputs.primary_domain != 'null'
    outputs:
      template_summary: ${{ steps.load.outputs.template_summary }}
      chunk_count: ${{ steps.load.outputs.chunk_count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml
          
      - name: Download Issue Data
        uses: actions/download-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/
          
      - name: Load Primary Domain Template
        id: load
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          echo "ğŸ“š Loading template for domain: $PRIMARY_DOMAIN"
          
          # Get domain summary for task decomposition
          python scripts/domain-template-loader.py \
            --action summary-for-decomposition \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_decomposition_data.json
          
          # Also get standard summary for reference
          python scripts/domain-template-loader.py \
            --action summary \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_summary.json
          
          # Split template into chunks
          python scripts/domain-template-loader.py \
            --action split \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/template_chunks.json
          
          # Extract basic info only (not full JSON)
          DOMAIN_NAME=$(jq -r '.domain_info.name' artifacts/domain_decomposition_data.json)
          EXPERT_ROLE=$(jq -r '.domain_info.expert' artifacts/domain_decomposition_data.json)
          CHUNK_COUNT=$(jq '.total_chunks' artifacts/template_chunks.json)
          
          echo "domain_name=$DOMAIN_NAME" >> $GITHUB_OUTPUT
          echo "expert_role=$EXPERT_ROLE" >> $GITHUB_OUTPUT
          echo "chunk_count=$CHUNK_COUNT" >> $GITHUB_OUTPUT
          
          echo "âœ… Template loaded: $DOMAIN_NAME ($CHUNK_COUNT chunks)"
          
      - name: Upload Template Data
        uses: actions/upload-artifact@v4
        with:
          name: domain-template-data
          path: artifacts/

  # ===========================================
  # PHASE 3: PROFESSIONAL TASK DECOMPOSITION
  # ===========================================
  
  professional-task-decomposition:
    name: "ğŸ§  Professional Task Decomposition"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates']
    outputs:
      task_count: ${{ steps.decompose.outputs.task_count }}
      dependency_groups: ${{ steps.decompose.outputs.dependency_groups }}
      estimated_duration: ${{ steps.decompose.outputs.estimated_duration }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml
          
      - name: Download and Merge Previous Artifacts
        run: |
          echo "ğŸ“¥ Downloading artifacts from previous jobs..."
          
          # Download artifacts selectively
          mkdir -p artifacts
          
          # Download issue-domain-data
          echo "Downloading issue-domain-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "issue-domain-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/issue-domain-data.zip
            unzip -q -o artifacts/issue-domain-data.zip -d artifacts/issue-domain-data/
            rm artifacts/issue-domain-data.zip
          done
          
          # Download domain-template-data
          echo "Downloading domain-template-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "domain-template-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/domain-template-data.zip
            unzip -q -o artifacts/domain-template-data.zip -d artifacts/domain-template-data/
            rm artifacts/domain-template-data.zip
          done
          
          # Merge artifacts to flat structure
          echo "Merging artifacts..."
          find artifacts -type f -name "*.json" -o -name "*.txt" -o -name "*.yaml" | while read -r file; do
            filename=$(basename "$file")
            if [ ! -f "artifacts/$filename" ]; then
              cp "$file" "artifacts/$filename"
            fi
          done
          
          echo "âœ… Artifacts downloaded and merged"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Professional Task Decomposition with Domain Knowledge
        id: decompose
        run: |
          echo "ğŸ§  Starting professional task decomposition..."
          
          # Create decomposition prompt using file references
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          EXPERT_ROLE="${{ needs.load-domain-templates.outputs.expert_role }}"
          
          cat > decomposition_prompt.txt << 'EOF'
          å°‚é–€çš„ãªã‚¿ã‚¹ã‚¯åˆ†è§£ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
          
          ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‚¿ã‚¹ã‚¯åˆ†è§£ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š
          1. ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€çŸ¥è­˜: artifacts/domain-template-data/domain_decomposition_data.json
          2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: artifacts/issue-domain-data/issue_content.txt
          
          ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€çŸ¥è­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼š
          - expert_context: å°‚é–€å®¶ã®å®Œå…¨ãªçŸ¥è­˜
          - task_decomposition_context: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æœ€é©åŒ–æƒ…å ±
          - constraints_and_requirements: ã™ã¹ã¦ã®åˆ¶ç´„äº‹é …
          - implementation_resources: åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹
          - complex_thinking_guide: æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®ã‚¬ã‚¤ãƒ‰
          
          ã‚¿ã‚¹ã‚¯åˆ†è§£ã®æ‰‹é †ï¼š
          1. domain_decomposition_data.jsonã®expert_contextã‚’å®Œå…¨ã«ç†è§£
          2. task_decomposition_contextã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚ç…§
          3. constraints_and_requirementsã®ã™ã¹ã¦ã®åˆ¶ç´„ã‚’è€ƒæ…®
          4. complex_thinking_guideã«å¾“ã£ã¦è¤‡é›‘ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
          5. implementation_resourcesã‹ã‚‰æœ€é©ãªãƒªã‚½ãƒ¼ã‚¹ã‚’é¸æŠ
          
          å‡ºåŠ›ã‚’artifacts/professional_task_decomposition.jsonã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚
          
          å‡ºåŠ›å½¢å¼ï¼š
          {
            "professional_analysis": {
              "understanding": "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å°‚é–€çš„ç†è§£ï¼ˆè©³ç´°ï¼‰",
              "considerations": ["è€ƒæ…®äº‹é …ã®ãƒªã‚¹ãƒˆ"],
              "thinking_process": "æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°ãªè¨˜éŒ²"
            },
            "tasks": [
              {
                "id": "task-1",
                "name": "ã‚¿ã‚¹ã‚¯å",
                "description": "è©³ç´°ãªèª¬æ˜",
                "reasoning": "ãªãœã“ã®ã‚¿ã‚¹ã‚¯ãŒå¿…è¦ã‹",
                "minimal_units": ["unit1", "unit2"],
                "dependencies": [],
                "estimated_duration": "5-10åˆ†",
                "professional_notes": "å°‚é–€çš„ãªæ³¨æ„ç‚¹",
                "quality_criteria": "å“è³ªåŸºæº–"
              }
            ],
            "workflow_optimization": {
              "parallel_groups": [],
              "critical_path": [],
              "optimization_rationale": "æœ€é©åŒ–ã®ç†ç”±"
            },
            "total_estimated_duration": "30åˆ†",
            "domain_specific_constraints": []
          }
          EOF
          
          # Add expert role context
          echo "ã‚ãªãŸã¯${EXPERT_ROLE}ã§ã™ã€‚" > final_prompt.txt
          echo "" >> final_prompt.txt
          cat decomposition_prompt.txt >> final_prompt.txt
          
          # Execute Claude Code for task decomposition
          npx @anthropic-ai/claude-code \
            -p "$(cat final_prompt.txt)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            > claude_output.log 2>&1
          
          # Check if execution was successful
          if [ $? -eq 0 ]; then
            echo "âœ… Claude Code execution completed"
            
            # Try multiple methods to find the generated file
            if [ -f "artifacts/professional_task_decomposition.json" ]; then
              echo "âœ… Found file at expected location"
            elif [ -f "professional_task_decomposition.json" ]; then
              echo "ğŸ“ Found file in current directory, moving to artifacts"
              mv professional_task_decomposition.json artifacts/
            else
              # Search for any JSON file that might contain the task decomposition
              echo "ğŸ” Searching for generated JSON files..."
              find . -name "*.json" -type f -newer final_prompt.txt -exec grep -l "professional_analysis" {} \; | while read -r file; do
                echo "ğŸ“ Found potential task decomposition at: $file"
                cp "$file" artifacts/professional_task_decomposition.json
                break
              done
            fi
            
            # Final check
            if [ ! -f "artifacts/professional_task_decomposition.json" ]; then
              echo "âŒ Could not find task decomposition file"
              echo "ğŸ“‹ Claude output:"
              cat claude_output.log
              exit 1
            fi
          else
            echo "âŒ Claude Code execution failed"
            cat claude_output.log
            exit 1
          fi
          
          # Extract results
          if [ -f "artifacts/professional_task_decomposition.json" ]; then
            TASK_COUNT=$(jq '.tasks | length' artifacts/professional_task_decomposition.json)
            DEPENDENCY_GROUPS=$(jq -c '.dependency_groups' artifacts/professional_task_decomposition.json)
            ESTIMATED_DURATION=$(jq -r '.total_estimated_duration' artifacts/professional_task_decomposition.json)
            
            echo "task_count=$TASK_COUNT" >> $GITHUB_OUTPUT
            echo "dependency_groups=$DEPENDENCY_GROUPS" >> $GITHUB_OUTPUT
            echo "estimated_duration=$ESTIMATED_DURATION" >> $GITHUB_OUTPUT
            
            echo "âœ… Decomposed into $TASK_COUNT tasks"
            echo "â±ï¸ Estimated duration: $ESTIMATED_DURATION"
          else
            echo "âŒ Task decomposition failed"
            exit 1
          fi
          
      - name: Upload Task Decomposition
        uses: actions/upload-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/professional_task_decomposition.json

  # ===========================================
  # PHASE 4: TASK ORDER OPTIMIZATION
  # ===========================================
  
  optimize-task-order:
    name: "ğŸ”„ Optimize Task Execution Order"
    runs-on: ubuntu-latest
    needs: ['professional-task-decomposition']
    outputs:
      optimized_order: ${{ steps.optimize.outputs.order }}
      mermaid_diagram: ${{ steps.optimize.outputs.diagram }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Task Decomposition
        uses: actions/download-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/
          
      - name: Analyze and Optimize Task Order
        id: optimize
        run: |
          echo "ğŸ”„ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé †åºã®æœ€é©åŒ–..."
          
          # ã‚¿ã‚¹ã‚¯é †åºæœ€é©åŒ–ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
          cat > optimize_prompt.txt << 'EOF'
          artifacts/professional_task_decomposition.jsonã‚’èª­ã¿è¾¼ã‚“ã§ã€ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œé †åºã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„ã€‚
          
          ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„ï¼š
          1. ã‚¿ã‚¹ã‚¯é–“ã®ä¾å­˜é–¢ä¿‚
          2. ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          3. ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®æœ€å¤§åŒ–
          4. URLæœ‰åŠ¹æœŸé™ãªã©ã®æ™‚é–“åˆ¶ç´„
          
          å‡ºåŠ›å½¢å¼ï¼š
          1. artifacts/optimized_task_order.json ã«æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè¡Œé †åº
          2. artifacts/task_order_mermaid.mmd ã«Mermaidå›³
          
          Mermaidå›³ã®è¦ä»¶ï¼š
          - graph TDå½¢å¼ã‚’ä½¿ç”¨
          - æ—¥æœ¬èªã®ã‚¿ã‚¹ã‚¯åã¯[Task-1: åå‰<br/>æ™‚é–“]å½¢å¼
          - ä¾å­˜é–¢ä¿‚ã‚’æ˜ç¢ºã«çŸ¢å°ã§è¡¨ç¾
          - subgraphã¯ä½¿ç”¨ã—ãªã„ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹é€ ã‚’ç¶­æŒï¼‰
          - classDefã§ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å®šç¾©å¯èƒ½
          - æ­£ã—ã„æ§‹æ–‡ä¾‹:
            graph TD
              Start[é–‹å§‹] --> T1[Task-1: æƒ…å ±åé›†<br/>5åˆ†]
              T1 --> T2[Task-2: åˆ†æ<br/>10åˆ†]
              T2 --> End[çµ‚äº†]
          EOF
          
          npx @anthropic-ai/claude-code \
            -p "$(cat optimize_prompt.txt)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits"
          
          # çµæœã‚’ç¢ºèª
          if [ -f "artifacts/optimized_task_order.json" ]; then
            echo "order=true" >> $GITHUB_OUTPUT
            
            # Mermaidå›³ã‚’ç’°å¢ƒå¤‰æ•°ã«ä¿å­˜ï¼ˆæ”¹è¡Œã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼‰
            if [ -f "artifacts/task_order_mermaid.mmd" ]; then
              DIAGRAM=$(cat artifacts/task_order_mermaid.mmd | sed ':a;N;$!ba;s/\n/\\n/g')
              echo "diagram<<EOF" >> $GITHUB_OUTPUT
              echo "$DIAGRAM" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
            fi
          else
            echo "order=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Display Task Order Summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## ğŸ”„ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé †åºã®æœ€é©åŒ–çµæœ
          
          ### ğŸ“Š ä¾å­˜é–¢ä¿‚å›³
          ```mermaid
          ${{ steps.optimize.outputs.diagram }}
          ```
          
          ### ğŸ“‹ æœ€é©åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ
          - ä¾å­˜é–¢ä¿‚ã«åŸºã¥ãé †åºæ±ºå®š
          - ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ç‰¹å®š
          - ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®æœ€å¤§åŒ–
          EOF
          
      - name: Upload Optimized Order
        uses: actions/upload-artifact@v4
        with:
          name: optimized-task-order
          path: |
            artifacts/optimized_task_order.json
            artifacts/task_order_mermaid.mmd

  # ===========================================
  # PHASE 5: CONSTRAINT-AWARE WORKFLOW GENERATION
  # ===========================================
  
  generate-professional-workflow:
    name: "âš¡ Generate Professional Workflow"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order']
    outputs:
      workflow_path: ${{ steps.generate.outputs.workflow_path }}
      workflow_name: ${{ steps.generate.outputs.workflow_name }}
      project_dir: ${{ steps.generate.outputs.project_dir }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Environment
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml
          
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Generate Professional Workflow
        id: generate
        run: |
          echo "âš¡ Generating professional workflow..."
          
          # Prepare all necessary data
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Create generation directory with absolute path
          # Use GITHUB_WORKSPACE for consistency across jobs
          if [ -n "$GITHUB_WORKSPACE" ]; then
            BASE_DIR="$GITHUB_WORKSPACE"
          else
            BASE_DIR="$(pwd)"
          fi
          PROJECT_DIR="${BASE_DIR}/projects/issue-${ISSUE_NUMBER}-${TIMESTAMP}"
          mkdir -p "$PROJECT_DIR/generated-workflow"
          
          echo "ğŸ“ Project directory: $PROJECT_DIR"
          
          # Load template chunks progressively
          CHUNKS=$(jq -r '.chunks[].id' artifacts/domain-template-data/template_chunks.json)
          
          # Create comprehensive generation prompt
          cat > generation_prompt.txt << 'EOF'
          ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªGitHub Actionsãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
          
          ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ï¼š
          1. ã‚¿ã‚¹ã‚¯åˆ†è§£çµæœ: artifacts/task-decomposition/professional_task_decomposition.json
          2. æœ€é©åŒ–ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯é †åº: artifacts/optimized-task-order/optimized_task_order.json (å­˜åœ¨ã™ã‚‹å ´åˆ)
          
          ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆã®è¦ä»¶ï¼š
          1. uses: ã§ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ãªã„ï¼ˆã‚¤ãƒ³ãƒ©ã‚¤ãƒ³å®Ÿè£…ï¼‰
          2. PROJECT_DIRã¯å„ã‚¸ãƒ§ãƒ–ã§æ˜ç¤ºçš„ã«è¨­å®šï¼š
             PROJECT_DIR="\${GITHUB_WORKSPACE}/projects/\${PROJECT_NAME}-\${TIMESTAMP}"
             mkdir -p "\${PROJECT_DIR}"
          3. MCPä½¿ç”¨æ™‚ã¯--mcp-configã‚’å¿…ãšå«ã‚ã‚‹
          4. ã‚¸ãƒ§ãƒ–é–“ã®ãƒ•ã‚¡ã‚¤ãƒ«å…±æœ‰ã¯artifactsã‚’ä½¿ç”¨
          5. å„ã‚¹ãƒ†ãƒƒãƒ—ã¯21000æ–‡å­—ä»¥å†…
          6. å…¨ã¦ã®å‡ºåŠ›ã¯\${PROJECT_DIR}é…ä¸‹ã«æ•´ç†
          
          ğŸš¨ CRITICAL: When constructing YAML, always follow these guidelines:
          
          1. YAML Construction Guidelines: docs/YAML_CONSTRUCTION_GUIDELINES.md
             - NEVER use HEREDOC (cat > file << EOF) - use echo commands instead
             - When creating files, use echo commands:
               echo 'first line' > file.txt
               echo 'second line' >> file.txt
             - For GitHub Actions variables in strings:
               echo "Status: ${{ github.workflow }}" >> file.txt
             - Data sharing between jobs MUST use artifacts
             - Define dependencies clearly with needs
          
          2. Minimal Unit Dependencies: docs/MINIMAL_UNIT_DATA_DEPENDENCIES.md
             - Check input/output specifications for each unit
             - Understand data flow and dependency patterns
             - Identify parallelizable tasks
          
          3. Claude Code SDK CLI Reference: docs/CLAUDE_CODE_SDK_CLI_REFERENCE.md
             - Proper MCP tool naming: mcp__serverName__toolName
             - Required environment variables for CI/CD
             - Best practices for GitHub Actions usage
             - Select appropriate data sharing methods
          
          ğŸš¨ File Creation Pattern (CRITICAL):
          When creating any file in the workflow, ALWAYS use echo commands:
          
          # Creating a markdown report
          echo '# Report Title' > report.md
          echo '' >> report.md
          echo "Generated at: $(date)" >> report.md
          echo "Status: ${{ github.workflow }}" >> report.md
          
          # Creating JSON
          echo '{' > output.json
          echo '  "status": "success",' >> output.json
          echo '  "timestamp": "'$(date -Iseconds)'"' >> output.json
          echo '}' >> output.json
          
          å°‚é–€çš„ãªå“è³ªåŸºæº–ã«å¾“ã£ã¦ã€å®Ÿå‹™ã§ä½¿ãˆã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
          
          å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: projects/issue-66-20250804-004120/generated-workflow/workflow.yml
          EOF
          
          # Replace project directory in prompt
          sed -i "s|projects/issue-66-20250804-004120|$PROJECT_DIR|g" generation_prompt.txt
          
          # Execute workflow generation
          npx @anthropic-ai/claude-code \
            -p "$(cat generation_prompt.txt)" \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Write,Read,MultiEdit" \
            --permission-mode "acceptEdits"
          
          # Verify workflow was created
          WORKFLOW_PATH="$PROJECT_DIR/generated-workflow/workflow.yml"
          if [ -f "$WORKFLOW_PATH" ]; then
            WORKFLOW_NAME="professional-workflow-${PRIMARY_DOMAIN}-${TIMESTAMP}"
            
            echo "workflow_path=$WORKFLOW_PATH" >> $GITHUB_OUTPUT
            echo "workflow_name=$WORKFLOW_NAME" >> $GITHUB_OUTPUT
            echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
            
            echo "âœ… Workflow generated: $WORKFLOW_NAME"
          else
            echo "âŒ Workflow generation failed"
            exit 1
          fi
          
      - name: Upload Generated Workflow
        uses: actions/upload-artifact@v4
        with:
          name: generated-workflow
          path: |
            projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-*

  # ===========================================
  # PHASE 6: VALIDATION & DEPLOYMENT
  # ==========================================
  
  validate-and-deploy:
    name: "âœ… Validate & Deploy"
    runs-on: ubuntu-latest
    needs: ['generate-professional-workflow']
    outputs:
      validation_passed: ${{ steps.validate.outputs.passed }}
      workflow_location: ${{ steps.copy.outputs.location }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Generated Workflow
        uses: actions/download-artifact@v4
        with:
          name: generated-workflow
          path: projects/
          
      - name: Validate Workflow
        id: validate
        run: |
          echo "âœ… Validating generated workflow..."
          
          # Use workflow with inputs if available, otherwise use original
          if [ "${{ needs.generate-professional-inputs.outputs.inputs_generated }}" == "true" ]; then
            WORKFLOW_PATH="${{ needs.generate-professional-inputs.outputs.workflow_path_with_inputs }}"
          else
            WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          fi
          
          # YAML syntax validation
          python -c "import yaml; yaml.safe_load(open('$WORKFLOW_PATH'))"
          echo "âœ… YAML syntax valid"
          
          # GitHub Actions structure validation
          if grep -q "^name:" "$WORKFLOW_PATH" && \
             grep -q "^on:" "$WORKFLOW_PATH" && \
             grep -q "^jobs:" "$WORKFLOW_PATH"; then
            echo "âœ… GitHub Actions structure valid"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Invalid GitHub Actions structure"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
      - name: Copy Workflow to Final Location
        id: copy
        run: |
          echo "ğŸ“‹ Copying workflow to final location..."
          
          # Use workflow with inputs if available, otherwise use original
          if [ "${{ needs.generate-professional-inputs.outputs.inputs_generated }}" == "true" ]; then
            WORKFLOW_PATH="${{ needs.generate-professional-inputs.outputs.workflow_path_with_inputs }}"
          else
            WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          fi
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          
          # Use the project directory from previous job
          PROJECT_DIR="${{ needs.generate-professional-workflow.outputs.project_dir }}"
          
          # Create project directory on this runner (it doesn't exist yet)
          mkdir -p "$PROJECT_DIR"
          
          # Copy to final location in project directory
          FINAL_DIR="${PROJECT_DIR}/final-workflow"
          mkdir -p "$FINAL_DIR"
          cp "$WORKFLOW_PATH" "$FINAL_DIR/${WORKFLOW_NAME}.yml"
          
          # Create deployment instructions
          cat > "$FINAL_DIR/DEPLOYMENT_INSTRUCTIONS.md" << EOF
          # Workflow Deployment Instructions
          
          ## Generated Workflow
          - **Name**: ${WORKFLOW_NAME}
          - **File**: ${WORKFLOW_NAME}.yml
          - **Domain**: ${{ needs.validate-and-detect.outputs.primary_domain }}
          - **Issue**: #${{ needs.validate-and-detect.outputs.issue_number }}
          
          ## Manual Deployment Steps
          1. Review the generated workflow file
          2. Copy to \`.github/workflows/\` directory if needed
          3. Ensure all required secrets are configured
          4. Test with \`workflow_dispatch\` trigger
          
          ## Workflow Summary
          Generated from professional domain templates with:
          - Domain-specific constraints applied
          - Optimized task dependencies
          - Professional quality standards
          EOF
          
          echo "âœ… Workflow saved to: $FINAL_DIR/${WORKFLOW_NAME}.yml"
          echo "ğŸ“ Deployment instructions: $FINAL_DIR/DEPLOYMENT_INSTRUCTIONS.md"
          
          echo "location=$FINAL_DIR" >> $GITHUB_OUTPUT
          
      - name: Update Issue
        run: |
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          
          # Get project directory from previous job
          PROJECT_DIR="${{ needs.generate-professional-workflow.outputs.project_dir }}"
          PROJECT_NAME=$(basename "$PROJECT_DIR")
          
          gh issue comment $ISSUE_NUMBER --body "## âœ… Professional Workflow Generated!
          
          **Workflow Name**: \`$WORKFLOW_NAME\`
          **Domain**: $DOMAIN
          **Status**: Successfully generated and validated
          
          ### ğŸ“‹ Summary:
          - Applied professional domain expertise
          - Incorporated domain-specific constraints
          - Optimized task dependencies
          - Validated GitHub Actions structure
          
          ### ğŸ“ Output Location:
          - **Project Directory**: \`projects/$PROJECT_NAME/\`
          - **Workflow File**: \`final-workflow/${WORKFLOW_NAME}.yml\`
          - **Deployment Guide**: \`final-workflow/DEPLOYMENT_INSTRUCTIONS.md\`
          
          ### ğŸš€ Next Steps:
          1. Download the workflow from artifacts
          2. Review the generated workflow
          3. Deploy manually to \`.github/workflows/\` if needed
          4. Configure required secrets
          5. Test with \`workflow_dispatch\`
          
          ---
          *Generated by Meta Workflow v12 with Domain Templates*"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ===========================================
  # PHASE 7: FINAL REPORT DISPLAY
  # ===========================================
  
  display-final-report:
    name: "ğŸ“Š æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order', 'generate-professional-workflow', 'validate-and-deploy']
    if: always()
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Generate and Display Final Report
        run: |
          echo "ğŸ“Š æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."
          
          # åŸºæœ¬æƒ…å ±
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          DOMAIN_NAME="${{ needs.load-domain-templates.outputs.domain_name }}"
          EXPERT_ROLE="${{ needs.load-domain-templates.outputs.expert_role }}"
          
          # GitHub Actions Summaryã«ç›´æ¥è¡¨ç¤º
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # ğŸ¯ Meta Workflow v12 å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ
          
          ## ğŸ“‹ å®Ÿè¡Œæ¦‚è¦
          EOF
          
          echo "- **Issueç•ªå·**: #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
          echo "- **æ¤œå‡ºãƒ‰ãƒ¡ã‚¤ãƒ³**: ${DOMAIN} (${DOMAIN_NAME})" >> $GITHUB_STEP_SUMMARY
          echo "- **å°‚é–€å®¶å½¹å‰²**: ${EXPERT_ROLE}" >> $GITHUB_STEP_SUMMARY
          echo "- **å®Ÿè¡Œæ™‚åˆ»**: $(date '+%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ†æçµæœ
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## ğŸ” ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ†æçµæœ
          
          ### èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæƒ…å ±
          EOF
          
          if [ -f "artifacts/domain-template-data/domain_decomposition_data.json" ]; then
            echo '```json' >> $GITHUB_STEP_SUMMARY
            jq '.domain_info' artifacts/domain-template-data/domain_decomposition_data.json >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            echo "### æ¨å¥¨MCPã‚µãƒ¼ãƒ“ã‚¹" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            jq '.implementation_resources.recommended_mcp_services' artifacts/domain-template-data/domain_decomposition_data.json >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "MCPã‚µãƒ¼ãƒ“ã‚¹æƒ…å ±ãªã—" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ã‚¿ã‚¹ã‚¯åˆ†è§£çµæœ
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## ğŸ“ ã‚¿ã‚¹ã‚¯åˆ†è§£çµæœ
          
          ### åˆ†è§£ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ä¸€è¦§
          EOF
          
          if [ -f "artifacts/task-decomposition/professional_task_decomposition.json" ]; then
            # ã‚¿ã‚¹ã‚¯æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            TASK_COUNT=$(jq '.tasks | length' artifacts/task-decomposition/professional_task_decomposition.json 2>/dev/null || echo "0")
            echo "**ç·ã‚¿ã‚¹ã‚¯æ•°**: ${TASK_COUNT}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # å„ã‚¿ã‚¹ã‚¯ã®è©³ç´°
            jq -r '.tasks[] | "#### \(.id): \(.name)\n- **èª¬æ˜**: \(.description)\n- **æ¨å®šæ™‚é–“**: \(.estimated_duration)\n- **ä¾å­˜é–¢ä¿‚**: \(.dependencies | join(", ") // "ãªã—")\n- **ä½¿ç”¨ãƒ¦ãƒ‹ãƒƒãƒˆ**: \(.minimal_units | join(", "))\n"' artifacts/task-decomposition/professional_task_decomposition.json >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "ã‚¿ã‚¹ã‚¯è©³ç´°ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé †åºã®æœ€é©åŒ–çµæœ
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## ğŸ”„ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé †åº
          
          ### æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè¡Œé †åºå›³
          EOF
          
          if [ -f "artifacts/optimized-task-order/task_order_mermaid.mmd" ]; then
            echo '```mermaid' >> $GITHUB_STEP_SUMMARY
            cat artifacts/optimized-task-order/task_order_mermaid.mmd >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "*ã‚¿ã‚¹ã‚¯é †åºå›³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ*" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆçµæœ
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## âš¡ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆçµæœ
          EOF
          
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          echo "- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å**: ${WORKFLOW_NAME}" >> $GITHUB_STEP_SUMMARY
          echo "- **æ¤œè¨¼çµæœ**: ${{ needs.validate-and-deploy.outputs.validation_passed == 'true' && 'âœ… æˆåŠŸ' || 'âŒ å¤±æ•—' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **ä¿å­˜å ´æ‰€**: projects/issue-${ISSUE_NUMBER}-*/final-workflow/" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚ºã‚µãƒãƒªãƒ¼
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## ğŸ—ï¸ å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º
          
          | ãƒ•ã‚§ãƒ¼ã‚º | çŠ¶æ…‹ | èª¬æ˜ |
          |---------|------|------|
          | 1. Issueæ¤œè¨¼ & ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡º | âœ… | Issueå†…å®¹ã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è‡ªå‹•æ¤œå‡º |
          | 2. ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ | âœ… | å°‚é–€çŸ¥è­˜ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª­ã¿è¾¼ã¿ |
          | 3. ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚¿ã‚¹ã‚¯åˆ†è§£ | âœ… | AIã«ã‚ˆã‚‹è©³ç´°ãªã‚¿ã‚¹ã‚¯åˆ†è§£ |
          | 4. ã‚¿ã‚¹ã‚¯é †åºæœ€é©åŒ– | âœ… | ä¾å­˜é–¢ä¿‚ã«åŸºã¥ãå®Ÿè¡Œé †åºæ±ºå®š |
          | 5. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆ | âœ… | GitHub Actionså½¢å¼ã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆ |
          EOF
          
          echo "| 6. æ¤œè¨¼ & é…ç½® | ${{ needs.validate-and-deploy.outputs.validation_passed == 'true' && 'âœ…' || 'âŒ' }} | YAMLãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ä¿å­˜ |" >> $GITHUB_STEP_SUMMARY
          echo "| 7. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ | âœ… | å®Ÿè¡Œçµæœã®ç·åˆãƒ¬ãƒãƒ¼ãƒˆ |" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æƒ…å ±
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## ğŸ“¥ æˆæœç‰©ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          
          ãƒ­ãƒ¼ã‚«ãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š
          
          \`\`\`bash
          # ã™ã¹ã¦ã®æˆæœç‰©ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          gh run download ${{ github.run_id }}
          
          # ç‰¹å®šã®æˆæœç‰©ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          gh run download ${{ github.run_id }} -n generated-workflow
          \`\`\`
          
          ## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯
          - [å®Ÿè¡Œè©³ç´°](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          - [Issue #${ISSUE_NUMBER}](https://github.com/${{ github.repository }}/issues/${ISSUE_NUMBER})
          - [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©](https://github.com/${{ github.repository }}/blob/main/.github/workflows/meta-workflow-executor-v12.yml)
          
          ---
          *Generated by Meta Workflow v12 with Domain Templates*
          EOF