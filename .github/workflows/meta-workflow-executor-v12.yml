name: "Meta Workflow Executor v12 with Domain Templates"
run-name: "ðŸš€ Meta Workflow v12 | Issue #${{ inputs.issue_number || github.event.issue.number }} | ${{ github.actor }}"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number for workflow generation request'
        required: true
        default: '66'
  
  issue_comment:
    types: [created]

permissions:
  contents: write
  issues: write
  actions: write
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  bootstrap:
    name: "ðŸ§© Bootstrap Diagnostics"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'issue_comment' && github.event.issue.pull_request == null && contains(github.event.comment.body, '/start'))
    steps:
      - name: Print event context
        run: |
          echo "event_name=${{ github.event_name }}"
          echo "actor=${{ github.actor }}"
          echo "ref=${{ github.ref }}"
          echo "issue_number_from_dispatch=${{ inputs.issue_number }}"
          echo "is_issue_comment=$([ "${{ github.event_name }}" = "issue_comment" ] && echo true || echo false)"
          if [ "${{ github.event_name }}" = "issue_comment" ]; then
            echo "comment_body<<EOT"
            echo "${{ github.event.comment.body }}"
            echo "EOT"
          fi
          echo "Bootstrap OK"
  
  # ===========================================
  # PHASE 1: ISSUE VALIDATION & DOMAIN DETECTION
  # ===========================================
  
  validate-and-detect:
    name: "ðŸ” Issue Validation & Domain Detection"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'issue_comment' && github.event.issue.pull_request == null && contains(github.event.comment.body, '/start'))
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
      issue_title: ${{ steps.extract.outputs.issue_title }}
      primary_domain: ${{ steps.detect.outputs.primary_domain }}
      detected_domains: ${{ steps.detect.outputs.detected_domains }}
      domain_count: ${{ steps.detect.outputs.domain_count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
        
      - name: Extract Issue Information
        id: extract
        run: |
          # Check if this is a valid trigger
          if [ "${{ github.event_name }}" == "issue_comment" ]; then
            COMMENT_BODY="${{ github.event.comment.body }}"
            # For issue comments, check if it's a start command
            if ! echo "$COMMENT_BODY" | grep -qE '(/start|^start$|^å®Ÿè¡Œ$|^execute$)'; then
              echo "::notice::Skipping - Comment does not contain start command"
              echo "issue_number=skip" >> $GITHUB_OUTPUT
              exit 0
            fi
            ISSUE_NUMBER="${{ github.event.issue.number }}"
          else
            # workflow_dispatch always proceeds
            ISSUE_NUMBER="${{ inputs.issue_number }}"
          fi
          
          echo "ðŸ” Analyzing Issue #$ISSUE_NUMBER..."
          
          # Get issue details using GitHub CLI
          ISSUE_DATA=$(gh issue view $ISSUE_NUMBER --json title,body,number --jq '{title: .title, body: .body, number: .number}')
          
          ISSUE_TITLE=$(echo "$ISSUE_DATA" | jq -r '.title')
          ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body')
          ISSUE_NUMBER=$(echo "$ISSUE_DATA" | jq -r '.number')
          
          # Save to artifacts for next jobs
          mkdir -p artifacts
          echo "$ISSUE_TITLE" > artifacts/issue_title.txt
          echo "$ISSUE_BODY" > artifacts/issue_body.txt
          echo "$ISSUE_NUMBER" > artifacts/issue_number.txt
          
          # Combine title and body for domain detection
          echo -e "$ISSUE_TITLE\n\n$ISSUE_BODY" > artifacts/issue_content.txt
          
          # Output minimal data
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          echo "issue_title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          
          echo "âœ… Issue #$ISSUE_NUMBER validated: $ISSUE_TITLE"
          
          # Initialize Progressive Report in GitHub Actions Summary
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # ðŸŽ¯ Meta Workflow v12 å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ
          
          ## ðŸ“‹ å®Ÿè¡Œæ¦‚è¦
          EOF
          
          echo "- **Issueç•ªå·**: #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
          echo "- **Issue ã‚¿ã‚¤ãƒˆãƒ«**: ${ISSUE_TITLE}" >> $GITHUB_STEP_SUMMARY  
          echo "- **å®Ÿè¡Œé–‹å§‹æ™‚åˆ»**: $(date '+%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          echo "- **å®Ÿè¡ŒçŠ¶æ³**: ðŸ”„ é€²è¡Œä¸­..." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ðŸ” Phase 1: Issueæ¤œè¨¼ & ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡º" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Issue #${ISSUE_NUMBER} å†…å®¹å–å¾—å®Œäº†" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡º: (pending)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Detect Domain from Issue
        id: detect
        run: |
          echo "ðŸŽ¯ Detecting domain from issue content..."
          
          python scripts/domain-template-loader.py \
            --action detect \
            --issue artifacts/issue_content.txt \
            --output artifacts/domain_detection.json
          
          # Extract results
          PRIMARY_DOMAIN=$(jq -r '.primary_domain' artifacts/domain_detection.json)
          DETECTED_DOMAINS=$(jq -c '.detected_domains' artifacts/domain_detection.json)
          DOMAIN_COUNT=$(jq '.detected_domains | length' artifacts/domain_detection.json)
          
          echo "primary_domain=$PRIMARY_DOMAIN" >> $GITHUB_OUTPUT
          echo "detected_domains=$DETECTED_DOMAINS" >> $GITHUB_OUTPUT
          echo "domain_count=$DOMAIN_COUNT" >> $GITHUB_OUTPUT
          
          echo "âœ… Primary domain detected: $PRIMARY_DOMAIN"
          echo "ðŸ“Š Total domains detected: $DOMAIN_COUNT"
          
      - name: Upload Issue and Domain Data
        uses: actions/upload-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/

      - name: Report Detected Domain
        run: |
          PRIMARY_DOMAIN="${{ steps.detect.outputs.primary_domain }}"
          COUNT="${{ steps.detect.outputs.domain_count }}"
          echo "- âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡º: ${PRIMARY_DOMAIN} (${COUNT} detected)" >> $GITHUB_STEP_SUMMARY

  # ===========================================
  # PHASE 2: DOMAIN TEMPLATE LOADING
  # ===========================================
  
  load-domain-templates:
    name: "ðŸ“š Load Domain Templates"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect']
    if: |
      needs.validate-and-detect.outputs.issue_number != 'skip' &&
      needs.validate-and-detect.outputs.primary_domain != 'null'
    outputs:
      template_summary: ${{ steps.load.outputs.template_summary }}
      chunk_count: ${{ steps.load.outputs.chunk_count }}
      input_schema: ${{ steps.inputs.outputs.input_schema }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download Issue Data
        uses: actions/download-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/
          
      - name: Load Primary Domain Template
        id: load
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          echo "ðŸ“š Loading template for domain: $PRIMARY_DOMAIN"
          
          # Get domain summary for task decomposition
          python scripts/domain-template-loader.py \
            --action summary-for-decomposition \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_decomposition_data.json
          
          # Also get standard summary for reference
          python scripts/domain-template-loader.py \
            --action summary \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_summary.json
          
          # Split template into chunks
          python scripts/domain-template-loader.py \
            --action split \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/template_chunks.json
          
          # Extract basic info only (not full JSON)
          DOMAIN_NAME=$(jq -r '.domain_info.name' artifacts/domain_decomposition_data.json)
          EXPERT_ROLE=$(jq -r '.domain_info.expert' artifacts/domain_decomposition_data.json)
          CHUNK_COUNT=$(jq '.total_chunks' artifacts/template_chunks.json)
          
          echo "domain_name=$DOMAIN_NAME" >> $GITHUB_OUTPUT
          echo "expert_role=$EXPERT_ROLE" >> $GITHUB_OUTPUT
          echo "chunk_count=$CHUNK_COUNT" >> $GITHUB_OUTPUT
          
          echo "âœ… Template loaded: $DOMAIN_NAME ($CHUNK_COUNT chunks)"
          
          # Add Phase 2 Report
          echo "## ðŸ“š Phase 2: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³: ${DOMAIN_NAME}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… å°‚é–€å®¶å½¹å‰²: ${EXPERT_ROLE}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒ£ãƒ³ã‚¯æ•°: ${CHUNK_COUNT}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Locate and Copy Domain Input Schema
        id: inputs
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          SCHEMA_PATH="meta/domain-templates/$PRIMARY_DOMAIN/input-schema.yaml"
          mkdir -p artifacts/domain-input-schema
          if [ -f "$SCHEMA_PATH" ]; then
            cp "$SCHEMA_PATH" artifacts/domain-input-schema/input-schema.yaml
            echo "input_schema=artifacts/domain-input-schema/input-schema.yaml" >> $GITHUB_OUTPUT
            echo "âœ… Input schema found: $SCHEMA_PATH"
            echo "- âœ… å…¥åŠ›ã‚¹ã‚­ãƒ¼ãƒžæ¤œå‡º: $PRIMARY_DOMAIN/input-schema.yaml" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Input schema not found for domain: $PRIMARY_DOMAIN"
            echo "input_schema=" >> $GITHUB_OUTPUT
            echo "- âŒ å…¥åŠ›ã‚¹ã‚­ãƒ¼ãƒžæœªæ¤œå‡º" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Locate Domain Checklists
        id: checklists
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          LIST=$(ls -1 "meta/domain-templates/$PRIMARY_DOMAIN"/checklist-*-specific.md 2>/dev/null || true)
          mkdir -p artifacts
          if [ -n "$LIST" ]; then
            echo "$LIST" > artifacts/domain-checklists.txt
            COUNT=$(echo "$LIST" | wc -l | tr -d ' ')
            echo "checklist_count=$COUNT" >> $GITHUB_OUTPUT
            echo "- âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆæ¤œå‡º ($COUNT ä»¶):" >> $GITHUB_STEP_SUMMARY
            echo "$LIST" | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“š Using domain checklists (detected $COUNT):"
            echo "$LIST" | sed 's/^/- /'
          else
            echo "checklist_count=0" >> $GITHUB_OUTPUT
            echo "- âŒ ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆæœªæ¤œå‡º" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“š Using domain checklists: (none found)"
          fi
          
      - name: Upload Template Data
        uses: actions/upload-artifact@v4
        with:
          name: domain-template-data
          path: artifacts/

  # ===========================================
  # PHASE 3: PROFESSIONAL TASK DECOMPOSITION
  # ===========================================
  
  professional-task-decomposition:
    name: "ðŸ§  Professional Task Decomposition"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates']
    outputs:
      task_count: ${{ steps.decompose.outputs.task_count }}
      dependency_groups: ${{ steps.decompose.outputs.dependency_groups }}
      estimated_duration: ${{ steps.decompose.outputs.estimated_duration }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download and Merge Previous Artifacts
        run: |
          echo "ðŸ“¥ Downloading artifacts from previous jobs..."
          
          # Download artifacts selectively
          mkdir -p artifacts
          
          # Download issue-domain-data
          echo "Downloading issue-domain-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "issue-domain-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/issue-domain-data.zip
            unzip -q -o artifacts/issue-domain-data.zip -d artifacts/issue-domain-data/
            rm artifacts/issue-domain-data.zip
          done
          
          # Download domain-template-data
          echo "Downloading domain-template-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "domain-template-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/domain-template-data.zip
            unzip -q -o artifacts/domain-template-data.zip -d artifacts/domain-template-data/
            rm artifacts/domain-template-data.zip
          done
          
          # Merge artifacts to flat structure
          echo "Merging artifacts..."
          find artifacts -type f -name "*.json" -o -name "*.txt" -o -name "*.yaml" | while read -r file; do
            filename=$(basename "$file")
            if [ ! -f "artifacts/$filename" ]; then
              cp "$file" "artifacts/$filename"
            fi
          done
          
          echo "âœ… Artifacts downloaded and merged"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Professional Task Decomposition with Domain Knowledge
        id: decompose
        run: |
          echo "ðŸ§  Starting professional task decomposition..."
          
          # Create decomposition prompt using file references
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          EXPERT_ROLE="${{ needs.load-domain-templates.outputs.expert_role }}"
          
          cat > decomposition_prompt.txt << 'EOF'
          å°‚é–€çš„ãªã‚¿ã‚¹ã‚¯åˆ†è§£ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
          
          ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‚¿ã‚¹ã‚¯åˆ†è§£ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š
          1. ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€çŸ¥è­˜: artifacts/domain-template-data/domain_decomposition_data.json
          2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: artifacts/issue-domain-data/issue_content.txt
          
          ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€çŸ¥è­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼š
          - expert_context: å°‚é–€å®¶ã®å®Œå…¨ãªçŸ¥è­˜
          - task_decomposition_context: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æœ€é©åŒ–æƒ…å ±
          - constraints_and_requirements: ã™ã¹ã¦ã®åˆ¶ç´„äº‹é …
          - implementation_resources: åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹
          - complex_thinking_guide: æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®ã‚¬ã‚¤ãƒ‰
          
          ã‚¿ã‚¹ã‚¯åˆ†è§£ã®æ‰‹é †ï¼š
          1. domain_decomposition_data.jsonã®expert_contextã‚’å®Œå…¨ã«ç†è§£
          2. task_decomposition_contextã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚ç…§
          3. constraints_and_requirementsã®ã™ã¹ã¦ã®åˆ¶ç´„ã‚’è€ƒæ…®
          4. complex_thinking_guideã«å¾“ã£ã¦è¤‡é›‘ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
          5. implementation_resourcesã‹ã‚‰æœ€é©ãªãƒªã‚½ãƒ¼ã‚¹ã‚’é¸æŠž
          
          å‡ºåŠ›ã‚’artifacts/professional_task_decomposition.jsonã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚
          
          å‡ºåŠ›å½¢å¼ï¼š
          {
            "professional_analysis": {
              "understanding": "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å°‚é–€çš„ç†è§£ï¼ˆè©³ç´°ï¼‰",
              "considerations": ["è€ƒæ…®äº‹é …ã®ãƒªã‚¹ãƒˆ"],
              "thinking_process": "æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°ãªè¨˜éŒ²"
            },
            "tasks": [
              {
                "id": "task-1",
                "name": "ã‚¿ã‚¹ã‚¯å",
                "description": "è©³ç´°ãªèª¬æ˜Ž",
                "reasoning": "ãªãœã“ã®ã‚¿ã‚¹ã‚¯ãŒå¿…è¦ã‹",
                "minimal_units": ["unit1", "unit2"],
                "dependencies": [],
                "estimated_duration": "5-10åˆ†",
                "professional_notes": "å°‚é–€çš„ãªæ³¨æ„ç‚¹",
                "quality_criteria": "å“è³ªåŸºæº–"
              }
            ],
            "workflow_optimization": {
              "parallel_groups": [],
              "critical_path": [],
              "optimization_rationale": "æœ€é©åŒ–ã®ç†ç”±"
            },
            "workflow_generation_parameters": {
              "calculated_scene_count": "constraints.yamlã®scene_calculationã«åŸºã¥ã„ã¦è¨ˆç®—ã—ãŸæ•°å€¤",
              "matrix_scene_list": "[1, 2, 3, ...]ã®å½¢å¼ã§è¨ˆç®—ã•ã‚ŒãŸã‚·ãƒ¼ãƒ³ãƒªã‚¹ãƒˆ",
              "max_parallel": "calculated_scene_countã¨åŒã˜å€¤",
              "assumed_scene_duration": "è¨ˆç®—ã§ä½¿ç”¨ã—ãŸ1ã‚·ãƒ¼ãƒ³ã‚ãŸã‚Šã®ç§’æ•°"
            },
            "total_estimated_duration": "30åˆ†",
            "domain_specific_constraints": []
          }
          EOF
          
          # Add expert role context
          echo "ã‚ãªãŸã¯${EXPERT_ROLE}ã§ã™ã€‚" > final_prompt.txt
          echo "" >> final_prompt.txt
          cat decomposition_prompt.txt >> final_prompt.txt
          
          # Execute Claude Code for task decomposition
          npx @anthropic-ai/claude-code \
            -p "$(cat final_prompt.txt)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            > claude_output.log 2>&1
          
          # Check if execution was successful
          if [ $? -eq 0 ]; then
            echo "âœ… Claude Code execution completed"
            
            # Try multiple methods to find the generated file
            if [ -f "artifacts/professional_task_decomposition.json" ]; then
              echo "âœ… Found file at expected location"
            elif [ -f "professional_task_decomposition.json" ]; then
              echo "ðŸ“ Found file in current directory, moving to artifacts"
              mv professional_task_decomposition.json artifacts/
            else
              # Search for any JSON file that might contain the task decomposition
              echo "ðŸ” Searching for generated JSON files..."
              find . -name "*.json" -type f -newer final_prompt.txt -exec grep -l "professional_analysis" {} \; | while read -r file; do
                echo "ðŸ“ Found potential task decomposition at: $file"
                cp "$file" artifacts/professional_task_decomposition.json
                break
              done
            fi
            
            # Final check
            if [ ! -f "artifacts/professional_task_decomposition.json" ]; then
              echo "âŒ Could not find task decomposition file"
              echo "ðŸ“‹ Claude output:"
              cat claude_output.log
              exit 1
            fi
          else
            echo "âŒ Claude Code execution failed"
            cat claude_output.log
            exit 1
          fi
          
          # Extract results
          if [ -f "artifacts/professional_task_decomposition.json" ]; then
            TASK_COUNT=$(jq '.tasks | length' artifacts/professional_task_decomposition.json)
            DEPENDENCY_GROUPS=$(jq -c '.dependency_groups' artifacts/professional_task_decomposition.json)
            ESTIMATED_DURATION=$(jq -r '.total_estimated_duration' artifacts/professional_task_decomposition.json)
            
            echo "task_count=$TASK_COUNT" >> $GITHUB_OUTPUT
            echo "dependency_groups=$DEPENDENCY_GROUPS" >> $GITHUB_OUTPUT
            echo "estimated_duration=$ESTIMATED_DURATION" >> $GITHUB_OUTPUT
            
            echo "âœ… Decomposed into $TASK_COUNT tasks"
            echo "â±ï¸ Estimated duration: $ESTIMATED_DURATION"
            
            # Add Phase 3 Report
            echo "## ðŸ§  Phase 3: ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚¿ã‚¹ã‚¯åˆ†è§£" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ã‚¿ã‚¹ã‚¯æ•°: ${TASK_COUNT}å€‹" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… æŽ¨å®šå®Ÿè¡Œæ™‚é–“: ${ESTIMATED_DURATION}" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ä¾å­˜é–¢ä¿‚ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æžå®Œäº†" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Task decomposition failed"
            exit 1
          fi
          
      - name: Upload Task Decomposition
        uses: actions/upload-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/professional_task_decomposition.json

  # ===========================================
  # PHASE 4: TASK ORDER OPTIMIZATION
  # ===========================================
  
  optimize-task-order:
    name: "ðŸ”„ Optimize Task Execution Order"
    runs-on: ubuntu-latest
    needs: ['professional-task-decomposition']
    outputs:
      optimized_order: ${{ steps.optimize.outputs.order }}
      mermaid_available: ${{ steps.optimize.outputs.mermaid_available }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Task Decomposition
        uses: actions/download-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/
          
      - name: Analyze and Optimize Task Order
        id: optimize
        run: |
          echo "ðŸ”„ ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé †åºã®æœ€é©åŒ–..."
          
          # Create artifacts directory
          mkdir -p artifacts
          
          # Run Claude Code SDK with specialized prompt file for reliable Mermaid generation
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            -p "$(cat meta/prompts/task-order-optimization-with-mermaid.md)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits"
          
          # çµæžœã‚’ç¢ºèª
          if [ -f "artifacts/optimized_task_order.json" ]; then
            echo "order=true" >> $GITHUB_OUTPUT
            
            # Add Phase 4 Report with Task Order
            echo "## ðŸ”„ Phase 4: ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé †åºã®æœ€é©åŒ–" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ä¾å­˜é–¢ä¿‚åˆ†æžå®Œäº†" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ä¸¦åˆ—å‡¦ç†ã‚°ãƒ«ãƒ¼ãƒ—ç‰¹å®š" >> $GITHUB_STEP_SUMMARY
            
            # å‹•çš„ãƒ†ã‚­ã‚¹ãƒˆå›³ã‚’ç”Ÿæˆï¼ˆæœ€é©åŒ–ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‹ã‚‰è‡ªå‹•ç”Ÿæˆï¼‰
            if [ -f "artifacts/optimized_task_order.json" ]; then
              echo "- âœ… æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè¡Œé †åºç”Ÿæˆå®Œäº†" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### ðŸ“Š å®Ÿè¡Œãƒ•ãƒ­ãƒ¼å›³ï¼ˆå‹•çš„ç”Ÿæˆï¼‰" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              
              # JSONã‹ã‚‰å‹•çš„ã«ã‚¿ã‚¹ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç”Ÿæˆï¼ˆå˜ä¸€è¡Œã§å®Ÿè¡Œï¼‰
              if [ -f "artifacts/optimized_task_order.json" ]; then
                python3 -c "import json; data=json.load(open('artifacts/optimized_task_order.json')); print('ã‚¿ã‚¹ã‚¯å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ï¼ˆå‹•çš„ç”Ÿæˆãƒ»ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–æ¸ˆã¿ï¼‰:'); print(); [print(f\"âš¡ {phase.get('phase', f'Phase {i+1}')} [{phase.get('execution_type', 'sequential').upper()}]\") if phase.get('execution_type') == 'parallel' else print(f\"ðŸ“‹ {phase.get('phase', f'Phase {i+1}')} [{phase.get('execution_type', 'sequential').upper()}]\") for i, phase in enumerate(data.get('optimized_execution_order', []))]" >> $GITHUB_STEP_SUMMARY
                echo "â±ï¸ æœ€é©åŒ–ã«ã‚ˆã‚Šä¸¦åˆ—å‡¦ç†ã‚’æ´»ç”¨ã—ãŸåŠ¹çŽ‡çš„ãªå®Ÿè¡Œé †åºã‚’ç”Ÿæˆ" >> $GITHUB_STEP_SUMMARY
              else
                echo "ã‚¿ã‚¹ã‚¯ãƒ•ãƒ­ãƒ¼æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“" >> $GITHUB_STEP_SUMMARY
              fi
              
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "mermaid_available=true" >> $GITHUB_OUTPUT
            else
              echo "- âŒ æœ€é©åŒ–é †åºã®ç”Ÿæˆã«å¤±æ•—" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "mermaid_available=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "order=false" >> $GITHUB_OUTPUT
          fi
          
      # Summary display moved to final report for better organization
          
      - name: Upload Optimized Order
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: optimized-task-order
          path: artifacts/
          if-no-files-found: warn

  # ===========================================
  # PHASE 5: CONSTRAINT-AWARE WORKFLOW GENERATION
  # ===========================================
  
  generate-professional-workflow:
    name: "âš¡ Generate Professional Workflow"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order']
    outputs:
      workflow_path: ${{ steps.generate.outputs.workflow_path }}
      workflow_name: ${{ steps.generate.outputs.workflow_name }}
      project_dir: ${{ steps.generate.outputs.project_dir }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Environment
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
          
      - name: Generate Professional Workflow
        id: generate
        run: |
          echo "âš¡ Generating professional workflow..."
          
          # Prepare all necessary data
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Create generation directory with absolute path
          # Use GITHUB_WORKSPACE for consistency across jobs
          if [ -n "$GITHUB_WORKSPACE" ]; then
            BASE_DIR="$GITHUB_WORKSPACE"
          else
            BASE_DIR="$(pwd)"
          fi
          PROJECT_DIR="${BASE_DIR}/projects/issue-${ISSUE_NUMBER}-${TIMESTAMP}"
          mkdir -p "$PROJECT_DIR/generated-workflow"
          
          echo "ðŸ“ Project directory: $PROJECT_DIR"
          
          # Load template chunks progressively
          CHUNKS=$(jq -r '.chunks[].id' artifacts/domain-template-data/template_chunks.json)
          
          # Create comprehensive generation prompt (domain-agnostic with strict domain enforcement when provided)
          cat > generation_prompt.txt << 'EOF'
          ã‚ãªãŸã¯ã€Œæ±Žç”¨ãƒ¡ã‚¿ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆå™¨ã€ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ï¼ˆIssueï¼‰ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿ã€æœ€é©ãªGitHub Actionsãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

          å…¥åŠ›ï¼ˆå¿…ãšå‚ç…§ï¼‰:
          1. ã‚¿ã‚¹ã‚¯åˆ†è§£: artifacts/task-decomposition/professional_task_decomposition.json
             ç‰¹ã«é‡è¦: workflow_generation_parameters ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã® calculated_scene_count ã¨ matrix_scene_list
          2. æœ€é©åŒ–é †åº(ä»»æ„): artifacts/optimized-task-order/optimized_task_order.json
          3. å…¥åŠ›ã‚¹ã‚­ãƒ¼ãƒž(å¿…é ˆ): artifacts/domain-input-schema/input-schema.yaml
          4. å¿…é ˆå…¥åŠ›ä¸€è¦§(ä»»æ„): artifacts/required_inputs.json / artifacts/required_input_keys.txt
          5. ãƒ‰ãƒ¡ã‚¤ãƒ³æ¦‚è¦/åˆ†è§£ãƒ‡ãƒ¼ã‚¿(ä»»æ„): artifacts/domain-template-data/domain_summary.json, artifacts/domain-template-data/domain_decomposition_data.json
          6. ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆä¸€è¦§(ä»»æ„): artifacts/domain-template-data/domain-checklists.txt
          7. å…±é€šãƒ«ãƒ¼ãƒ«: docs/YAML_CONSTRUCTION_GUIDELINES.md, docs/MINIMAL_UNIT_DATA_DEPENDENCIES.md

          ç”Ÿæˆã‚¬ã‚¤ãƒ‰ï¼ˆæ±Žç”¨ï¼‰:
          - MUST: uses: ã§ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹å‚ç…§ã‚’ã—ãªã„ï¼ˆã‚¤ãƒ³ãƒ©ã‚¤ãƒ³å®Ÿè£…ï¼‰
          - MUST: å…¨ã¦ã®å‡ºåŠ›/ä¸­é–“ç”Ÿæˆç‰©ã¯ PROJECT_DIR_PLACEHOLDER é…ä¸‹ã«ä¿å­˜
          - MUST: ã‚¸ãƒ§ãƒ–é–“å…±æœ‰ã¯ actions/upload-artifact / download-artifact ã‚’ä½¿ç”¨
          - MUST: workflow_dispatch.inputs ã¯ input-schema.yaml ã¨å¿…é ˆå…¥åŠ›ä¸€è¦§ã‚’èª­ã¿è¾¼ã¿åæ˜ ï¼ˆenumâ†’choice, default, descriptionã€è¿½åŠ å¿…é ˆã‚­ãƒ¼ã®è£œå®Œï¼‰
          - MUST: çµ¶å¯¾ãƒ‘ã‚¹ã‚„ãƒ«ãƒ¼ãƒˆç›´ä¸‹ã®å‡ºåŠ›ã‚’ç¦æ­¢ã—ã€å¸¸ã« PROJECT_DIR_PLACEHOLDER ã‚’ä½¿ã†
          - MUST: ç’°å¢ƒå¤‰æ•°ã‚»ã‚¯ã‚·ãƒ§ãƒ³(env:)ã«ä»¥ä¸‹ã‚’å¿…ãšå«ã‚ã‚‹:
            env:
              CLAUDE_CODE_CI_MODE: true
              CLAUDE_CODE_AUTO_APPROVE_MCP: true
              CLAUDE_CODE_OAUTH_TOKEN: \${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          - SHOULD: ã‚¹ãƒ†ãƒƒãƒ—ã¯21000æ–‡å­—ä»¥å†…ã«åˆ†å‰²

          ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®é©ç”¨ï¼ˆå¼·åˆ¶ï¼‰:
          - artifacts/domain-template-data/domain-checklists.txt ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€åˆ—æŒ™ã•ã‚ŒãŸå„ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’èª­ã¿ã€ŒMUSTã€éµå®ˆã™ã‚‹ã“ã¨ã€‚éµå®ˆã§ããªã„å ´åˆã¯ç”Ÿæˆæ™‚ã«ä»£æ›¿è¨­è¨ˆã‚’è¡Œã„ã€ãã‚Œã§ã‚‚ä¸å¯ãªã‚‰æ¤œè¨¼æ®µéšŽã§ FAILED ã¨ã™ã‚‹å‰æã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
          - meta/domain-templates/<domain>/constraints.yaml ãŒå­˜åœ¨ã™ã‚‹å ´åˆ:
            * MUST: constraints.composition_rules / timing_constraints / orchestration / path constraints ã‚’é©ç”¨ï¼ˆè©²å½“ã‚¿ã‚¹ã‚¯ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
            * SHOULD: constraints.rule_references / checklist_references ã«åˆ—æŒ™ã•ã‚ŒãŸå„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆrules/*.yaml, checklists/*.mdï¼‰ã‚’é †ã«èª­ã¿ã€MUSTã‚’å„ªå…ˆã—ã¦è¨­è¨ˆã¸åæ˜ 
          - è¤‡æ•°ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒé–¢ä¿‚ã™ã‚‹å ´åˆ:
            * MUST: å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã® constraints / rules / checklists ã‚’çµ±åˆé©ç”¨
            * MUST: ç«¶åˆæ™‚ã¯å®‰å…¨å´ï¼ˆã‚ˆã‚ŠåŽ³ã—ã„MUSTï¼‰ã‚’æŽ¡ç”¨ã—ã€å¦¥å”ç‚¹ã¯æ˜Žè¨˜

          è¨­è¨ˆåŽŸå‰‡ï¼ˆä¾‹ï¼‰:
          - ç”»åƒâ†’å‹•ç”»ãªã©æ˜Žç¤ºçš„ãªç›´åˆ—è¦ä»¶ãŒ constraints/rules ã§ç¤ºã•ã‚Œã‚‹å ´åˆã€å¯¾è±¡ã‚¢ã‚¤ãƒ†ãƒ /ã‚·ãƒ¼ãƒ³ã”ã¨ã«ã€Œç›´åˆ—ãƒã‚§ãƒ¼ãƒ³ã€ã‚’åŒä¸€ã‚¸ãƒ§ãƒ–å†…ã§å®Ÿè¡Œã—ã€å…¨ä½“ã‚’ matrix ã§ä¸¦åˆ—åŒ–ï¼ˆmax-parallel ã¯ constraints ã«å¾“ã†ï¼‰ã€‚
          - é¡žä¼¼ä½œæ¥­ï¼ˆä¾‹: ã‚¹ãƒ©ã‚¤ãƒ‰è¤‡æ•°æžšç”Ÿæˆï¼‰ã¯ä¸¦åˆ—æœ€é©åŒ–ã€‚ãŸã ã—ãƒ‡ãƒ¼ã‚¿ä¾å­˜ãŒã‚ã‚‹å ´åˆã¯ç›´åˆ—åŒ–ã€‚
          - ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãƒ»åˆ¶ç´„ãŒç„¡ã„å ´åˆã¯ã€ã‚¿ã‚¹ã‚¯åˆ†è§£/æœ€é©åŒ–é †åºã«åŸºã¥ãä¸€èˆ¬çš„ãªç›´åˆ—/ä¸¦åˆ—æ§‹æˆã¨ã™ã‚‹ã€‚
          
          é‡è¦: video-productionãƒ‰ãƒ¡ã‚¤ãƒ³ã®å ´åˆ:
          - å¿…ãš workflow_generation_parameters.matrix_scene_list ã‚’ä½¿ç”¨ã—ã¦matrix.sceneã‚’è¨­å®š
          - max-parallelã¯ workflow_generation_parameters.max_parallel ã®å€¤ã‚’ä½¿ç”¨
          - å›ºå®šå€¤ï¼ˆä¾‹: batch: [1,2,3]ï¼‰ã§ã¯ãªãã€è¨ˆç®—ã•ã‚ŒãŸå‹•çš„ãªå€¤ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
          - ç”»åƒç”Ÿæˆï¼ˆT2Iï¼‰â†’å‹•ç”»å¤‰æ›ï¼ˆI2Vï¼‰ã¯å¿…ãšåŒä¸€ã‚¸ãƒ§ãƒ–å†…ã§ç›´åˆ—å®Ÿè¡Œï¼ˆURLæœŸé™å¯¾ç­–ï¼‰
          - å„ã‚·ãƒ¼ãƒ³ã‚¸ãƒ§ãƒ–æ§‹é€ ï¼š
            1. phase1-audio-generation (ç‹¬ç«‹ã‚¸ãƒ§ãƒ–ã¾ãŸã¯äº‹å‰ç”Ÿæˆ)
            2. phase2-image-to-video (matrixä¸¦åˆ—ã‚¸ãƒ§ãƒ–):
               - step1: ç”»åƒç”Ÿæˆ (T2I)
               - step2: å³åº§ã«å‹•ç”»å¤‰æ› (I2V) - åŒä¸€ã‚¸ãƒ§ãƒ–å†…ã§ç›´åˆ—
            3. phase3-bgm-generation (ç‹¬ç«‹ã‚¸ãƒ§ãƒ–)
            4. phase4-composition (å…¨ç´ æçµ±åˆ)

          å‡ºåŠ›å…ˆï¼ˆMUSTï¼‰:
          - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ PROJECT_DIR_PLACEHOLDER/generated-workflow/workflow.yml ã«ç”Ÿæˆ
          EOF
          
          # Replace project directory placeholder with actual path
          sed -i "s|PROJECT_DIR_PLACEHOLDER|$PROJECT_DIR|g" generation_prompt.txt
          
          # Add visibility in logs: which checklists will be referenced
          echo "ðŸ“š Using domain checklists:" >> $GITHUB_STEP_SUMMARY
          if [ -f artifacts/domain-template-data/domain-checklists.txt ]; then
            cat artifacts/domain-template-data/domain-checklists.txt | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
          elif [ -f artifacts/domain-checklists.txt ]; then
            cat artifacts/domain-checklists.txt | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
          else
            echo "- (none found)" >> $GITHUB_STEP_SUMMARY
          fi

          # Also list rule references if present in constraints
          if [ -f artifacts/domain-template-data/domain_summary.json ]; then
            echo "### Domain Rule References" >> $GITHUB_STEP_SUMMARY
            jq -r '.constraints.rule_references[]?.path' artifacts/domain-template-data/domain_summary.json 2>/dev/null | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY || true
          fi

          # Note: do not inject domain-specific helper jobs inline. All domain rules are enforced via referenced checklists during validation/auto-fix.
          
          # Execute workflow generation with explicit output
          echo "ðŸ“ Generating workflow with Claude Code SDK..."
          echo "Target: $PROJECT_DIR/generated-workflow/workflow.yml"
          
          npx @anthropic-ai/claude-code \
            -p "$(cat generation_prompt.txt)" \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Write,Read,MultiEdit,Bash" \
            --permission-mode "acceptEdits" \
            --max-turns 50

          # Do not inlineãƒ‰ãƒ¡ã‚¤ãƒ³è¦ä»¶ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã¯è¡Œã‚ãšã€ç”Ÿæˆæ™‚ã«å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã‚€å½¢ã§åæ˜ ã•ã›ã¾ã™
          
          # Verify workflow was created
          WORKFLOW_PATH="$PROJECT_DIR/generated-workflow/workflow.yml"
          if [ -f "$WORKFLOW_PATH" ]; then
            WORKFLOW_NAME="professional-workflow-${PRIMARY_DOMAIN}-${TIMESTAMP}"
            
            echo "workflow_path=$WORKFLOW_PATH" >> $GITHUB_OUTPUT
            echo "workflow_name=$WORKFLOW_NAME" >> $GITHUB_OUTPUT
            echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
            
            echo "âœ… Workflow generated: $WORKFLOW_NAME"
            
            # Add Phase 5 Report
            echo "## âš¡ Phase 5: ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆ" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å: ${WORKFLOW_NAME}" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³: ${PRIMARY_DOMAIN}" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… GitHub Actionså½¢å¼ã§ç”Ÿæˆå®Œäº†" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Workflow generation failed"
            exit 1
          fi
          
      - name: Upload Generated Workflow
        uses: actions/upload-artifact@v4
        with:
          name: generated-workflow
          path: |
            projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-*

  # ===========================================
  # PHASE 6: VALIDATION & DEPLOYMENT
  # ==========================================
  
  validate-and-deploy:
    name: "âœ… Validate & Deploy"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect','generate-professional-workflow']
    outputs:
      validation_passed: ${{ steps.validate.outputs.passed }}
      workflow_location: ${{ steps.copy.outputs.location }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Generated Workflow
        uses: actions/download-artifact@v4
        with:
          name: generated-workflow
          path: projects/

      - name: Download Domain Template Data (for input schema)
        uses: actions/download-artifact@v4
        with:
          name: domain-template-data
          path: artifacts/

      - name: Inject required inputs into generated workflow from schema
        run: |
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          # Schema file downloaded from 'domain-template-data' artifact into artifacts/
          SCHEMA_PATH="artifacts/domain-input-schema/input-schema.yaml"
          
          # Pre-validate YAML before attempting schema injection
          if ! python -c "import yaml; yaml.safe_load(open('$WORKFLOW_PATH'))" >/dev/null 2>&1; then
            echo "âŒ Generated workflow YAML is invalid. Attempting auto-repair..."
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "Read,Write" \
              --permission-mode "acceptEdits" \
              --max-turns 12 \
              -p "ä»¥ä¸‹ã®YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€GitHub Actionsä»•æ§˜ã«æº–æ‹ ã•ã›ã¦ãã ã•ã„ã€‚\n\nå¯¾è±¡: $WORKFLOW_PATH\nè¦ä»¶:\n- ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã« name, on, jobs ã‚’ä¿æŒ\n- HEREDOCç¦æ­¢ã€‚è¡Œã”ã¨ã«å®‰å…¨ã«ç”Ÿæˆã•ã‚Œã‚‹å½¢ã‚’ç¶­æŒ\n- docs/YAML_CONSTRUCTION_GUIDELINES.md ã®ãƒ«ãƒ¼ãƒ«ã‚’é †å®ˆ\n- æ—¢å­˜ã®æ„å›³ï¼ˆã‚¸ãƒ§ãƒ–/ã‚¹ãƒ†ãƒƒãƒ—æ§‹é€ ï¼‰ã‚’å£Šã•ãªã„\n\nä¿®æ­£å¾Œã¯åŒã˜ãƒ‘ã‚¹ã«ä¸Šæ›¸ãä¿å­˜ã—ã¦ãã ã•ã„ã€‚"

            # Re-validate after auto-repair
            if ! python -c "import yaml; yaml.safe_load(open('$WORKFLOW_PATH'))" >/dev/null 2>&1; then
              echo "::error::Workflow YAML remains invalid after auto-repair. Skipping schema injection."
              exit 1
            fi
            echo "âœ… Auto-repair completed; YAML is now valid."
          fi
          if [ -f "$SCHEMA_PATH" ] && [ -f "$WORKFLOW_PATH" ]; then
            python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; schema_path='$SCHEMA_PATH'; wf=yaml.safe_load(open(wf_path)) or {}; schema=yaml.safe_load(open(schema_path)) or {}; req=(schema.get('inputs') or {}).get('required') or {}; on=wf.setdefault('on',{}); wd=on.setdefault('workflow_dispatch',{}); inputs=wd.setdefault('inputs',{}); [ (inputs.setdefault(k,{}).update({'description':(v.get('description',k)), 'required':True}) or (inputs[k].update({'default':v['default']}) if 'default' in v else None) or (inputs[k].update({'type':'choice','options':v['enum']}) if 'enum' in v else inputs[k].pop('type', None)) ) for k,v in req.items() ]; open(wf_path,'w').write(yaml.safe_dump(wf, sort_keys=False))"
            echo "âœ… Injected required inputs into workflow_dispatch"
          else
            echo "::warning::Schema or workflow file not found; skip injection"
          fi

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Validate Workflow
        id: validate
        run: |
          echo "âœ… Validating generated workflow..."
          
          # Use generated workflow path
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          
          # YAML syntax validation
          python -c "import yaml; yaml.safe_load(open('$WORKFLOW_PATH'))"
          echo "âœ… YAML syntax valid"
          
          # GitHub Actions structure validation (robust against quoted keys)
          python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; wf=yaml.safe_load(open(wf_path)) or {}; sys.exit(0 if isinstance(wf, dict) and 'name' in wf and 'on' in wf and 'jobs' in wf else 1)"
          if [ $? -eq 0 ]; then
            echo "âœ… GitHub Actions structure valid"

            # Input schema compliance validation (file-referenced, no inline duplication)
            if [ -f "artifacts/domain-input-schema/input-schema.yaml" ]; then
              python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; schema_path='artifacts/domain-input-schema/input-schema.yaml'; wf=yaml.safe_load(open(wf_path)) or {}; schema=yaml.safe_load(open(schema_path)) or {}; wf_inputs=(((wf.get('on') or {}).get('workflow_dispatch') or {}).get('inputs') or {}); groups=(schema.get('inputs') or {}); required=(groups.get('required') or {}); missing=[k for k in required.keys() if k not in wf_inputs]; (print('Missing inputs in workflow:', missing) or sys.exit(1)) if missing else None"
              echo "âœ… Input schema alignment (required): OK"
            else
              echo "::warning::No input schema file found for validation"
            fi

            # Static structural checks (non-domain specific)
            echo "ðŸ”Ž Static structural checks..."
            python3 -c "import os, re, sys, yaml; wf_path='$WORKFLOW_PATH'; text=open(wf_path,'r',encoding='utf-8').read(); data=yaml.safe_load(text) or {}; jobs=data.get('jobs') or {}; warnings=[]; [warnings.append(f\"Local action reference detected in job '{job_name}': uses={uses}\") if uses.startswith(('./','../')) else warnings.append(f\"Suspicious action reference (missing @) in job '{job_name}': uses={uses}\") if '@' not in uses and not uses.startswith('docker://') else None for job_name,job in (jobs or {}).items() for step in (job or {}).get('steps',[]) or [] if isinstance(step,dict) and 'uses' in step for uses in [str(step['uses']).strip()]]; warnings.append('No \${PROJECT_DIR}/ occurrences found') if '\${PROJECT_DIR}/' not in text else None; warnings.append('actions/upload-artifact not found') if not re.search(r'actions/upload-artifact@',text) else None; warnings.append('actions/download-artifact not found') if not re.search(r'actions/download-artifact@',text) else None; [print(f'::warning ::{w}') for w in warnings]; print(f'Static checks: {len(warnings)} warning(s)')"
            
            # Domain-aware validation (generic, non-specialized)
            echo "ðŸ” Executing domain-aware validation (generic)..."
            DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
            CONSTRAINTS_PATH="meta/domain-templates/$DOMAIN/constraints.yaml"
            {
              echo "åŸºæœ¬æ¤œè¨¼ã¨ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¶ç´„ã®æ¤œè¨¼ã‚’è¡Œã„ã€validation_result.json ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚";
              echo;
              echo "å¯¾è±¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: $WORKFLOW_PATH";
              echo "åˆ¶ç´„ãƒ•ã‚¡ã‚¤ãƒ«: $CONSTRAINTS_PATH (å­˜åœ¨ã™ã‚‹å ´åˆã®ã¿)";
              echo;
              echo "åŸºæœ¬æ¤œè¨¼:";
              echo "- uses: ã§ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹å‚ç…§ãŒç„¡ã„ã“ã¨";
              echo "- ç”Ÿæˆç‰©ã¯ projects/ é…ä¸‹ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨";
              echo "- ã‚¸ãƒ§ãƒ–é–“å…±æœ‰ã« artifacts ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨";
              echo "- video-productionãƒ‰ãƒ¡ã‚¤ãƒ³ã®å ´åˆ:";
              echo "  * ç”»åƒç”Ÿæˆ(T2I)â†’å‹•ç”»å¤‰æ›(I2V)ãŒåŒä¸€ã‚¸ãƒ§ãƒ–å†…ã§ç›´åˆ—å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨";
              echo "  * è¤‡æ•°ã‚·ãƒ¼ãƒ³ãŒmatrix strategyã§ä¸¦åˆ—åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨";
              echo "  * ã‚·ãƒ¼ãƒ³æ•°ãŒå‹•çš„ã«è¨ˆç®—ã•ã‚ŒãŸå€¤ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨";
              echo;
              echo "åˆ¶ç´„æ¤œè¨¼ï¼ˆä»»æ„ï¼‰:";
              echo "- constraints.composition_rules ãŒã‚ã‚Œã°ã€ãã®è¦ä»¶ï¼ˆpipeline/matrix/max_parallel/duration_allocationï¼‰ã«æ²¿ã£ã¦ã„ã‚‹ã“ã¨";
              echo "- constraints.rule_references ã¨ checklist_references ãŒç¤ºã™ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †ã«èª­ã¿ã€MUSTã‚’å„ªå…ˆã—ã¦å¦¥å½“æ€§ã‚’ç¢ºèªã™ã‚‹ã“ã¨";
              echo "- ç›´åˆ—/ä¸¦åˆ—/matrix/å‘½å/ä¸€è²«æ€§/æ™‚é–“é…åˆ†ãªã©ã®è¦å‰‡ãŒã‚ã‚Œã°é©ç”¨ã•ã‚Œã¦ã„ã‚‹ã“ã¨";
              echo;
              echo '{"overall_result":"PASSED","failed_items":[],"details":{}}';
            } > validation_prompt.txt
            
            # Replace placeholder with actual path
            sed -i "s|WORKFLOW_PATH_PLACEHOLDER|$WORKFLOW_PATH|g" validation_prompt.txt
            
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "Read,Write" \
              --permission-mode "acceptEdits" \
              --max-turns 30 \
              -p "$(cat validation_prompt.txt)"
            
            # Ensure validation_result.json exists (create minimal PASSED if missing)
            if [ ! -f "validation_result.json" ]; then
              echo "âš ï¸ validation_result.json not created - creating minimal PASSED report"
              echo '{"overall_result":"PASSED","failed_items":[],"details":{}}' > validation_result.json
            fi

            # Domain rule structural checks (non-blocking warnings)
            echo "ðŸ”Ž Domain rule structural checks..."
            python3 -c "import os, re, sys, yaml, json; wf_path='$WORKFLOW_PATH'; domain='${{ needs.validate-and-detect.outputs.primary_domain }}'; constraints_path=f'meta/domain-templates/{domain}/constraints.yaml'; constraints=yaml.safe_load(open(constraints_path, 'r', encoding='utf-8')) if os.path.exists(constraints_path) else {}; rule_refs=constraints.get('rule_references') or []; rules_by_name={}; [rules_by_name.update({p: yaml.safe_load(open(p, 'r', encoding='utf-8')) if os.path.exists(p) and p.endswith(('.yaml','.yml')) else None}) for ref in rule_refs if (p:=(ref or {}).get('path'))]; text=open(wf_path, 'r', encoding='utf-8').read(); data=yaml.safe_load(text) or {}; jobs=data.get('jobs') or {}; warns=[]; orc=next((v for k,v in rules_by_name.items() if k.endswith('/rules/orchestration.yaml') and isinstance(v, dict)), None); matrix_key=(((orc.get('matrix') or {}).get('key')) or 'scene') if orc else 'scene'; max_parallel_lim=((orc.get('matrix') or {}).get('max_parallel')) if orc else None; found=any(matrix_key in ((job or {}).get('strategy') or {}).get('matrix', {}) for job in (jobs or {}).values() if isinstance(((job or {}).get('strategy') or {}).get('matrix'), dict)); warns.append(f\"No job with strategy.matrix containing key '{matrix_key}' found\") if orc and not found else None; cons=next((v for k,v in rules_by_name.items() if k.endswith('/rules/consistency.yaml') and isinstance(v, dict)), None); img_pat=((cons.get('naming') or {}).get('image_pattern')) if cons else None; vid_pat=((cons.get('naming') or {}).get('video_pattern')) if cons else None; warns.append('Scene image naming pattern not referenced in workflow text (scene_)') if img_pat and 'scene_' not in text else None; warns.append('Scene video naming pattern not referenced in workflow text (scene_)') if vid_pat and 'scene_' not in text else None; [print(f'::warning ::{w}') for w in warns]; print(f'Domain rule checks: {len(warns)} warning(s)')"
            
            # Check validation result from JSON
            if [ -f "validation_result.json" ]; then
              VALIDATION_RESULT=$(jq -r '.overall_result' validation_result.json 2>/dev/null || echo "FAILED")
              CRITICAL_PASS=$(jq -r '.critical_pass_count' validation_result.json 2>/dev/null || echo "0/10")
              FAILED_ITEMS=$(jq -r '.failed_items[]' validation_result.json 2>/dev/null || echo "Unknown")
              
              echo "ðŸ“Š Validation Result: $VALIDATION_RESULT"
              echo "ðŸ“Š Critical Requirements: $CRITICAL_PASS"
              
              if [ "$VALIDATION_RESULT" = "PASSED" ]; then
                echo "âœ… STRICT validation PASSED - All critical requirements met"
                echo "passed=true" >> $GITHUB_OUTPUT
                
                # Add detailed validation report to summary
                echo "### ðŸŽ¯ Strict Validation Report" >> $GITHUB_STEP_SUMMARY
                echo "- **Result**: âœ… PASSED" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical Requirements**: $CRITICAL_PASS" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              else
                echo "âŒ STRICT validation FAILED - Critical requirements not met"
                echo "âŒ Failed items: $FAILED_ITEMS"
                
                # Add failure report to summary
                echo "### ðŸš¨ Strict Validation Report" >> $GITHUB_STEP_SUMMARY
                echo "- **Result**: âŒ FAILED" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical Requirements**: $CRITICAL_PASS" >> $GITHUB_STEP_SUMMARY
                echo "- **Failed Items**:" >> $GITHUB_STEP_SUMMARY
                echo "$FAILED_ITEMS" | while read item; do
                  echo "  - $item" >> $GITHUB_STEP_SUMMARY
                done
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "- **Action**: Attempting auto-fix..." >> $GITHUB_STEP_SUMMARY

                echo "ðŸ”§ Attempting generic auto-fix based on domain constraints..."

                # Build rule file list from constraints (if any) for precise autofix
                RULE_FILES=$(jq -r '.constraints.rule_references[]?.path' artifacts/domain-template-data/domain_summary.json 2>/dev/null || true)
                CHECKLIST_FILES=$(jq -r '.constraints.checklist_references[]?.path' artifacts/domain-template-data/domain_summary.json 2>/dev/null || true)

                echo "ðŸ”§ AI auto-fix with explicit domain rule inputs..."
                npx @anthropic-ai/claude-code \
                  --mcp-config ".claude/mcp-kamuicode.json" \
                  --allowedTools "Read,Write" \
                  --permission-mode "acceptEdits" \
                  --max-turns 40 \
                  -p "æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ¤œè¨¼å¤±æ•—ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

                  å¯¾è±¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: $WORKFLOW_PATH
                  æ¤œè¨¼çµæžœ: validation_result.json
                  ãƒ‰ãƒ¡ã‚¤ãƒ³: $DOMAIN
                  åˆ¶ç´„: $CONSTRAINTS_PATH
                  ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:\n$RULE_FILES
                  ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆä¸€è¦§:\n$CHECKLIST_FILES

                  å¿…é ˆä¿®æ­£ï¼ˆMUSTï¼‰:
                  1) ãƒ­ãƒ¼ã‚«ãƒ« uses ã®æŽ’é™¤ / ã™ã¹ã¦ã®å‡ºåŠ›ã‚’ ${PROJECT_DIR} é…ä¸‹ã¸ / artifacts ã«ã‚ˆã‚‹å…±æœ‰
                  2) constraints.composition_rules / rules/orchestration.yaml ã«å¾“ã„ã€è©²å½“ã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆ:
                     - per-item/perscene ç›´åˆ—ãƒã‚§ãƒ¼ãƒ³ï¼ˆä¾‹: generate_image -> image_to_videoï¼‰ã‚’åŒä¸€ã‚¸ãƒ§ãƒ–å†…ã§å®Ÿè¡Œ
                     - strategy.matrix ã‚’å°Žå…¥ã—ã€matrix.keyï¼ˆrulesã®matrix.keyï¼‰ã§ä¸¦åˆ—åŒ–
                     - strategy.max-parallel ã‚’ rulesã® max_parallel ä»¥ä¸‹ã«è¨­å®š
                  3) rules/consistency.yaml ã®å‘½åè¦ç´„ï¼ˆimage_pattern / video_patternï¼‰ã¨è§£åƒåº¦/éŸ³å£°åŸºæº–ã‚’æº€ãŸã™ã‚ˆã†å‘½åãƒ»è¨­å®š
                  4) paths: ${PROJECT_DIR}/media/{images|videos|audio}/ ãŠã‚ˆã³ ${PROJECT_DIR}/metadata/ ã«æ•´ãˆã‚‹

                  æŽ¨å¥¨ä¿®æ­£ï¼ˆSHOULDï¼‰:
                  - checklist ã® MUST/SHOULD ã®ã†ã¡ã€å®Ÿè£…å¯èƒ½ãªé …ç›®ã¯é©ç”¨

                  å¤‰æ›´ã¯ $WORKFLOW_PATH ã«ä¸Šæ›¸ãä¿å­˜ã€‚fix_summary.txt ã«ä¿®æ­£ç‚¹ã®è¦ç´„ï¼ˆé©ç”¨ã—ãŸãƒ«ãƒ¼ãƒ«ã€å¤‰æ›´ç®‡æ‰€ï¼‰ã‚’è¨˜éŒ²ã€‚"

                # Safety cap for max-parallel if still exceeding rule limit
                echo "Applying safety cap for max-parallel..."
              
                if [ $? -eq 0 ]; then
                  echo "âœ… Auto-fix completed - Re-validating..."
                  
                  # Re-validate after fix
                npx @anthropic-ai/claude-code \
                  --mcp-config ".claude/mcp-kamuicode.json" \
                  --allowedTools "Read,Write" \
                  --permission-mode "acceptEdits" \
                  --max-turns 10 \
                  -p "ä¿®æ­£å¾Œã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å†æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚

                  å¯¾è±¡: $WORKFLOW_PATH
                  ãƒ‰ãƒ¡ã‚¤ãƒ³: $DOMAIN
                  åˆ¶ç´„: $CONSTRAINTS_PATHï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
                  
                  1) åŸºæœ¬æ¤œè¨¼ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«usesç¦æ­¢ã€artifactsåˆ©ç”¨ã€æ§‹é€ å¦¥å½“æ€§ï¼‰
                  2) åˆ¶ç´„ãŒã‚ã‚‹å ´åˆã®ã¿ composition_rules ã®é©ç”¨ç¢ºèª
                  çµæžœã‚’ revalidation_result.json ã«ä¿å­˜"
                  
                  if [ -f "revalidation_result.json" ]; then
                    REVALIDATION_RESULT=$(jq -r '.overall_result' revalidation_result.json 2>/dev/null || echo "FAILED")
                    if [ "$REVALIDATION_RESULT" = "PASSED" ]; then
                      echo "âœ… Re-validation PASSED - All issues fixed"
                      echo "passed=true" >> $GITHUB_OUTPUT
                    else
                      echo "âŒ Re-validation FAILED - Some issues remain"
                      echo "passed=false" >> $GITHUB_OUTPUT
                    fi
                  else
                    echo "âŒ Re-validation failed to complete"
                    echo "passed=false" >> $GITHUB_OUTPUT
                  fi
                else
                  echo "âŒ Auto-fix failed - manual intervention required"
                  echo "passed=false" >> $GITHUB_OUTPUT
                fi
              fi
            else
              echo "âŒ Validation result file not found"
              echo "passed=false" >> $GITHUB_OUTPUT
            fi
            
            # Add Phase 6 Report
            echo "## âœ… Phase 6: åŒ…æ‹¬æ¤œè¨¼ & é…ç½®" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… YAMLæ§‹æ–‡æ¤œè¨¼: æ­£å¸¸" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… GitHub Actionsæ§‹é€ æ¤œè¨¼: æ­£å¸¸" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–åŒ…æ‹¬æ¤œè¨¼: å®Œäº†" >> $GITHUB_STEP_SUMMARY
            echo "- âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é…ç½®æº–å‚™å®Œäº†" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Invalid GitHub Actions structure"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Upload Validation Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: |
            validation_result.json
            revalidation_result.json
          if-no-files-found: warn
          
      - name: Copy Workflow to Final Location
        id: copy
        run: |
          echo "ðŸ“‹ Copying workflow to final location..."
          
          # Use generated workflow path
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          
          # Use the project directory from previous job
          PROJECT_DIR="${{ needs.generate-professional-workflow.outputs.project_dir }}"
          
          # Create project directory on this runner (it doesn't exist yet)
          mkdir -p "$PROJECT_DIR"
          
          # Copy to final location in project directory
          FINAL_DIR="${PROJECT_DIR}/final-workflow"
          mkdir -p "$FINAL_DIR"
          cp "$WORKFLOW_PATH" "$FINAL_DIR/${WORKFLOW_NAME}.yml"
          
          # Create deployment instructions
          cat > "$FINAL_DIR/DEPLOYMENT_INSTRUCTIONS.md" << EOF
          # Workflow Deployment Instructions
          
          ## Generated Workflow
          - **Name**: ${WORKFLOW_NAME}
          - **File**: ${WORKFLOW_NAME}.yml
          - **Domain**: ${{ needs.validate-and-detect.outputs.primary_domain }}
          - **Issue**: #${{ needs.validate-and-detect.outputs.issue_number }}
          
          ## Manual Deployment Steps
          1. Review the generated workflow file
          2. Copy to \`.github/workflows/\` directory if needed
          3. Ensure all required secrets are configured
          4. Test with \`workflow_dispatch\` trigger
          
          ## Workflow Summary
          Generated from professional domain templates with:
          - Domain-specific constraints applied
          - Optimized task dependencies
          - Professional quality standards
          EOF
          
          echo "âœ… Workflow saved to: $FINAL_DIR/${WORKFLOW_NAME}.yml"
          echo "ðŸ“ Deployment instructions: $FINAL_DIR/DEPLOYMENT_INSTRUCTIONS.md"
          
          echo "location=$FINAL_DIR" >> $GITHUB_OUTPUT
          
      - name: Update Issue
        run: |
          # Use input parameter for workflow_dispatch, or job output for issue_comment
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            ISSUE_NUMBER="${{ inputs.issue_number }}"
          else
            ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          fi
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          
          # Get project directory from previous job
          PROJECT_DIR="${{ needs.generate-professional-workflow.outputs.project_dir }}"
          PROJECT_NAME=$(basename "$PROJECT_DIR")
          
          gh issue comment "$ISSUE_NUMBER" --body "## âœ… Professional Workflow Generated!
          
          **Workflow Name**: \`$WORKFLOW_NAME\`
          **Domain**: $DOMAIN
          **Status**: Successfully generated and validated
          
          ### ðŸ“‹ Summary:
          - Applied professional domain expertise
          - Incorporated domain-specific constraints
          - Optimized task dependencies
          - Validated GitHub Actions structure
          
          ### ðŸ“ Output Location:
          - **Project Directory**: \`projects/$PROJECT_NAME/\`
          - **Workflow File**: \`final-workflow/${WORKFLOW_NAME}.yml\`
          - **Deployment Guide**: \`final-workflow/DEPLOYMENT_INSTRUCTIONS.md\`
          
          ### ðŸš€ Next Steps:
          1. Download the workflow from artifacts
          2. Review the generated workflow
          3. Deploy manually to \`.github/workflows/\` if needed
          4. Configure required secrets
          5. Test with \`workflow_dispatch\`
          
          ---
          *Generated by Meta Workflow v12 with Domain Templates*"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ===========================================
  # PHASE 7: REGENERATION LOOP (IF NEEDED)
  # ===========================================
  
  regeneration-loop:
    name: "ðŸ”„ ä¿®æ­£ãƒ»å†ç”Ÿæˆãƒ«ãƒ¼ãƒ—"
    runs-on: ubuntu-latest
    needs: ['validate-and-deploy', 'validate-and-detect', 'load-domain-templates']
    if: needs.validate-and-deploy.outputs.validation_passed == 'false'
    outputs:
      regeneration_attempt: ${{ steps.attempt.outputs.regeneration_attempt }}
      regeneration_success: ${{ steps.regenerate.outputs.success }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Environment
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml
          
      - name: Download All Previous Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Record Regeneration Attempt
        id: attempt
        run: |
          echo "ðŸ”„ æ¤œè¨¼å¤±æ•—ã«ã‚ˆã‚‹å†ç”Ÿæˆã‚’é–‹å§‹..."
          ATTEMPT_COUNT=1
          echo "regeneration_attempt=$ATTEMPT_COUNT" >> $GITHUB_OUTPUT
          
          echo "## ðŸ”„ Phase 7: ä¿®æ­£ãƒ»å†ç”Ÿæˆãƒ«ãƒ¼ãƒ—" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸš¨ åˆå›žç”Ÿæˆã®æ¤œè¨¼å¤±æ•—ã‚’æ¤œå‡º" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”„ è‡ªå‹•å†ç”Ÿæˆã‚’å®Ÿè¡Œä¸­..." >> $GITHUB_STEP_SUMMARY
          
      - name: Analyze Validation Failures
        id: analyze
        run: |
          echo "ðŸ” æ¤œè¨¼å¤±æ•—ã®è©³ç´°åˆ†æž..."
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          
          # Extract specific failure reasons from previous validation
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            --max-turns 20 \
            -p "æ¤œè¨¼å¤±æ•—ã®åŽŸå› ã‚’è©³ç´°åˆ†æžã—ã¦ãã ã•ã„:
            
          å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«:
          1. projects/workflow-execution-logs/meta-workflow-construction-checklist.md (æ±Žç”¨å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³)
          2. meta/domain-templates/$DOMAIN/checklist-*-specific.md (ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³)
          3. artifacts/ (å‰å›žã®å®Ÿè¡Œçµæžœ)
          
          åˆ†æžé …ç›®:
          - ã©ã®æ¤œè¨¼é …ç›®ã§å¤±æ•—ã—ãŸã‹
          - å¤±æ•—ã®æ ¹æœ¬åŽŸå› 
          - ä¿®æ­£ã™ã¹ãå…·ä½“çš„ãªãƒã‚¤ãƒ³ãƒˆ
          - å†ç”Ÿæˆæ™‚ã®æ”¹å–„æ–¹é‡
          
          åˆ†æžçµæžœã‚’artifacts/failure_analysis.jsonã«ä¿å­˜ã—ã¦ãã ã•ã„:
          {
            \"failure_reasons\": [\"åŽŸå› 1\", \"åŽŸå› 2\"],
            \"critical_issues\": [\"é‡è¦ãªå•é¡Œ1\", \"é‡è¦ãªå•é¡Œ2\"],
            \"improvement_strategy\": \"æ”¹å–„æˆ¦ç•¥ã®è©³ç´°\",
            \"regeneration_focus\": [\"å†ç”Ÿæˆã§ç‰¹ã«æ³¨æ„ã™ã¹ãç‚¹1\", \"ç‚¹2\"]
          }"
          
          if [ -f "artifacts/failure_analysis.json" ]; then
            echo "âœ… å¤±æ•—åˆ†æžå®Œäº†"
            echo "- âœ… å¤±æ•—åŽŸå› ã®ç‰¹å®šå®Œäº†" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ å¤±æ•—åˆ†æžã«å¤±æ•— - Fallbackã‚’ä½œæˆ"
            # Fallback: use validation report to craft minimal analysis
            REPORT_DIR="artifacts/validation-report"
            REPORT_FILE=""
            if [ -f "$REPORT_DIR/validation_result.json" ]; then
              REPORT_FILE="$REPORT_DIR/validation_result.json"
            elif [ -f "validation_result.json" ]; then
              REPORT_FILE="validation_result.json"
            fi
            mkdir -p artifacts
            if [ -n "$REPORT_FILE" ]; then
              jq -n --argjson failed "$(jq -r '.failed_items // []' "$REPORT_FILE" 2>/dev/null || echo '[]')" '{failure_reasons:$failed, critical_issues:$failed, improvement_strategy:"Auto-fallback from validation_result.json", regeneration_focus:$failed}' > artifacts/failure_analysis.json || echo '{"failure_reasons":[],"critical_issues":[],"improvement_strategy":"fallback","regeneration_focus":[]}' > artifacts/failure_analysis.json
              echo "- âš ï¸ Fallback failure_analysis.json ã‚’ä½œæˆ" >> $GITHUB_STEP_SUMMARY
            else
              echo '{"failure_reasons":[],"critical_issues":[],"improvement_strategy":"no-report","regeneration_focus":[]}' > artifacts/failure_analysis.json
              echo "- âš ï¸ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆæœªæ¤œå‡ºã®ãŸã‚ç©ºã®åˆ†æžã‚’ä½œæˆ" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
      - name: Regenerate with Improved Strategy
        id: regenerate
        run: |
          echo "âš¡ æ”¹å–„æˆ¦ç•¥ã«åŸºã¥ãå†ç”Ÿæˆå®Ÿè¡Œ..."
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          
          # Create regeneration directory
          REGEN_DIR="projects/issue-$ISSUE_NUMBER-regeneration-$(date +%Y%m%d-%H%M%S)"
          mkdir -p "$REGEN_DIR/metadata"
          mkdir -p "$REGEN_DIR/logs"
          mkdir -p "$REGEN_DIR/generated-workflow"
          
          # Enhanced regeneration with failure analysis input (with retries + backoff)
          set +e
          CLI_STATUS=1
          for attempt in {1..3}; do
            echo "ðŸ› ï¸ Regeneration attempt $attempt/3"
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "Read,Write" \
              --permission-mode "acceptEdits" \
              --max-turns 30 \
              -p "æ¤œè¨¼å¤±æ•—ã‚’è¸ã¾ãˆãŸæ”¹å–„ç‰ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†ç”Ÿæˆ:
              
            å‚ç…§ãƒ‡ãƒ¼ã‚¿:
            1. artifacts/failure_analysis.json (å¤±æ•—åˆ†æžçµæžœ)
            2. artifacts/professional_task_decomposition.json (ã‚¿ã‚¹ã‚¯åˆ†è§£)
            3. artifacts/optimized_task_order.json (æœ€é©åŒ–æ¸ˆã¿å®Ÿè¡Œé †åº)
            4. meta/domain-templates/$DOMAIN/ (ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±)
            
            å¿…é ˆä¿®æ­£ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³:
            1. projects/workflow-execution-logs/meta-workflow-construction-checklist.md (æ±Žç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³)
            2. meta/domain-templates/$DOMAIN/checklist-*-specific.md (ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–)
            
            é‡è¦æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ:
            - å‰å›žã®æ¤œè¨¼å¤±æ•—é …ç›®ã‚’å…¨ã¦ä¿®æ­£
            - ç›´åˆ—ä¸¦åˆ—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹é€ ã®ç¢ºå®Ÿãªå®Ÿè£…
            - URLæœŸé™åˆ‡ã‚Œå¯¾ç­–ã®å¼·åŒ–
            - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã®æ”¹å–„
            - ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã®å¼·åŒ–
            - ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–ãƒ¬ãƒãƒ¼ãƒˆå®Ÿè£…ã®æ”¹å–„
            
            æ”¹å–„ã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’$REGEN_DIR/generated-workflow/ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚"
            CLI_STATUS=$?
            if [ $CLI_STATUS -eq 0 ]; then
              break
            fi
            echo "â³ CLI failed (status=$CLI_STATUS). Retrying after backoff..."
            sleep $((attempt * 5))
          done
          set -e
          
          if [ -f "$REGEN_DIR/generated-workflow"/*.yml ]; then
            REGEN_WORKFLOW=$(ls "$REGEN_DIR/generated-workflow"/*.yml | head -1)
            echo "âœ… å†ç”Ÿæˆå®Œäº†: $(basename "$REGEN_WORKFLOW")"
            
            # Quick validation of regenerated workflow
            if ! python -c "import yaml; yaml.safe_load(open('$REGEN_WORKFLOW'))" >/dev/null 2>&1; then
              echo "âŒ å†ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®YAMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼ - è‡ªå‹•ä¿®å¾©ã‚’è©¦è¡Œ"
              npx @anthropic-ai/claude-code \
                --mcp-config ".claude/mcp-kamuicode.json" \
                --allowedTools "Read,Write" \
                --permission-mode "acceptEdits" \
                --max-turns 12 \
                -p "ä»¥ä¸‹ã®YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€GitHub Actionsä»•æ§˜ã«æº–æ‹ ã•ã›ã¦ãã ã•ã„ã€‚\n\nå¯¾è±¡: $REGEN_WORKFLOW\nè¦ä»¶:\n- ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã« name, on, jobs ã‚’ä¿æŒ\n- docs/YAML_CONSTRUCTION_GUIDELINES.md ã‚’é †å®ˆ\n- æ§‹é€ ã¨æ„å›³ã‚’ä¿æŒ\n\nä¿®æ­£å¾Œã¯åŒã˜ãƒ‘ã‚¹ã«ä¸Šæ›¸ãä¿å­˜ã—ã¦ãã ã•ã„ã€‚"
            fi
            
            if python -c "import yaml; yaml.safe_load(open('$REGEN_WORKFLOW'))" >/dev/null 2>&1; then
              echo "âœ… å†ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®YAMLæ§‹æ–‡æ¤œè¨¼: æ­£å¸¸"
              echo "success=true" >> $GITHUB_OUTPUT
              
              echo "- âœ… æ”¹å–„ç‰ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†ç”Ÿæˆå®Œäº†" >> $GITHUB_STEP_SUMMARY
              echo "- âœ… YAMLæ§‹æ–‡æ¤œè¨¼: æ­£å¸¸" >> $GITHUB_STEP_SUMMARY
              echo "- ðŸ“ ä¿å­˜å ´æ‰€: $REGEN_DIR/generated-workflow/" >> $GITHUB_STEP_SUMMARY
            else
              echo "âŒ å†ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®YAMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼"
              echo "success=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "âŒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†ç”Ÿæˆå¤±æ•—"
            echo "success=false" >> $GITHUB_OUTPUT
            echo "- âŒ å†ç”Ÿæˆå¤±æ•— - æ‰‹å‹•å¯¾å¿œãŒå¿…è¦" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload Regenerated Workflow
        uses: actions/upload-artifact@v4
        if: steps.regenerate.outputs.success == 'true'
        with:
          name: regenerated-workflow
          path: projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-regeneration-*
          if-no-files-found: warn

  # ===========================================
  # PHASE 8: FINAL REPORT DISPLAY
  # ===========================================
  
  display-final-report:
    name: "ðŸ“Š å®Ÿè¡Œå®Œäº†"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order', 'generate-professional-workflow', 'validate-and-deploy', 'regeneration-loop']
    if: always()
    steps:
          
      - name: Add Completion Summary
        run: |
          echo "ðŸ“Š å®Ÿè¡Œå®Œäº†ã‚µãƒžãƒªãƒ¼ã‚’è¿½åŠ ä¸­..."
          
          # åŸºæœ¬æƒ…å ±
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          VALIDATION_STATUS="${{ needs.validate-and-deploy.outputs.validation_passed }}"
          
          # å®Ÿè¡Œå®Œäº†ã‚µãƒžãƒªãƒ¼ã‚’è¿½åŠ 
          echo "## ðŸŽ‰ å®Ÿè¡Œå®Œäº†" >> $GITHUB_STEP_SUMMARY
          echo "- **å®Œäº†æ™‚åˆ»**: $(date '+%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          
          # å†ç”Ÿæˆçµæžœã®ç¢ºèª
          REGENERATION_SUCCESS="${{ needs.regeneration-loop.outputs.regeneration_success }}"
          REGENERATION_ATTEMPTED="${{ needs.regeneration-loop.outputs.regeneration_attempt }}"
          
          if [ "$VALIDATION_STATUS" = "true" ]; then
            echo "- **å…¨ä½“å®Ÿè¡Œçµæžœ**: âœ… æˆåŠŸï¼ˆåˆå›žç”Ÿæˆï¼‰" >> $GITHUB_STEP_SUMMARY
          elif [ "$REGENERATION_SUCCESS" = "true" ]; then
            echo "- **å…¨ä½“å®Ÿè¡Œçµæžœ**: âœ… æˆåŠŸï¼ˆå†ç”Ÿæˆã«ã‚ˆã‚Šä¿®æ­£ï¼‰" >> $GITHUB_STEP_SUMMARY
            echo "- **å†ç”Ÿæˆå®Ÿè¡Œ**: âœ… å®Œäº†ï¼ˆæ¤œè¨¼å¤±æ•—ã‚’è‡ªå‹•ä¿®æ­£ï¼‰" >> $GITHUB_STEP_SUMMARY
          elif [ "$REGENERATION_ATTEMPTED" = "1" ]; then
            echo "- **å…¨ä½“å®Ÿè¡Œçµæžœ**: âŒ å¤±æ•—ï¼ˆå†ç”Ÿæˆã§ã‚‚ä¿®æ­£ä¸å¯ï¼‰" >> $GITHUB_STEP_SUMMARY
            echo "- **å†ç”Ÿæˆå®Ÿè¡Œ**: âŒ å¤±æ•—ï¼ˆæ‰‹å‹•å¯¾å¿œãŒå¿…è¦ï¼‰" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **å…¨ä½“å®Ÿè¡Œçµæžœ**: âš ï¸ ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼ã‚ã‚Š" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æƒ…å ±
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## ðŸ“¥ æˆæžœç‰©ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          
          ãƒ­ãƒ¼ã‚«ãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒžãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š
          
          \`\`\`bash
          # ã™ã¹ã¦ã®æˆæžœç‰©ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          gh run download ${{ github.run_id }}
          
          # ç‰¹å®šã®æˆæžœç‰©ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          gh run download ${{ github.run_id }} -n generated-workflow
          EOF
          
          # å†ç”Ÿæˆã•ã‚ŒãŸå ´åˆã®è¿½åŠ æƒ…å ±
          if [ "$REGENERATION_SUCCESS" = "true" ]; then
            cat >> $GITHUB_STEP_SUMMARY << EOF
          
          # å†ç”Ÿæˆç‰ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæŽ¨å¥¨ï¼‰
          gh run download ${{ github.run_id }} -n regenerated-workflow
          EOF
          fi
          
          cat >> $GITHUB_STEP_SUMMARY << EOF
          \`\`\`
          EOF
