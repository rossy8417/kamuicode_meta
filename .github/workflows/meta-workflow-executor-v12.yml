name: "Meta Workflow Executor v12 with Domain Templates"
run-name: "🚀 Meta Workflow v12 | Issue #${{ inputs.issue_number || github.event.issue.number }} | ${{ github.actor }}"

on:
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number for workflow generation request'
        required: true
        default: '66'
  
  issue_comment:
    types: [created]

permissions:
  contents: write
  issues: write
  actions: write
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  bootstrap:
    name: "🧩 Bootstrap Diagnostics"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'issue_comment' && github.event.issue.pull_request == null && contains(github.event.comment.body, '/start'))
    steps:
      - name: Print event context
        run: |
          echo "event_name=${{ github.event_name }}"
          echo "actor=${{ github.actor }}"
          echo "ref=${{ github.ref }}"
          echo "issue_number_from_dispatch=${{ inputs.issue_number }}"
          echo "is_issue_comment=$([ "${{ github.event_name }}" = "issue_comment" ] && echo true || echo false)"
          if [ "${{ github.event_name }}" = "issue_comment" ]; then
            echo "comment_body<<EOT"
            echo "${{ github.event.comment.body }}"
            echo "EOT"
          fi
          echo "Bootstrap OK"
  
  # ===========================================
  # PHASE 1: ISSUE VALIDATION & DOMAIN DETECTION
  # ===========================================
  
  validate-and-detect:
    name: "🔍 Issue Validation & Domain Detection"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'issue_comment' && github.event.issue.pull_request == null && contains(github.event.comment.body, '/start'))
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
      issue_title: ${{ steps.extract.outputs.issue_title }}
      primary_domain: ${{ steps.detect.outputs.primary_domain }}
      detected_domains: ${{ steps.detect.outputs.detected_domains }}
      domain_count: ${{ steps.detect.outputs.domain_count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
        
      - name: Extract Issue Information
        id: extract
        run: |
          # Check if this is a valid trigger
          if [ "${{ github.event_name }}" == "issue_comment" ]; then
            COMMENT_BODY="${{ github.event.comment.body }}"
            # For issue comments, check if it's a start command
            if ! echo "$COMMENT_BODY" | grep -qE '(/start|^start$|^実行$|^execute$)'; then
              echo "::notice::Skipping - Comment does not contain start command"
              echo "issue_number=skip" >> $GITHUB_OUTPUT
              exit 0
            fi
            ISSUE_NUMBER="${{ github.event.issue.number }}"
          else
            # workflow_dispatch always proceeds
            ISSUE_NUMBER="${{ inputs.issue_number }}"
          fi
          
          echo "🔍 Analyzing Issue #$ISSUE_NUMBER..."
          
          # Get issue details using GitHub CLI
          ISSUE_DATA=$(gh issue view $ISSUE_NUMBER --json title,body,number --jq '{title: .title, body: .body, number: .number}')
          
          ISSUE_TITLE=$(echo "$ISSUE_DATA" | jq -r '.title')
          ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body')
          ISSUE_NUMBER=$(echo "$ISSUE_DATA" | jq -r '.number')
          
          # Save to artifacts for next jobs
          mkdir -p artifacts
          echo "$ISSUE_TITLE" > artifacts/issue_title.txt
          echo "$ISSUE_BODY" > artifacts/issue_body.txt
          echo "$ISSUE_NUMBER" > artifacts/issue_number.txt
          
          # Combine title and body for domain detection
          echo -e "$ISSUE_TITLE\n\n$ISSUE_BODY" > artifacts/issue_content.txt
          
          # Output minimal data
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          echo "issue_title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          
          echo "✅ Issue #$ISSUE_NUMBER validated: $ISSUE_TITLE"
          
          # Initialize Progressive Report in GitHub Actions Summary
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # 🎯 Meta Workflow v12 実行レポート
          
          ## 📋 実行概要
          EOF
          
          echo "- **Issue番号**: #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
          echo "- **Issue タイトル**: ${ISSUE_TITLE}" >> $GITHUB_STEP_SUMMARY  
          echo "- **実行開始時刻**: $(date '+%Y年%m月%d日 %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          echo "- **実行状況**: 🔄 進行中..." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## 🔍 Phase 1: Issue検証 & ドメイン検出" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Issue #${ISSUE_NUMBER} 内容取得完了" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ ドメイン検出: video-production" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Detect Domain from Issue
        id: detect
        run: |
          echo "🎯 Detecting domain from issue content..."
          
          python scripts/domain-template-loader.py \
            --action detect \
            --issue artifacts/issue_content.txt \
            --output artifacts/domain_detection.json
          
          # Extract results
          PRIMARY_DOMAIN=$(jq -r '.primary_domain' artifacts/domain_detection.json)
          DETECTED_DOMAINS=$(jq -c '.detected_domains' artifacts/domain_detection.json)
          DOMAIN_COUNT=$(jq '.detected_domains | length' artifacts/domain_detection.json)
          
          echo "primary_domain=$PRIMARY_DOMAIN" >> $GITHUB_OUTPUT
          echo "detected_domains=$DETECTED_DOMAINS" >> $GITHUB_OUTPUT
          echo "domain_count=$DOMAIN_COUNT" >> $GITHUB_OUTPUT
          
          echo "✅ Primary domain detected: $PRIMARY_DOMAIN"
          echo "📊 Total domains detected: $DOMAIN_COUNT"
          
      - name: Upload Issue and Domain Data
        uses: actions/upload-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/

  # ===========================================
  # PHASE 2: DOMAIN TEMPLATE LOADING
  # ===========================================
  
  load-domain-templates:
    name: "📚 Load Domain Templates"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect']
    if: |
      needs.validate-and-detect.outputs.issue_number != 'skip' &&
      needs.validate-and-detect.outputs.primary_domain != 'null'
    outputs:
      template_summary: ${{ steps.load.outputs.template_summary }}
      chunk_count: ${{ steps.load.outputs.chunk_count }}
      input_schema: ${{ steps.inputs.outputs.input_schema }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download Issue Data
        uses: actions/download-artifact@v4
        with:
          name: issue-domain-data
          path: artifacts/
          
      - name: Load Primary Domain Template
        id: load
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          echo "📚 Loading template for domain: $PRIMARY_DOMAIN"
          
          # Get domain summary for task decomposition
          python scripts/domain-template-loader.py \
            --action summary-for-decomposition \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_decomposition_data.json
          
          # Also get standard summary for reference
          python scripts/domain-template-loader.py \
            --action summary \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/domain_summary.json
          
          # Split template into chunks
          python scripts/domain-template-loader.py \
            --action split \
            --domain "$PRIMARY_DOMAIN" \
            --output artifacts/template_chunks.json
          
          # Extract basic info only (not full JSON)
          DOMAIN_NAME=$(jq -r '.domain_info.name' artifacts/domain_decomposition_data.json)
          EXPERT_ROLE=$(jq -r '.domain_info.expert' artifacts/domain_decomposition_data.json)
          CHUNK_COUNT=$(jq '.total_chunks' artifacts/template_chunks.json)
          
          echo "domain_name=$DOMAIN_NAME" >> $GITHUB_OUTPUT
          echo "expert_role=$EXPERT_ROLE" >> $GITHUB_OUTPUT
          echo "chunk_count=$CHUNK_COUNT" >> $GITHUB_OUTPUT
          
          echo "✅ Template loaded: $DOMAIN_NAME ($CHUNK_COUNT chunks)"
          
          # Add Phase 2 Report
          echo "## 📚 Phase 2: ドメインテンプレート読み込み" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ ドメイン: ${DOMAIN_NAME}" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ 専門家役割: ${EXPERT_ROLE}" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ テンプレートチャンク数: ${CHUNK_COUNT}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Locate and Copy Domain Input Schema
        id: inputs
        run: |
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          SCHEMA_PATH="meta/domain-templates/$PRIMARY_DOMAIN/input-schema.yaml"
          mkdir -p artifacts/domain-input-schema
          if [ -f "$SCHEMA_PATH" ]; then
            cp "$SCHEMA_PATH" artifacts/domain-input-schema/input-schema.yaml
            echo "input_schema=artifacts/domain-input-schema/input-schema.yaml" >> $GITHUB_OUTPUT
            echo "✅ Input schema found: $SCHEMA_PATH"
            echo "- ✅ 入力スキーマ検出: $PRIMARY_DOMAIN/input-schema.yaml" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Input schema not found for domain: $PRIMARY_DOMAIN"
            echo "input_schema=" >> $GITHUB_OUTPUT
            echo "- ❌ 入力スキーマ未検出" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload Template Data
        uses: actions/upload-artifact@v4
        with:
          name: domain-template-data
          path: artifacts/

  # ===========================================
  # PHASE 3: PROFESSIONAL TASK DECOMPOSITION
  # ===========================================
  
  professional-task-decomposition:
    name: "🧠 Professional Task Decomposition"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates']
    outputs:
      task_count: ${{ steps.decompose.outputs.task_count }}
      dependency_groups: ${{ steps.decompose.outputs.dependency_groups }}
      estimated_duration: ${{ steps.decompose.outputs.estimated_duration }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install Dependencies
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download and Merge Previous Artifacts
        run: |
          echo "📥 Downloading artifacts from previous jobs..."
          
          # Download artifacts selectively
          mkdir -p artifacts
          
          # Download issue-domain-data
          echo "Downloading issue-domain-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "issue-domain-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/issue-domain-data.zip
            unzip -q -o artifacts/issue-domain-data.zip -d artifacts/issue-domain-data/
            rm artifacts/issue-domain-data.zip
          done
          
          # Download domain-template-data
          echo "Downloading domain-template-data..."
          gh api "/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
            --jq '.artifacts[] | select(.name == "domain-template-data") | .id' | \
          while read -r artifact_id; do
            gh api "/repos/${{ github.repository }}/actions/artifacts/${artifact_id}/zip" \
              --header "Accept: application/vnd.github+json" \
              > artifacts/domain-template-data.zip
            unzip -q -o artifacts/domain-template-data.zip -d artifacts/domain-template-data/
            rm artifacts/domain-template-data.zip
          done
          
          # Merge artifacts to flat structure
          echo "Merging artifacts..."
          find artifacts -type f -name "*.json" -o -name "*.txt" -o -name "*.yaml" | while read -r file; do
            filename=$(basename "$file")
            if [ ! -f "artifacts/$filename" ]; then
              cp "$file" "artifacts/$filename"
            fi
          done
          
          echo "✅ Artifacts downloaded and merged"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Professional Task Decomposition with Domain Knowledge
        id: decompose
        run: |
          echo "🧠 Starting professional task decomposition..."
          
          # Create decomposition prompt using file references
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          EXPERT_ROLE="${{ needs.load-domain-templates.outputs.expert_role }}"
          
          cat > decomposition_prompt.txt << 'EOF'
          専門的なタスク分解を実行してください。
          
          以下のファイルを読み込んでタスク分解を行ってください：
          1. ドメイン専門知識: artifacts/domain-template-data/domain_decomposition_data.json
          2. ユーザーリクエスト: artifacts/issue-domain-data/issue_content.txt
          
          ドメイン専門知識ファイルには以下が含まれています：
          - expert_context: 専門家の完全な知識
          - task_decomposition_context: ワークフローパターンと最適化情報
          - constraints_and_requirements: すべての制約事項
          - implementation_resources: 利用可能なリソース
          - complex_thinking_guide: 思考プロセスのガイド
          
          タスク分解の手順：
          1. domain_decomposition_data.jsonのexpert_contextを完全に理解
          2. task_decomposition_contextのワークフローパターンを参照
          3. constraints_and_requirementsのすべての制約を考慮
          4. complex_thinking_guideに従って複雑な思考プロセスを実行
          5. implementation_resourcesから最適なリソースを選択
          
          出力をartifacts/professional_task_decomposition.jsonに保存してください。
          
          出力形式：
          {
            "professional_analysis": {
              "understanding": "リクエストの専門的理解（詳細）",
              "considerations": ["考慮事項のリスト"],
              "thinking_process": "思考プロセスの詳細な記録"
            },
            "tasks": [
              {
                "id": "task-1",
                "name": "タスク名",
                "description": "詳細な説明",
                "reasoning": "なぜこのタスクが必要か",
                "minimal_units": ["unit1", "unit2"],
                "dependencies": [],
                "estimated_duration": "5-10分",
                "professional_notes": "専門的な注意点",
                "quality_criteria": "品質基準"
              }
            ],
            "workflow_optimization": {
              "parallel_groups": [],
              "critical_path": [],
              "optimization_rationale": "最適化の理由"
            },
            "total_estimated_duration": "30分",
            "domain_specific_constraints": []
          }
          EOF
          
          # Add expert role context
          echo "あなたは${EXPERT_ROLE}です。" > final_prompt.txt
          echo "" >> final_prompt.txt
          cat decomposition_prompt.txt >> final_prompt.txt
          
          # Execute Claude Code for task decomposition
          npx @anthropic-ai/claude-code \
            -p "$(cat final_prompt.txt)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            > claude_output.log 2>&1
          
          # Check if execution was successful
          if [ $? -eq 0 ]; then
            echo "✅ Claude Code execution completed"
            
            # Try multiple methods to find the generated file
            if [ -f "artifacts/professional_task_decomposition.json" ]; then
              echo "✅ Found file at expected location"
            elif [ -f "professional_task_decomposition.json" ]; then
              echo "📁 Found file in current directory, moving to artifacts"
              mv professional_task_decomposition.json artifacts/
            else
              # Search for any JSON file that might contain the task decomposition
              echo "🔍 Searching for generated JSON files..."
              find . -name "*.json" -type f -newer final_prompt.txt -exec grep -l "professional_analysis" {} \; | while read -r file; do
                echo "📁 Found potential task decomposition at: $file"
                cp "$file" artifacts/professional_task_decomposition.json
                break
              done
            fi
            
            # Final check
            if [ ! -f "artifacts/professional_task_decomposition.json" ]; then
              echo "❌ Could not find task decomposition file"
              echo "📋 Claude output:"
              cat claude_output.log
              exit 1
            fi
          else
            echo "❌ Claude Code execution failed"
            cat claude_output.log
            exit 1
          fi
          
          # Extract results
          if [ -f "artifacts/professional_task_decomposition.json" ]; then
            TASK_COUNT=$(jq '.tasks | length' artifacts/professional_task_decomposition.json)
            DEPENDENCY_GROUPS=$(jq -c '.dependency_groups' artifacts/professional_task_decomposition.json)
            ESTIMATED_DURATION=$(jq -r '.total_estimated_duration' artifacts/professional_task_decomposition.json)
            
            echo "task_count=$TASK_COUNT" >> $GITHUB_OUTPUT
            echo "dependency_groups=$DEPENDENCY_GROUPS" >> $GITHUB_OUTPUT
            echo "estimated_duration=$ESTIMATED_DURATION" >> $GITHUB_OUTPUT
            
            echo "✅ Decomposed into $TASK_COUNT tasks"
            echo "⏱️ Estimated duration: $ESTIMATED_DURATION"
            
            # Add Phase 3 Report
            echo "## 🧠 Phase 3: プロフェッショナルタスク分解" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ タスク数: ${TASK_COUNT}個" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ 推定実行時間: ${ESTIMATED_DURATION}" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ 依存関係グループ分析完了" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Task decomposition failed"
            exit 1
          fi
          
      - name: Upload Task Decomposition
        uses: actions/upload-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/professional_task_decomposition.json

  # ===========================================
  # PHASE 4: TASK ORDER OPTIMIZATION
  # ===========================================
  
  optimize-task-order:
    name: "🔄 Optimize Task Execution Order"
    runs-on: ubuntu-latest
    needs: ['professional-task-decomposition']
    outputs:
      optimized_order: ${{ steps.optimize.outputs.order }}
      mermaid_available: ${{ steps.optimize.outputs.mermaid_available }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Task Decomposition
        uses: actions/download-artifact@v4
        with:
          name: task-decomposition
          path: artifacts/
          
      - name: Analyze and Optimize Task Order
        id: optimize
        run: |
          echo "🔄 タスク実行順序の最適化..."
          
          # Create artifacts directory
          mkdir -p artifacts
          
          # Run Claude Code SDK with specialized prompt file for reliable Mermaid generation
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            -p "$(cat meta/prompts/task-order-optimization-with-mermaid.md)" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits"
          
          # 結果を確認
          if [ -f "artifacts/optimized_task_order.json" ]; then
            echo "order=true" >> $GITHUB_OUTPUT
            
            # Add Phase 4 Report with Task Order
            echo "## 🔄 Phase 4: タスク実行順序の最適化" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ 依存関係分析完了" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ 並列処理グループ特定" >> $GITHUB_STEP_SUMMARY
            
            # 動的テキスト図を生成（最適化されたタスクから自動生成）
            if [ -f "artifacts/optimized_task_order.json" ]; then
              echo "- ✅ 最適化された実行順序生成完了" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### 📊 実行フロー図（動的生成）" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              
              # JSONから動的にタスクフローを生成（単一行で実行）
              if [ -f "artifacts/optimized_task_order.json" ]; then
                python3 -c "import json; data=json.load(open('artifacts/optimized_task_order.json')); print('タスク実行フロー（動的生成・並列処理最適化済み）:'); print(); [print(f\"⚡ {phase.get('phase', f'Phase {i+1}')} [{phase.get('execution_type', 'sequential').upper()}]\") if phase.get('execution_type') == 'parallel' else print(f\"📋 {phase.get('phase', f'Phase {i+1}')} [{phase.get('execution_type', 'sequential').upper()}]\") for i, phase in enumerate(data.get('optimized_execution_order', []))]" >> $GITHUB_STEP_SUMMARY
                echo "⏱️ 最適化により並列処理を活用した効率的な実行順序を生成" >> $GITHUB_STEP_SUMMARY
              else
                echo "タスクフロー情報が利用できません" >> $GITHUB_STEP_SUMMARY
              fi
              
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "mermaid_available=true" >> $GITHUB_OUTPUT
            else
              echo "- ❌ 最適化順序の生成に失敗" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "mermaid_available=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "order=false" >> $GITHUB_OUTPUT
          fi
          
      # Summary display moved to final report for better organization
          
      - name: Upload Optimized Order
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: optimized-task-order
          path: artifacts/
          if-no-files-found: warn

  # ===========================================
  # PHASE 5: CONSTRAINT-AWARE WORKFLOW GENERATION
  # ===========================================
  
  generate-professional-workflow:
    name: "⚡ Generate Professional Workflow"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order']
    outputs:
      workflow_path: ${{ steps.generate.outputs.workflow_path }}
      workflow_name: ${{ steps.generate.outputs.workflow_name }}
      project_dir: ${{ steps.generate.outputs.project_dir }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Environment
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
          
      - name: Generate Professional Workflow
        id: generate
        run: |
          echo "⚡ Generating professional workflow..."
          
          # Prepare all necessary data
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          PRIMARY_DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Create generation directory with absolute path
          # Use GITHUB_WORKSPACE for consistency across jobs
          if [ -n "$GITHUB_WORKSPACE" ]; then
            BASE_DIR="$GITHUB_WORKSPACE"
          else
            BASE_DIR="$(pwd)"
          fi
          PROJECT_DIR="${BASE_DIR}/projects/issue-${ISSUE_NUMBER}-${TIMESTAMP}"
          mkdir -p "$PROJECT_DIR/generated-workflow"
          
          echo "📁 Project directory: $PROJECT_DIR"
          
          # Load template chunks progressively
          CHUNKS=$(jq -r '.chunks[].id' artifacts/domain-template-data/template_chunks.json)
          
          # Create comprehensive generation prompt
          cat > generation_prompt.txt << 'EOF'
          プロフェッショナルなGitHub Actionsワークフローを生成してください。
          
          以下のファイルから情報を読み込んでください：
          1. タスク分解結果: artifacts/task-decomposition/professional_task_decomposition.json
          2. 最適化されたタスク順序: artifacts/optimized-task-order/optimized_task_order.json (存在する場合)
          3. 入力スキーマ: artifacts/domain-input-schema/input-schema.yaml
          4. 必須入力一覧: artifacts/required_inputs.json（存在する場合）/ artifacts/required_input_keys.txt
          
          ワークフロー生成の要件：
          1. uses: でローカルファイルを参照しない（インライン実装）
          2. PROJECT_DIRは各ジョブで明示的に設定：
             PROJECT_DIR="\${GITHUB_WORKSPACE}/projects/\${PROJECT_NAME}-\${TIMESTAMP}"
             mkdir -p "\${PROJECT_DIR}"
          3. MCP使用時は--mcp-configを必ず含める
          4. ジョブ間のファイル共有はartifactsを使用
          5. 各ステップは21000文字以内
          6. 全ての出力は\${PROJECT_DIR}配下に整理
          7. workflow_dispatch の inputs は必ず「入力スキーマファイル」を読み取り反映すること（インライン貼り付け禁止、ファイル参照で設計）
          8. 入力定義は「スキーマの inputs.required の各キー」を GitHub Actions の on.workflow_dispatch.inputs に展開すること：
             - type: enum がある場合は type: choice と options を使用
             - default があれば default を設定
             - description を反映（無ければキー名）
             - required: true を設定
             - recommended/optional は任意（可能なら description のみ comments として保持）
          
          🚨 CRITICAL: You MUST read and follow these guidelines:
          
          1. YAML Construction Guidelines: docs/YAML_CONSTRUCTION_GUIDELINES.md
             - Contains all patterns to avoid (especially HEREDOC)
             - Provides correct file creation examples
             - MANDATORY: Read this file and apply ALL rules
          
          2. Minimal Unit Dependencies: docs/MINIMAL_UNIT_DATA_DEPENDENCIES.md
             - Check input/output specifications for each unit
             - Understand data flow and dependency patterns
             - Identify parallelizable tasks
          
          3. Claude Code SDK CLI Reference: docs/CLAUDE_CODE_SDK_CLI_REFERENCE.md
             - Proper MCP tool naming: mcp__serverName__toolName
             - Required environment variables for CI/CD
             - Best practices for GitHub Actions usage
             - Select appropriate data sharing methods
          
          専門的な品質基準に従って、実務で使えるワークフローを生成してください。
          
          重要: ファイル作成時は必ずYAML Construction Guidelinesのパターンに従ってください。
          
          出力ファイル: projects/issue-66-20250804-004120/generated-workflow/workflow.yml
          EOF
          
          # Replace project directory in prompt
          sed -i "s|projects/issue-66-20250804-004120|$PROJECT_DIR|g" generation_prompt.txt
          
          # Execute workflow generation
          npx @anthropic-ai/claude-code \
            -p "$(cat generation_prompt.txt)" \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Write,Read,MultiEdit" \
            --permission-mode "acceptEdits"
          
          # Verify workflow was created
          WORKFLOW_PATH="$PROJECT_DIR/generated-workflow/workflow.yml"
          if [ -f "$WORKFLOW_PATH" ]; then
            WORKFLOW_NAME="professional-workflow-${PRIMARY_DOMAIN}-${TIMESTAMP}"
            
            echo "workflow_path=$WORKFLOW_PATH" >> $GITHUB_OUTPUT
            echo "workflow_name=$WORKFLOW_NAME" >> $GITHUB_OUTPUT
            echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
            
            echo "✅ Workflow generated: $WORKFLOW_NAME"
            
            # Add Phase 5 Report
            echo "## ⚡ Phase 5: プロフェッショナルワークフロー生成" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ ワークフロー名: ${WORKFLOW_NAME}" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ ドメイン: ${PRIMARY_DOMAIN}" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ GitHub Actions形式で生成完了" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Workflow generation failed"
            exit 1
          fi
          
      - name: Upload Generated Workflow
        uses: actions/upload-artifact@v4
        with:
          name: generated-workflow
          path: |
            projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-*

  # ===========================================
  # PHASE 6: VALIDATION & DEPLOYMENT
  # ==========================================
  
  validate-and-deploy:
    name: "✅ Validate & Deploy"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect','generate-professional-workflow']
    outputs:
      validation_passed: ${{ steps.validate.outputs.passed }}
      workflow_location: ${{ steps.copy.outputs.location }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Generated Workflow
        uses: actions/download-artifact@v4
        with:
          name: generated-workflow
          path: projects/

      - name: Download Domain Template Data (for input schema)
        uses: actions/download-artifact@v4
        with:
          name: domain-template-data
          path: artifacts/

      - name: Inject required inputs into generated workflow from schema
        run: |
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          # Schema file downloaded from 'domain-template-data' artifact into artifacts/
          SCHEMA_PATH="artifacts/domain-input-schema/input-schema.yaml"
          if [ -f "$SCHEMA_PATH" ] && [ -f "$WORKFLOW_PATH" ]; then
            python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; schema_path='$SCHEMA_PATH'; wf=yaml.safe_load(open(wf_path)) or {}; schema=yaml.safe_load(open(schema_path)) or {}; req=(schema.get('inputs') or {}).get('required') or {}; on=wf.setdefault('on',{}); wd=on.setdefault('workflow_dispatch',{}); inputs=wd.setdefault('inputs',{}); [ (inputs.setdefault(k,{}).update({'description':(v.get('description',k)), 'required':True}) or (inputs[k].update({'default':v['default']}) if 'default' in v else None) or (inputs[k].update({'type':'choice','options':v['enum']}) if 'enum' in v else inputs[k].pop('type', None)) ) for k,v in req.items() ]; open(wf_path,'w').write(yaml.safe_dump(wf, sort_keys=False))"
            echo "✅ Injected required inputs into workflow_dispatch"
          else
            echo "::warning::Schema or workflow file not found; skip injection"
          fi

      - name: Install jq
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          
      - name: Validate Workflow
        id: validate
        run: |
          echo "✅ Validating generated workflow..."
          
          # Use generated workflow path
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          
          # YAML syntax validation
          python -c "import yaml; yaml.safe_load(open('$WORKFLOW_PATH'))"
          echo "✅ YAML syntax valid"
          
          # GitHub Actions structure validation (robust against quoted keys)
          python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; wf=yaml.safe_load(open(wf_path)) or {}; sys.exit(0 if isinstance(wf, dict) and 'name' in wf and 'on' in wf and 'jobs' in wf else 1)"
          if [ $? -eq 0 ]; then
            echo "✅ GitHub Actions structure valid"

            # Input schema compliance validation (file-referenced, no inline duplication)
            if [ -f "artifacts/domain-input-schema/input-schema.yaml" ]; then
              python -c "import yaml,sys; wf_path='$WORKFLOW_PATH'; schema_path='artifacts/domain-input-schema/input-schema.yaml'; wf=yaml.safe_load(open(wf_path)) or {}; schema=yaml.safe_load(open(schema_path)) or {}; wf_inputs=(((wf.get('on') or {}).get('workflow_dispatch') or {}).get('inputs') or {}); groups=(schema.get('inputs') or {}); required=(groups.get('required') or {}); missing=[k for k in required.keys() if k not in wf_inputs]; (print('Missing inputs in workflow:', missing) or sys.exit(1)) if missing else None"
              echo "✅ Input schema alignment (required): OK"
            else
              echo "::warning::No input schema file found for validation"
            fi
            
            # STRICT domain-specific validation with mandatory requirements
            echo "🔍 Executing STRICT validation with mandatory requirements..."
            DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
            
            # First attempt: Strict validation with critical requirements
            echo "Creating validation prompt..."
            {
              echo "厳格な検証を実行し、必ず validation_result.json を作成してください。";
              echo;
              echo "ファイル:";
              echo "- 検証対象ワークフロー: WORKFLOW_PATH_PLACEHOLDER";
              echo "- 検証基準: meta/validation/strict-validation-requirements.md";
              echo;
              echo "タスク:";
              echo "1. ワークフローを読み込む";
              echo "2. strict-validation-requirements.md の CRITICAL REQUIREMENTS 10項目を確認";
              echo "3. 各項目の実際の値を抽出して検証";
              echo "4. 結果を validation_result.json に保存";
              echo;
              echo "検証する項目（特に重要）:";
              echo "- CR001: I2V処理の --max-turns の値（80以上必須）";
              echo "- CR003: ファイルサイズ検証（300KB以上のチェック）";
              echo "- CR006: if: always() の使用箇所数（5箇所以上）";
              echo;
              echo "出力形式:";
              echo "{";
              echo "  \"overall_result\": \"PASSED または FAILED\",";
              echo "  \"critical_pass_count\": \"X/10\",";
              echo "  \"failed_items\": [\"失敗項目のリスト\"],";
              echo "  \"details\": {";
              echo "    \"CR001_max_turns\": {\"status\": \"✅/❌\", \"found\": \"実際の値\"},";
              echo "    \"CR003_file_size\": {\"status\": \"✅/❌\", \"found\": \"有/無\"}";
              echo "  }";
              echo "}";
              echo;
              echo "重要: 1つでもCRITICAL要件違反があれば overall_result は FAILED";
            } > validation_prompt.txt
            
            # Replace placeholder with actual path
            sed -i "s|WORKFLOW_PATH_PLACEHOLDER|$WORKFLOW_PATH|g" validation_prompt.txt
            
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "Read,Write" \
              --permission-mode "acceptEdits" \
              --max-turns 30 \
              -p "$(cat validation_prompt.txt)"
            
            # Ensure validation_result.json exists (create fallback if needed)
            if [ ! -f "validation_result.json" ]; then
              echo "⚠️ validation_result.json not created by Claude Code - creating fallback"
              
              # Quick manual check for critical issues
              I2V_MAX_TURNS=$(grep -E "i2v.*--max-turns\s+[0-9]+" "$WORKFLOW_PATH" | grep -oE "[0-9]+" | head -1)
              FILE_SIZE_CHECK=$(grep -c "file_size.*-lt.*300000" "$WORKFLOW_PATH" || echo "0")
              IF_ALWAYS_COUNT=$(grep -c "if:\s*always()" "$WORKFLOW_PATH" || echo "0")
              
              # Create fallback validation result
              echo '{' > validation_result.json
              echo '  "overall_result": "FAILED",' >> validation_result.json
              echo '  "critical_pass_count": "0/10",' >> validation_result.json
              echo '  "failed_items": ["CR001: Max turns検証未完了", "検証タイムアウト"],' >> validation_result.json
              echo '  "details": {' >> validation_result.json
              echo '    "CR001_max_turns": {"status": "❌", "found": "'"${I2V_MAX_TURNS:-unknown}"'"},' >> validation_result.json
              echo '    "CR003_file_size": {"status": "❌", "found": "'"${FILE_SIZE_CHECK}"'"},' >> validation_result.json
              echo '    "CR006_if_always": {"status": "❌", "found": "'"${IF_ALWAYS_COUNT}"'"}' >> validation_result.json
              echo '  },' >> validation_result.json
              echo '  "auto_generated": true,' >> validation_result.json
              echo '  "reason": "Validation timeout - fallback result"' >> validation_result.json
              echo '}' >> validation_result.json
              echo "✅ Fallback validation_result.json created"
            fi
            
            # Check validation result from JSON
            if [ -f "validation_result.json" ]; then
              VALIDATION_RESULT=$(jq -r '.overall_result' validation_result.json 2>/dev/null || echo "FAILED")
              CRITICAL_PASS=$(jq -r '.critical_pass_count' validation_result.json 2>/dev/null || echo "0/10")
              FAILED_ITEMS=$(jq -r '.failed_items[]' validation_result.json 2>/dev/null || echo "Unknown")
              
              echo "📊 Validation Result: $VALIDATION_RESULT"
              echo "📊 Critical Requirements: $CRITICAL_PASS"
              
              if [ "$VALIDATION_RESULT" = "PASSED" ]; then
                echo "✅ STRICT validation PASSED - All critical requirements met"
                echo "passed=true" >> $GITHUB_OUTPUT
                
                # Add detailed validation report to summary
                echo "### 🎯 Strict Validation Report" >> $GITHUB_STEP_SUMMARY
                echo "- **Result**: ✅ PASSED" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical Requirements**: $CRITICAL_PASS" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              else
                echo "❌ STRICT validation FAILED - Critical requirements not met"
                echo "❌ Failed items: $FAILED_ITEMS"
                
                # Add failure report to summary
                echo "### 🚨 Strict Validation Report" >> $GITHUB_STEP_SUMMARY
                echo "- **Result**: ❌ FAILED" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical Requirements**: $CRITICAL_PASS" >> $GITHUB_STEP_SUMMARY
                echo "- **Failed Items**:" >> $GITHUB_STEP_SUMMARY
                echo "$FAILED_ITEMS" | while read item; do
                  echo "  - $item" >> $GITHUB_STEP_SUMMARY
                done
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "- **Action**: Attempting auto-fix..." >> $GITHUB_STEP_SUMMARY
                
                echo "🔧 Attempting auto-fix for failed requirements..."
              
                # Attempt auto-correction with specific failed items
              npx @anthropic-ai/claude-code \
                --mcp-config ".claude/mcp-kamuicode.json" \
                  --allowedTools "Read,Write" \
                  --permission-mode "acceptEdits" \
                  --max-turns 30 \
                  -p "検証で失敗した項目を必ず修正してください:

                問題のあるワークフロー: $WORKFLOW_PATH
                検証結果: validation_result.json
                ドメイン: $DOMAIN

                必須修正項目（validation_result.jsonのfailed_itemsから）:
                $FAILED_ITEMS

                修正ガイドライン（厳密に従うこと）:
                1. meta/validation/strict-validation-requirements.md (全要件の詳細)
                2. projects/workflow-execution-logs/meta-workflow-construction-checklist.md
                3. meta/domain-templates/$DOMAIN/checklist-*-specific.md

                具体的な修正アクション:
                - CR001違反: I2V処理の--max-turnsを80以上に変更
                - CR003違反: 300KB以上のファイルサイズ検証コードを追加
                - CR006違反: if: always()を主要ステップに追加（最低5箇所）
                - CR007違反: Google URL優先処理のパターンを実装
                - CR008違反: リトライロジック（for attempt in {1..3}）を追加

                修正後:
                1. 修正したワークフローを$WORKFLOW_PATHに上書き保存
                2. 修正内容のサマリーをfix_summary.txtに保存"
              
                if [ $? -eq 0 ]; then
                  echo "✅ Auto-fix completed - Re-validating..."
                  
                  # Re-validate after fix
                npx @anthropic-ai/claude-code \
                  --mcp-config ".claude/mcp-kamuicode.json" \
                    --allowedTools "Read,Write" \
                    --permission-mode "acceptEdits" \
                    --max-turns 10 \
                    -p "修正後のワークフローを再検証してください:
                    
                    ワークフロー: $WORKFLOW_PATH
                    検証要件: meta/validation/strict-validation-requirements.md
                    
                    前回失敗した項目が修正されているか確認:
                    $FAILED_ITEMS
                    
                    結果をrevalidation_result.jsonに保存"
                  
                  if [ -f "revalidation_result.json" ]; then
                    REVALIDATION_RESULT=$(jq -r '.overall_result' revalidation_result.json 2>/dev/null || echo "FAILED")
                    if [ "$REVALIDATION_RESULT" = "PASSED" ]; then
                      echo "✅ Re-validation PASSED - All issues fixed"
                      echo "passed=true" >> $GITHUB_OUTPUT
                    else
                      echo "❌ Re-validation FAILED - Some issues remain"
                      echo "passed=false" >> $GITHUB_OUTPUT
                    fi
                  else
                    echo "❌ Re-validation failed to complete"
                    echo "passed=false" >> $GITHUB_OUTPUT
                  fi
                else
                  echo "❌ Auto-fix failed - manual intervention required"
                  echo "passed=false" >> $GITHUB_OUTPUT
                fi
              fi
            else
              echo "❌ Validation result file not found"
              echo "passed=false" >> $GITHUB_OUTPUT
            fi
            
            # Add Phase 6 Report
            echo "## ✅ Phase 6: 包括検証 & 配置" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ YAML構文検証: 正常" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ GitHub Actions構造検証: 正常" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ ドメイン特化包括検証: 完了" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ ワークフロー配置準備完了" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Invalid GitHub Actions structure"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
      - name: Copy Workflow to Final Location
        id: copy
        run: |
          echo "📋 Copying workflow to final location..."
          
          # Use generated workflow path
          WORKFLOW_PATH="${{ needs.generate-professional-workflow.outputs.workflow_path }}"
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          
          # Use the project directory from previous job
          PROJECT_DIR="${{ needs.generate-professional-workflow.outputs.project_dir }}"
          
          # Create project directory on this runner (it doesn't exist yet)
          mkdir -p "$PROJECT_DIR"
          
          # Copy to final location in project directory
          FINAL_DIR="${PROJECT_DIR}/final-workflow"
          mkdir -p "$FINAL_DIR"
          cp "$WORKFLOW_PATH" "$FINAL_DIR/${WORKFLOW_NAME}.yml"
          
          # Create deployment instructions
          cat > "$FINAL_DIR/DEPLOYMENT_INSTRUCTIONS.md" << EOF
          # Workflow Deployment Instructions
          
          ## Generated Workflow
          - **Name**: ${WORKFLOW_NAME}
          - **File**: ${WORKFLOW_NAME}.yml
          - **Domain**: ${{ needs.validate-and-detect.outputs.primary_domain }}
          - **Issue**: #${{ needs.validate-and-detect.outputs.issue_number }}
          
          ## Manual Deployment Steps
          1. Review the generated workflow file
          2. Copy to \`.github/workflows/\` directory if needed
          3. Ensure all required secrets are configured
          4. Test with \`workflow_dispatch\` trigger
          
          ## Workflow Summary
          Generated from professional domain templates with:
          - Domain-specific constraints applied
          - Optimized task dependencies
          - Professional quality standards
          EOF
          
          echo "✅ Workflow saved to: $FINAL_DIR/${WORKFLOW_NAME}.yml"
          echo "📝 Deployment instructions: $FINAL_DIR/DEPLOYMENT_INSTRUCTIONS.md"
          
          echo "location=$FINAL_DIR" >> $GITHUB_OUTPUT
          
      - name: Update Issue
        run: |
          # Use input parameter for workflow_dispatch, or job output for issue_comment
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            ISSUE_NUMBER="${{ inputs.issue_number }}"
          else
            ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          fi
          WORKFLOW_NAME="${{ needs.generate-professional-workflow.outputs.workflow_name }}"
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          
          # Get project directory from previous job
          PROJECT_DIR="${{ needs.generate-professional-workflow.outputs.project_dir }}"
          PROJECT_NAME=$(basename "$PROJECT_DIR")
          
          gh issue comment "$ISSUE_NUMBER" --body "## ✅ Professional Workflow Generated!
          
          **Workflow Name**: \`$WORKFLOW_NAME\`
          **Domain**: $DOMAIN
          **Status**: Successfully generated and validated
          
          ### 📋 Summary:
          - Applied professional domain expertise
          - Incorporated domain-specific constraints
          - Optimized task dependencies
          - Validated GitHub Actions structure
          
          ### 📁 Output Location:
          - **Project Directory**: \`projects/$PROJECT_NAME/\`
          - **Workflow File**: \`final-workflow/${WORKFLOW_NAME}.yml\`
          - **Deployment Guide**: \`final-workflow/DEPLOYMENT_INSTRUCTIONS.md\`
          
          ### 🚀 Next Steps:
          1. Download the workflow from artifacts
          2. Review the generated workflow
          3. Deploy manually to \`.github/workflows/\` if needed
          4. Configure required secrets
          5. Test with \`workflow_dispatch\`
          
          ---
          *Generated by Meta Workflow v12 with Domain Templates*"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ===========================================
  # PHASE 7: REGENERATION LOOP (IF NEEDED)
  # ===========================================
  
  regeneration-loop:
    name: "🔄 修正・再生成ループ"
    runs-on: ubuntu-latest
    needs: ['validate-and-deploy', 'validate-and-detect', 'load-domain-templates']
    if: needs.validate-and-deploy.outputs.validation_passed == 'false'
    outputs:
      regeneration_attempt: ${{ steps.attempt.outputs.regeneration_attempt }}
      regeneration_success: ${{ steps.regenerate.outputs.success }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Environment
        run: |
          npm install -g @anthropic-ai/claude-code
          pip install pyyaml
          
      - name: Download All Previous Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Record Regeneration Attempt
        id: attempt
        run: |
          echo "🔄 検証失敗による再生成を開始..."
          ATTEMPT_COUNT=1
          echo "regeneration_attempt=$ATTEMPT_COUNT" >> $GITHUB_OUTPUT
          
          echo "## 🔄 Phase 7: 修正・再生成ループ" >> $GITHUB_STEP_SUMMARY
          echo "- 🚨 初回生成の検証失敗を検出" >> $GITHUB_STEP_SUMMARY
          echo "- 🔄 自動再生成を実行中..." >> $GITHUB_STEP_SUMMARY
          
      - name: Analyze Validation Failures
        id: analyze
        run: |
          echo "🔍 検証失敗の詳細分析..."
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          
          # Extract specific failure reasons from previous validation
          npx @anthropic-ai/claude-code \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            --max-turns 8 \
            -p "検証失敗の原因を詳細分析してください:
            
          参照ファイル:
          1. projects/workflow-execution-logs/meta-workflow-construction-checklist.md (汎用失敗パターン)
          2. meta/domain-templates/$DOMAIN/checklist-*-specific.md (ドメイン特化失敗パターン)
          3. artifacts/ (前回の実行結果)
          
          分析項目:
          - どの検証項目で失敗したか
          - 失敗の根本原因
          - 修正すべき具体的なポイント
          - 再生成時の改善方針
          
          分析結果をartifacts/failure_analysis.jsonに保存してください:
          {
            \"failure_reasons\": [\"原因1\", \"原因2\"],
            \"critical_issues\": [\"重要な問題1\", \"重要な問題2\"],
            \"improvement_strategy\": \"改善戦略の詳細\",
            \"regeneration_focus\": [\"再生成で特に注意すべき点1\", \"点2\"]
          }"
          
          if [ -f "artifacts/failure_analysis.json" ]; then
            echo "✅ 失敗分析完了"
            echo "- ✅ 失敗原因の特定完了" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ 失敗分析に失敗"
          fi
          
      - name: Regenerate with Improved Strategy
        id: regenerate
        run: |
          echo "⚡ 改善戦略に基づく再生成実行..."
          DOMAIN="${{ needs.validate-and-detect.outputs.primary_domain }}"
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          
          # Create regeneration directory
          REGEN_DIR="projects/issue-$ISSUE_NUMBER-regeneration-$(date +%Y%m%d-%H%M%S)"
          mkdir -p "$REGEN_DIR/metadata"
          mkdir -p "$REGEN_DIR/logs"
          mkdir -p "$REGEN_DIR/generated-workflow"
          
          # Enhanced regeneration with failure analysis input
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            --max-turns 20 \
            -p "検証失敗を踏まえた改善版ワークフロー再生成:
            
          参照データ:
          1. artifacts/failure_analysis.json (失敗分析結果)
          2. artifacts/professional_task_decomposition.json (タスク分解)
          3. artifacts/optimized_task_order.json (最適化済み実行順序)
          4. meta/domain-templates/$DOMAIN/ (ドメイン情報)
          
          必須修正ガイドライン:
          1. projects/workflow-execution-logs/meta-workflow-construction-checklist.md (汎用パターン)
          2. meta/domain-templates/$DOMAIN/checklist-*-specific.md (ドメイン特化)
          
          重要改善ポイント:
          - 前回の検証失敗項目を全て修正
          - 直列並列パイプライン構造の確実な実装
          - URL期限切れ対策の強化
          - エラーハンドリング・リトライロジックの改善
          - ファイル検証の強化
          - プログレッシブレポート実装の改善
          
          改善されたワークフローを$REGEN_DIR/generated-workflow/に保存してください。"
          
          if [ -f "$REGEN_DIR/generated-workflow"/*.yml ]; then
            REGEN_WORKFLOW=$(ls "$REGEN_DIR/generated-workflow"/*.yml | head -1)
            echo "✅ 再生成完了: $(basename "$REGEN_WORKFLOW")"
            
            # Quick validation of regenerated workflow
            python -c "import yaml; yaml.safe_load(open('$REGEN_WORKFLOW'))"
            
            if [ $? -eq 0 ]; then
              echo "✅ 再生成ワークフローのYAML構文検証: 正常"
              echo "success=true" >> $GITHUB_OUTPUT
              
              echo "- ✅ 改善版ワークフロー再生成完了" >> $GITHUB_STEP_SUMMARY
              echo "- ✅ YAML構文検証: 正常" >> $GITHUB_STEP_SUMMARY
              echo "- 📁 保存場所: $REGEN_DIR/generated-workflow/" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ 再生成ワークフローのYAML構文エラー"
              echo "success=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "❌ ワークフロー再生成失敗"
            echo "success=false" >> $GITHUB_OUTPUT
            echo "- ❌ 再生成失敗 - 手動対応が必要" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload Regenerated Workflow
        uses: actions/upload-artifact@v4
        if: steps.regenerate.outputs.success == 'true'
        with:
          name: regenerated-workflow
          path: projects/issue-${{ needs.validate-and-detect.outputs.issue_number }}-regeneration-*
          if-no-files-found: warn

  # ===========================================
  # PHASE 8: FINAL REPORT DISPLAY
  # ===========================================
  
  display-final-report:
    name: "📊 実行完了"
    runs-on: ubuntu-latest
    needs: ['validate-and-detect', 'load-domain-templates', 'professional-task-decomposition', 'optimize-task-order', 'generate-professional-workflow', 'validate-and-deploy', 'regeneration-loop']
    if: always()
    steps:
          
      - name: Add Completion Summary
        run: |
          echo "📊 実行完了サマリーを追加中..."
          
          # 基本情報
          ISSUE_NUMBER="${{ needs.validate-and-detect.outputs.issue_number }}"
          VALIDATION_STATUS="${{ needs.validate-and-deploy.outputs.validation_passed }}"
          
          # 実行完了サマリーを追加
          echo "## 🎉 実行完了" >> $GITHUB_STEP_SUMMARY
          echo "- **完了時刻**: $(date '+%Y年%m月%d日 %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
          
          # 再生成結果の確認
          REGENERATION_SUCCESS="${{ needs.regeneration-loop.outputs.regeneration_success }}"
          REGENERATION_ATTEMPTED="${{ needs.regeneration-loop.outputs.regeneration_attempt }}"
          
          if [ "$VALIDATION_STATUS" = "true" ]; then
            echo "- **全体実行結果**: ✅ 成功（初回生成）" >> $GITHUB_STEP_SUMMARY
          elif [ "$REGENERATION_SUCCESS" = "true" ]; then
            echo "- **全体実行結果**: ✅ 成功（再生成により修正）" >> $GITHUB_STEP_SUMMARY
            echo "- **再生成実行**: ✅ 完了（検証失敗を自動修正）" >> $GITHUB_STEP_SUMMARY
          elif [ "$REGENERATION_ATTEMPTED" = "1" ]; then
            echo "- **全体実行結果**: ❌ 失敗（再生成でも修正不可）" >> $GITHUB_STEP_SUMMARY
            echo "- **再生成実行**: ❌ 失敗（手動対応が必要）" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **全体実行結果**: ⚠️ 一部エラーあり" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # ダウンロード情報
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## 📥 成果物のダウンロード
          
          ローカルで以下のコマンドを実行してください：
          
          \`\`\`bash
          # すべての成果物をダウンロード
          gh run download ${{ github.run_id }}
          
          # 特定の成果物のみダウンロード
          gh run download ${{ github.run_id }} -n generated-workflow
          EOF
          
          # 再生成された場合の追加情報
          if [ "$REGENERATION_SUCCESS" = "true" ]; then
            cat >> $GITHUB_STEP_SUMMARY << EOF
          
          # 再生成版ワークフローもダウンロード（推奨）
          gh run download ${{ github.run_id }} -n regenerated-workflow
          EOF
          fi
          
          cat >> $GITHUB_STEP_SUMMARY << EOF
          \`\`\`
          EOF
