---
name: Advanced Story Video Audio Pipeline
run-name: ${{ github.actor }} creates complete story content 🎬🎵🎙️

on:
  workflow_dispatch:
    inputs:
      story_concept:
        description: 'ストーリーのコンセプト・テーマ'
        required: true
        type: string
        default: '冒険の物語'
      narrative_style:
        description: 'ナラティブスタイル'
        required: false
        type: choice
        options:
          - documentary
          - storytelling
          - dramatic
        default: storytelling
      visual_style:
        description: '映像スタイル'
        required: false
        type: choice
        options:
          - photorealistic
          - anime
          - illustration
          - cinematic
        default: cinematic
      music_genre:
        description: 'BGMジャンル'
        required: false
        type: choice
        options:
          - orchestral
          - ambient
          - electronic
          - acoustic
        default: orchestral
      voice_character:
        description: 'ナレーター音声キャラクター'
        required: false
        type: choice
        options:
          - professional_male
          - professional_female
          - warm_narrator
          - authoritative
        default: warm_narrator
      output_quality:
        description: '出力品質'
        required: false
        type: choice
        options:
          - draft
          - standard
          - high
          - ultra
        default: high

permissions:
  contents: write
  actions: read

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

jobs:
  # Phase 1: ストーリー構想・企画
  story-planning:
    runs-on: ubuntu-latest
    outputs:
      story_outline: ${{ steps.planning.outputs.story_outline }}
      scene_count: ${{ steps.planning.outputs.scene_count }}
      narrative_text: ${{ steps.planning.outputs.narrative_text }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Story Planning & Outline Creation
        id: planning
        run: |
          echo "📝 Creating detailed story plan..."
          
          mkdir -p outputs/{planning,images,videos,audio,final}
          
          # ストーリー企画の詳細化
          STORY_CONCEPT="${{ github.event.inputs.story_concept }}"
          NARRATIVE_STYLE="${{ github.event.inputs.narrative_style }}"
          
          echo "Story Concept: $STORY_CONCEPT"
          echo "Narrative Style: $NARRATIVE_STYLE"
          
          # ストーリーアウトライン生成
          cat > outputs/planning/story-outline.md << EOF
          # Story Outline: $STORY_CONCEPT
          
          ## Narrative Style: $NARRATIVE_STYLE
          
          ### Scene 1: Introduction
          - Setting establishment
          - Character introduction
          - Theme presentation
          
          ### Scene 2: Development
          - Conflict introduction
          - Character development
          - Tension building
          
          ### Scene 3: Climax
          - Peak moment
          - Resolution approach
          - Emotional culmination
          
          ### Scene 4: Resolution
          - Conflict resolution
          - Character conclusion
          - Theme reinforcement
          
          ## Technical Requirements
          - Visual Style: ${{ github.event.inputs.visual_style }}
          - Music Genre: ${{ github.event.inputs.music_genre }}
          - Voice Character: ${{ github.event.inputs.voice_character }}
          - Quality: ${{ github.event.inputs.output_quality }}
          EOF
          
          # ナラティブテキスト準備
          NARRATIVE_TEXT="The story of $STORY_CONCEPT unfolds through four distinct scenes, each building upon the previous to create a compelling $NARRATIVE_STYLE experience."
          
          echo "story_outline=outputs/planning/story-outline.md" >> $GITHUB_OUTPUT
          echo "scene_count=4" >> $GITHUB_OUTPUT
          echo "narrative_text=$NARRATIVE_TEXT" >> $GITHUB_OUTPUT
          
          echo "✅ Story planning completed"

  # Phase 2: 並列画像生成 (T2I)
  generate-scene-images:
    needs: story-planning
    runs-on: ubuntu-latest
    strategy:
      matrix:
        scene: [1, 2, 3, 4]
    outputs:
      image_paths: ${{ steps.t2i.outputs.image_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download Story Plan
        run: |
          mkdir -p outputs/planning
          # In real implementation, would download from artifacts
          echo "Downloaded story plan for scene ${{ matrix.scene }}"
        
      - name: Generate Scene Image (T2I)
        id: t2i
        run: |
          echo "🎨 Generating image for Scene ${{ matrix.scene }}..."
          
          SCENE_NUM="${{ matrix.scene }}"
          VISUAL_STYLE="${{ github.event.inputs.visual_style }}"
          STORY_CONCEPT="${{ github.event.inputs.story_concept }}"
          
          mkdir -p outputs/images
          
          # T2I プロンプト構成
          case $SCENE_NUM in
            1) SCENE_PROMPT="Introduction scene of $STORY_CONCEPT, $VISUAL_STYLE style, establishing shot";;
            2) SCENE_PROMPT="Development scene of $STORY_CONCEPT, $VISUAL_STYLE style, character focus";;
            3) SCENE_PROMPT="Climax scene of $STORY_CONCEPT, $VISUAL_STYLE style, dramatic moment";;
            4) SCENE_PROMPT="Resolution scene of $STORY_CONCEPT, $VISUAL_STYLE style, peaceful conclusion";;
          esac
          
          echo "T2I Prompt: $SCENE_PROMPT"
          
          # MCP T2I サービス実行 (シミュレーション)
          # 実際の実装では claude-code --mcp t2i-google-imagen3 等を使用
          IMAGE_PATH="outputs/images/scene-${SCENE_NUM}-$(date +%Y%m%d-%H%M%S).png"
          
          echo "📸 Scene $SCENE_NUM image generated: $IMAGE_PATH"
          echo "image_path=$IMAGE_PATH" >> $GITHUB_OUTPUT
          
          # メタデータ保存
          cat > "${IMAGE_PATH}.metadata.json" << EOF
          {
            "scene_number": $SCENE_NUM,
            "prompt": "$SCENE_PROMPT",
            "style": "$VISUAL_STYLE",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "mcp_service": "t2i-google-imagen3"
          }
          EOF

  # Phase 3: 画像統合・動画生成 (I2V)
  generate-story-video:
    needs: [story-planning, generate-scene-images]
    runs-on: ubuntu-latest
    outputs:
      video_path: ${{ steps.i2v.outputs.video_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Collect Scene Images
        run: |
          echo "📁 Collecting all scene images..."
          mkdir -p outputs/images outputs/videos
          
          # 実際の実装では前のジョブからartifactsをダウンロード
          echo "Collected images from all scenes"
        
      - name: Generate Story Video (I2V)
        id: i2v
        run: |
          echo "🎬 Creating story video from scene images..."
          
          STORY_CONCEPT="${{ github.event.inputs.story_concept }}"
          OUTPUT_QUALITY="${{ github.event.inputs.output_quality }}"
          
          VIDEO_PATH="outputs/videos/story-video-$(date +%Y%m%d-%H%M%S).mp4"
          
          echo "Creating video sequence..."
          echo "- Scene 1: Introduction"
          echo "- Scene 2: Development" 
          echo "- Scene 3: Climax"
          echo "- Scene 4: Resolution"
          
          # MCP I2V サービス実行 (シミュレーション)
          # 実際の実装では claude-code --mcp i2v-fal-hailuo-02-pro 等を使用
          
          echo "🎥 Story video generated: $VIDEO_PATH"
          echo "video_path=$VIDEO_PATH" >> $GITHUB_OUTPUT
          
          # メタデータ保存
          cat > "${VIDEO_PATH}.metadata.json" << EOF
          {
            "story_concept": "$STORY_CONCEPT",
            "scene_count": 4,
            "quality": "$OUTPUT_QUALITY",
            "duration_estimate": "60-90 seconds",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "mcp_service": "i2v-fal-hailuo-02-pro"
          }
          EOF

  # Phase 4: BGM生成 (T2M)
  generate-background-music:
    needs: story-planning
    runs-on: ubuntu-latest
    outputs:
      bgm_path: ${{ steps.t2m.outputs.bgm_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Generate Background Music (T2M)
        id: t2m
        run: |
          echo "🎵 Generating background music..."
          
          STORY_CONCEPT="${{ github.event.inputs.story_concept }}"
          MUSIC_GENRE="${{ github.event.inputs.music_genre }}"
          NARRATIVE_STYLE="${{ github.event.inputs.narrative_style }}"
          
          mkdir -p outputs/audio
          
          # T2M プロンプト構成
          MUSIC_PROMPT="$MUSIC_GENRE background music for $STORY_CONCEPT story, $NARRATIVE_STYLE mood, 60-90 seconds duration"
          
          echo "T2M Prompt: $MUSIC_PROMPT"
          
          BGM_PATH="outputs/audio/bgm-$(date +%Y%m%d-%H%M%S).mp3"
          
          # MCP T2M サービス実行 (シミュレーション)
          # 実際の実装では claude-code --mcp t2m-google-lyria 等を使用
          
          echo "🎶 Background music generated: $BGM_PATH"
          echo "bgm_path=$BGM_PATH" >> $GITHUB_OUTPUT
          
          # メタデータ保存
          cat > "${BGM_PATH}.metadata.json" << EOF
          {
            "prompt": "$MUSIC_PROMPT",
            "genre": "$MUSIC_GENRE",
            "mood": "$NARRATIVE_STYLE",
            "duration": "60-90 seconds",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "mcp_service": "t2m-google-lyria"
          }
          EOF

  # Phase 5: ナレーション生成 (T2A)
  generate-narration:
    needs: story-planning
    runs-on: ubuntu-latest
    outputs:
      narration_path: ${{ steps.t2a.outputs.narration_path }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Generate Narration (T2A)
        id: t2a
        run: |
          echo "🎙️ Generating narration audio..."
          
          NARRATIVE_TEXT="${{ needs.story-planning.outputs.narrative_text }}"
          VOICE_CHARACTER="${{ github.event.inputs.voice_character }}"
          STORY_CONCEPT="${{ github.event.inputs.story_concept }}"
          
          mkdir -p outputs/audio
          
          echo "Narration Text: $NARRATIVE_TEXT"
          echo "Voice Character: $VOICE_CHARACTER"
          
          NARRATION_PATH="outputs/audio/narration-$(date +%Y%m%d-%H%M%S).mp3"
          
          # MCP T2A サービス実行 (シミュレーション)
          # 実際の実装では claude-code --mcp v2a-fal-metavoice-v1 等を使用
          
          echo "🗣️ Narration generated: $NARRATION_PATH"
          echo "narration_path=$NARRATION_PATH" >> $GITHUB_OUTPUT
          
          # メタデータ保存
          cat > "${NARRATION_PATH}.metadata.json" << EOF
          {
            "text": "$NARRATIVE_TEXT",
            "voice_character": "$VOICE_CHARACTER",
            "story_concept": "$STORY_CONCEPT",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "mcp_service": "v2a-fal-metavoice-v1"
          }
          EOF

  # Phase 6: 最終統合・出力
  final-integration:
    needs: [story-planning, generate-story-video, generate-background-music, generate-narration]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Download All Components
        run: |
          echo "📥 Downloading all generated components..."
          mkdir -p outputs/{videos,audio,final}
          
          # 実際の実装では各ジョブからartifactsをダウンロード
          echo "Downloaded: Video, BGM, Narration"
        
      - name: Final Audio-Video Integration
        run: |
          echo "🎭 Integrating video, BGM, and narration..."
          
          VIDEO_PATH="${{ needs.generate-story-video.outputs.video_path }}"
          BGM_PATH="${{ needs.generate-background-music.outputs.bgm_path }}"
          NARRATION_PATH="${{ needs.generate-narration.outputs.narration_path }}"
          STORY_CONCEPT="${{ github.event.inputs.story_concept }}"
          
          echo "Integrating components:"
          echo "- Video: $VIDEO_PATH"
          echo "- BGM: $BGM_PATH"
          echo "- Narration: $NARRATION_PATH"
          
          FINAL_OUTPUT="outputs/final/complete-story-$(date +%Y%m%d-%H%M%S).mp4"
          
          # 音声・映像統合処理 (シミュレーション)
          # 実際の実装では ffmpeg 等を使用
          echo "🎬 Audio-video integration processing..."
          echo "- Mixing BGM at 30% volume"
          echo "- Overlaying narration at 70% volume"
          echo "- Synchronizing with video timeline"
          
          echo "✅ Final story content created: $FINAL_OUTPUT"
          
          # 最終メタデータ
          cat > "${FINAL_OUTPUT}.metadata.json" << EOF
          {
            "story_concept": "$STORY_CONCEPT",
            "components": {
              "video": "$VIDEO_PATH",
              "bgm": "$BGM_PATH", 
              "narration": "$NARRATION_PATH"
            },
            "settings": {
              "visual_style": "${{ github.event.inputs.visual_style }}",
              "music_genre": "${{ github.event.inputs.music_genre }}",
              "voice_character": "${{ github.event.inputs.voice_character }}",
              "quality": "${{ github.event.inputs.output_quality }}"
            },
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "total_processing_time": "estimated 5-8 minutes"
          }
          EOF
        
      - name: Upload Final Story Content
        uses: actions/upload-artifact@v4
        with:
          name: complete-story-content-${{ github.run_number }}
          path: outputs/
          retention-days: 30
          
      - name: Generate Summary Report
        run: |
          echo "📋 Generating completion summary..."
          
          cat > outputs/final/completion-report.md << EOF
          # Story Creation Completion Report
          
          ## Story Details
          - **Concept**: ${{ github.event.inputs.story_concept }}
          - **Style**: ${{ github.event.inputs.narrative_style }}
          - **Quality**: ${{ github.event.inputs.output_quality }}
          
          ## Generated Components
          - ✅ **Story Planning**: 4-scene narrative structure
          - ✅ **Scene Images**: 4 visual scenes (T2I)
          - ✅ **Story Video**: Integrated video sequence (I2V)
          - ✅ **Background Music**: ${{ github.event.inputs.music_genre }} soundtrack (T2M)
          - ✅ **Narration**: ${{ github.event.inputs.voice_character }} voice (T2A)
          - ✅ **Final Integration**: Complete audio-video content
          
          ## Technical Process
          1. **Phase 1**: Story planning & scene breakdown
          2. **Phase 2**: Parallel scene image generation (4 scenes)
          3. **Phase 3**: Video sequence creation
          4. **Phase 4**: Background music composition
          5. **Phase 5**: Narration voice generation
          6. **Phase 6**: Final audio-video integration
          
          ## Output Files
          - Complete story video with integrated audio
          - Individual component files
          - Metadata for each generation step
          - Processing logs and reports
          
          ## Usage Instructions
          1. Download the artifact: \`complete-story-content-${{ github.run_number }}\`
          2. Extract to your local machine
          3. Find final video in \`outputs/final/\` directory
          4. Review component files in respective subdirectories
          
          ---
          Generated by Advanced Story Video Audio Pipeline
          Execution Date: $(date -u +%Y-%m-%d\ %H:%M:%S\ UTC)
          Workflow Run: ${{ github.run_number }}
          EOF
          
          echo "🎯 Story creation pipeline completed successfully!"