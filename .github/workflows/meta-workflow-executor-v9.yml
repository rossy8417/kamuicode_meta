name: Meta Workflow Executor v9
run-name: ðŸš€ Dynamic minimal-unit based workflow for Issue #${{ github.event.issue.number || inputs.issue_number }}

on:
  issue_comment:
    types: [created]
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number to process'
        required: true
        default: '46'

permissions:
  contents: write
  issues: write
  actions: read
  pull-requests: write

env:
  CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true

jobs:
  # Phase 1: Trigger Validation & Answer Extraction
  validate-trigger:
    runs-on: ubuntu-latest
    if: github.event_name != 'push' && (github.event_name == 'workflow_dispatch' || contains(github.event.comment.body, 'start'))
    outputs:
      should_execute: ${{ steps.validate.outputs.should_execute }}
      issue_number: ${{ steps.validate.outputs.issue_number }}
    
    steps:
      - name: Validate Trigger
        id: validate
        run: |
          echo "ðŸ” Validating trigger conditions..."
          
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "âœ… Manual trigger via workflow_dispatch"
            echo "should_execute=true" >> $GITHUB_OUTPUT
            echo "issue_number=${{ inputs.issue_number }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" = "issue_comment" ]; then
            COMMENT_USER="${{ github.event.comment.user.login }}"
            ISSUE_AUTHOR="${{ github.event.issue.user.login }}"
            COMMENT_BODY="${{ github.event.comment.body }}"
            
            if [ "$COMMENT_USER" = "$ISSUE_AUTHOR" ] && echo "$COMMENT_BODY" | grep -q '^start'; then
              echo "âœ… Valid start trigger from issue author"
              echo "should_execute=true" >> $GITHUB_OUTPUT
              echo "issue_number=${{ github.event.issue.number }}" >> $GITHUB_OUTPUT
            else
              echo "âŒ Invalid trigger"
              echo "should_execute=false" >> $GITHUB_OUTPUT
            fi
          fi

  extract-requirements:
    needs: validate-trigger
    runs-on: ubuntu-latest
    if: needs.validate-trigger.outputs.should_execute == 'true'
    outputs:
      user_request: ${{ steps.extract.outputs.user_request }}
      workflow_type: ${{ steps.extract.outputs.workflow_type }}
      stepback_answers: ${{ steps.extract.outputs.stepback_answers }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Extract Requirements from Issue
        id: extract
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          ISSUE_NUMBER="${{ needs.validate-trigger.outputs.issue_number }}"
          echo "ðŸ“ Extracting requirements from Issue #$ISSUE_NUMBER..."
          
          mkdir -p generated/metadata/requirements
          
          # Get issue body
          gh api repos/${{ github.repository }}/issues/$ISSUE_NUMBER \
            --jq '.body' > generated/metadata/requirements/issue-body.txt
          
          ISSUE_BODY=$(cat generated/metadata/requirements/issue-body.txt)
          
          # Extract workflow type
          WORKFLOW_TYPE="custom"
          if echo "$ISSUE_BODY" | grep -q "å‹•ç”».*ç”Ÿæˆ\|video.*generation"; then
            WORKFLOW_TYPE="video-generation"
          elif echo "$ISSUE_BODY" | grep -q "ç”»åƒ.*ç”Ÿæˆ\|image.*generation"; then
            WORKFLOW_TYPE="image-generation"
          elif echo "$ISSUE_BODY" | grep -q "3[Dd].*ãƒ¢ãƒ‡ãƒ«"; then
            WORKFLOW_TYPE="3d-model"
          elif echo "$ISSUE_BODY" | grep -q "éŸ³æ¥½\|BGM\|music"; then
            WORKFLOW_TYPE="audio-generation"
          fi
          
          # Extract stepback answers
          STEPBACK_ANSWERS=$(echo "$ISSUE_BODY" | grep -E "Q[1-5].*å›žç­”ï¼š|å›žç­”ï¼š" -A 5 | head -30)
          
          # Extract user request (first section before Q1)
          USER_REQUEST=$(echo "$ISSUE_BODY" | sed -n '1,/Q1/p' | head -20)
          
          echo "workflow_type=$WORKFLOW_TYPE" >> $GITHUB_OUTPUT
          echo "user_request<<EOF" >> $GITHUB_OUTPUT
          echo "$USER_REQUEST" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "stepback_answers<<EOF" >> $GITHUB_OUTPUT
          echo "$STEPBACK_ANSWERS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
      - name: Upload Requirements
        uses: actions/upload-artifact@v4
        with:
          name: requirements-metadata
          path: generated/metadata/requirements/
          retention-days: 1

  # Phase 2: Ultra-Detailed Task Decomposition with Claude Code SDK
  decompose-tasks:
    needs: extract-requirements
    runs-on: ubuntu-latest
    outputs:
      task_plan: ${{ steps.decompose.outputs.task_plan }}
      task_count: ${{ steps.decompose.outputs.task_count }}
      parallel_groups: ${{ steps.decompose.outputs.parallel_groups }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Install Claude Code SDK
        run: |
          npm init -y
          npm install @anthropic-ai/claude-code
          
      - name: Ultra-Detailed Task Decomposition
        id: decompose
        run: |
          echo "ðŸ§  Performing ultra-detailed task decomposition..."
          
          mkdir -p generated/metadata/task-decomposition
          
          # Create ultra-detailed decomposition prompt
          cat > generated/metadata/task-decomposition/decompose-prompt.md << 'EOF'
          # Ultra-Detailed Task Decomposition Request
          
          Based on the following user request, perform an ULTRA-DETAILED task decomposition that mimics human unconscious thought processes:
          
          ## User Request
          ${{ needs.extract-requirements.outputs.user_request }}
          
          ## Stepback Answers
          ${{ needs.extract-requirements.outputs.stepback_answers }}
          
          ## Workflow Type
          ${{ needs.extract-requirements.outputs.workflow_type }}
          
          ## Decomposition Requirements
          
          ### 1. Think Like a Human
          Decompose tasks as a human would naturally think about them, including:
          - Preparation tasks (checking requirements, setting up environment)
          - Research tasks (looking for references, examples)
          - Planning tasks (organizing approach, creating outlines)
          - Main execution tasks
          - Quality check tasks
          - Refinement tasks
          - Documentation tasks
          
          ### 2. Ultra-Fine Granularity
          Break down each major task into 3-7 subtasks. For example:
          - "Generate image" should become:
            - "Research visual style references"
            - "Draft initial prompt"
            - "Optimize prompt for model"
            - "Generate test image"
            - "Evaluate quality"
            - "Refine and regenerate"
            - "Select best version"
          
          ### 3. Parallel Processing Optimization
          Identify opportunities for:
          - 3-way parallel (common for independent generation tasks)
          - 4-way parallel (for multiple variations)
          - 5-way parallel (for comprehensive coverage)
          - Sequential dependencies where necessary
          
          ### 4. Human-like Workflow Patterns
          Include natural human behaviors:
          - Iterative refinement cycles
          - Quality checks after each major step
          - Alternative approaches for fallback
          - Documentation and note-taking
          - Progress tracking
          
          ### 5. Comprehensive Coverage
          Ensure the decomposition covers:
          - Pre-processing (20-30% of tasks)
          - Main processing (40-50% of tasks)
          - Post-processing (20-30% of tasks)
          - Quality assurance (10% of tasks)
          
          Output as JSON in generated/metadata/task-decomposition/task-plan.json with structure:
          ```json
          {
            "tasks": [
              {
                "id": "task-001",
                "name": "Research Visual References",
                "type": "research",
                "description": "Search for visual style references and examples",
                "subtasks": ["web search", "style analysis", "reference collection"],
                "dependencies": [],
                "parallel_group": 1,
                "estimated_duration": "3-5 minutes",
                "required_units": ["web-search", "image-analysis"],
                "human_behavior": "natural exploration phase"
              }
            ],
            "parallel_groups": {
              "1": ["task-001", "task-002", "task-003"],
              "2": ["task-004", "task-005"],
              "3": ["task-006", "task-007", "task-008", "task-009"]
            },
            "total_estimated_duration": "45-60 minutes",
            "optimization_notes": "3-way parallel for research, 4-way for generation"
          }
          ```
          EOF
          
          # Execute Claude Code with extended context
          npx @anthropic-ai/claude-code \
            -f generated/metadata/task-decomposition/decompose-prompt.md \
            --allowedTools "Write,Read" \
            --permission-mode "acceptEdits" \
            --max-tokens 8000 || {
              # Enhanced fallback plan
              echo '{
                "tasks":[
                  {"id":"task-001","name":"Initial Planning","type":"planning","parallel_group":1},
                  {"id":"task-002","name":"Resource Gathering","type":"research","parallel_group":1},
                  {"id":"task-003","name":"Style Analysis","type":"analysis","parallel_group":1},
                  {"id":"task-004","name":"Main Generation","type":"generation","parallel_group":2,"dependencies":["task-001","task-002","task-003"]},
                  {"id":"task-005","name":"Quality Check","type":"validation","parallel_group":3,"dependencies":["task-004"]},
                  {"id":"task-006","name":"Refinement","type":"processing","parallel_group":4,"dependencies":["task-005"]}
                ],
                "parallel_groups":{
                  "1":["task-001","task-002","task-003"],
                  "2":["task-004"],
                  "3":["task-005"],
                  "4":["task-006"]
                },
                "total_estimated_duration":"30-45 minutes"
              }' > generated/metadata/task-decomposition/task-plan.json
            }
          
          # Extract metrics
          TASK_COUNT=$(jq '.tasks | length' generated/metadata/task-decomposition/task-plan.json || echo "6")
          PARALLEL_GROUPS=$(jq -c '.parallel_groups' generated/metadata/task-decomposition/task-plan.json || echo '{}')
          
          echo "task_count=$TASK_COUNT" >> $GITHUB_OUTPUT
          echo "task_plan=generated/metadata/task-decomposition/task-plan.json" >> $GITHUB_OUTPUT
          echo "parallel_groups=$PARALLEL_GROUPS" >> $GITHUB_OUTPUT
          
          # Display decomposition summary
          echo "ðŸ“Š Task Decomposition Summary:"
          echo "- Total tasks: $TASK_COUNT"
          echo "- Parallel groups: $(echo $PARALLEL_GROUPS | jq 'keys | length')"
          echo "- Estimated duration: $(jq -r '.total_estimated_duration' generated/metadata/task-decomposition/task-plan.json)"
          
      - name: Upload Task Plan
        uses: actions/upload-artifact@v4
        with:
          name: task-decomposition
          path: generated/metadata/task-decomposition/
          retention-days: 1

  # Phase 3: Select Minimal Units from All 55 Available Units
  select-minimal-units:
    needs: [extract-requirements, decompose-tasks]
    runs-on: ubuntu-latest
    outputs:
      selected_units: ${{ steps.select.outputs.selected_units }}
      unit_count: ${{ steps.select.outputs.unit_count }}
      parallel_optimization: ${{ steps.select.outputs.parallel_optimization }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Install Dependencies
        run: |
          npm init -y
          npm install @anthropic-ai/claude-code js-yaml
          
      - name: Download Task Plan
        uses: actions/download-artifact@v4
        with:
          name: task-decomposition
          path: generated/metadata/task-decomposition/
          
      - name: Select Minimal Units with Full Catalog
        id: select
        run: |
          echo "ðŸ§© Selecting from all 55 minimal units..."
          
          mkdir -p generated/metadata/unit-selection
          
          # Create comprehensive unit catalog with metadata
          cat > generated/metadata/unit-selection/unit-catalog.md << 'EOF'
          # Complete Minimal Units Catalog (55 Units)
          
          ## ðŸŽ¨ Image Generation & Processing (8 units)
          - t2i-imagen3: Google Imagen3ã«ã‚ˆã‚‹é«˜å“è³ªç”»åƒç”Ÿæˆ
          - image-t2i: æ±Žç”¨Text-to-Imageï¼ˆè¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰
          - t2i-sdxl: Stable Diffusion XLã«ã‚ˆã‚‹ç”»åƒç”Ÿæˆ
          - i2i-flux-kontext: Flux Kontextã«ã‚ˆã‚‹ç”»åƒå¤‰æ›
          - image-analysis: ç”»åƒå†…å®¹ã®åˆ†æž
          - banner-text: ãƒãƒŠãƒ¼ç”»åƒã«ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ 
          - banner-planning: ãƒãƒŠãƒ¼ä¼ç”»ç«‹æ¡ˆ
          - title-composition: ã‚¿ã‚¤ãƒˆãƒ«ç”»åƒåˆæˆ
          
          ## ðŸŽ¬ Video Generation & Processing (13 units)
          - video-generation: æ±Žç”¨å‹•ç”»ç”Ÿæˆï¼ˆi2v/t2vå¯¾å¿œï¼‰
          - t2v-veo3: Google Veo3ã«ã‚ˆã‚‹Text-to-Video
          - t2v-wan: Wan V2ã«ã‚ˆã‚‹Text-to-Video
          - i2v-seedance: SeeDanceã«ã‚ˆã‚‹Image-to-Video
          - r2v-vidu: Reference-to-Videoç”Ÿæˆ
          - v2v-luma-ray2: Luma Ray2ã«ã‚ˆã‚‹å‹•ç”»å¤‰æ›
          - v2v-creatify: Creatifyã«ã‚ˆã‚‹å‹•ç”»ç·¨é›†
          - video-concat: è¤‡æ•°å‹•ç”»ã®çµåˆ
          - upscale-topaz: Topazã«ã‚ˆã‚‹å‹•ç”»ã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒ«
          - video-analysis: å‹•ç”»å†…å®¹ã®åˆ†æž
          - video-prompt-opt: å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–
          - lipsync-pixverse: Pixverseãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯
          - pixverse-quota-guard: Pixverseã‚¯ã‚©ãƒ¼ã‚¿ç®¡ç†
          
          ## ðŸŽµ Audio Generation & Processing (10 units)
          - bgm-generate: BGMç”Ÿæˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆï¼‰
          - bgm-generate-mcp: BGMç”Ÿæˆï¼ˆMCPç‰ˆï¼‰
          - t2s-google: Google Text-to-Speech
          - t2s-minimax-turbo: MiniMax Turbo TTS
          - t2s-minimax-voice: MiniMax Voice Design
          - t2s-openai: OpenAI Text-to-Speech
          - audio-elevenlabs: ElevenLabséŸ³å£°ç”Ÿæˆ
          - audio-minimax: MiniMaxéŸ³å£°ç”Ÿæˆ
          - bgm-overlay: BGMã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
          - wav-segmentation: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²
          
          ## ðŸ‘„ Subtitles & Sync (5 units)
          - srt-make: SRTãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
          - srt-sync: SRTåŒæœŸèª¿æ•´
          - srt-translate: SRTç¿»è¨³
          - subtitle-overlay: å­—å¹•ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
          - lipsync-pixverse: (ä¸Šè¨˜Videoå‡¦ç†ã§ã‚«ã‚¦ãƒ³ãƒˆæ¸ˆã¿)
          
          ## ðŸ“‹ Planning & Analysis (9 units)
          - planning-ccsdk: Claude Code SDKã«ã‚ˆã‚‹ä¼ç”»
          - web-search: Webæ¤œç´¢ã«ã‚ˆã‚‹æƒ…å ±åŽé›†
          - article-generation: è¨˜äº‹ç”Ÿæˆ
          - markdown-summary: Markdownã‚µãƒžãƒªãƒ¼ç”Ÿæˆ
          - data-analysis: ãƒ‡ãƒ¼ã‚¿åˆ†æž
          - data-visualization: ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
          - news-planning: ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¼ç”»
          - news-summary: ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„
          - slide-generation: ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
          
          ## ðŸ“° Content Creation (3 units)
          - blog-generation: ãƒ–ãƒ­ã‚°è¨˜äº‹ç”Ÿæˆ
          - (newsç³»ã¯ä¸Šè¨˜ã§ã‚«ã‚¦ãƒ³ãƒˆæ¸ˆã¿)
          - (banner-planningã¯ä¸Šè¨˜ã§ã‚«ã‚¦ãƒ³ãƒˆæ¸ˆã¿)
          
          ## ðŸ› ï¸ Utility & Integration (7 units)
          - local-save: ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜
          - fal-upload: FALã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
          - git-branch-setup: Gitãƒ–ãƒ©ãƒ³ãƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
          - git-pr-create: ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
          - cleanup-branch: ãƒ–ãƒ©ãƒ³ãƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
          - pdf-create: PDFä½œæˆ
          - sns-publish: SNSæŠ•ç¨¿
          
          ## ðŸŽ­ 3D Generation (1 unit)
          - i2i3d-hunyuan: Hunyuanã«ã‚ˆã‚‹Image-to-3D
          
          Total: 55 units available for selection
          EOF
          
          # Create enhanced selection prompt
          cat > generated/metadata/unit-selection/select-prompt.md << 'EOF'
          # Comprehensive Minimal Unit Selection
          
          Select minimal units from the complete catalog to implement the task plan:
          
          ## Task Plan
          $(cat generated/metadata/task-decomposition/task-plan.json)
          
          ## Available Units (55 total)
          $(cat generated/metadata/unit-selection/unit-catalog.md)
          
          ## Selection Strategy
          
          ### 1. Comprehensive Coverage
          - Ensure ALL required functionality is covered
          - Select multiple units for complex tasks
          - Include preparation, execution, and validation units
          
          ### 2. Parallel Optimization
          - Identify 3-way parallel opportunities (e.g., multiple image generations)
          - Identify 4-way parallel opportunities (e.g., variations generation)
          - Identify 5-way parallel opportunities (e.g., comprehensive analysis)
          - Balance parallel execution with dependencies
          
          ### 3. Human-like Selection
          - Include units for research and planning phases
          - Add quality check and validation units
          - Include refinement and optimization units
          - Add documentation and summary units
          
          ### 4. Unit Mapping Guidelines
          For each task in the plan:
          - Map primary functionality to core units
          - Add supporting units for pre/post processing
          - Include validation and quality units
          - Consider fallback and alternative units
          
          Output as JSON in generated/metadata/unit-selection/selected-units.json:
          ```json
          {
            "selected_units": [
              {
                "task_id": "task-001",
                "unit_name": "planning-ccsdk",
                "unit_path": "minimal-units/planning/planning-ccsdk.yml",
                "purpose": "Initial project planning and structure",
                "inputs": {
                  "prompt": "Generated from user requirements"
                },
                "dependencies": [],
                "parallel_group": 1,
                "execution_order": 1
              }
            ],
            "parallel_optimization": {
              "strategy": "4-way parallel for main generation, 3-way for analysis",
              "groups": {
                "1": {"units": 3, "type": "research"},
                "2": {"units": 4, "type": "generation"},
                "3": {"units": 2, "type": "validation"}
              }
            },
            "unit_statistics": {
              "total_selected": 25,
              "by_category": {
                "planning": 5,
                "image": 6,
                "video": 8,
                "audio": 4,
                "utility": 2
              }
            }
          }
          ```
          EOF
          
          # Execute comprehensive selection
          npx @anthropic-ai/claude-code \
            -f generated/metadata/unit-selection/select-prompt.md \
            --allowedTools "Read,Write" \
            --permission-mode "acceptEdits" \
            --max-tokens 8000 || {
              # Enhanced fallback with multiple units
              echo '{
                "selected_units":[
                  {"task_id":"task-001","unit_name":"planning-ccsdk","unit_path":"minimal-units/planning/planning-ccsdk.yml","parallel_group":1},
                  {"task_id":"task-002","unit_name":"web-search","unit_path":"minimal-units/planning/web-search.yml","parallel_group":1},
                  {"task_id":"task-003","unit_name":"image-analysis","unit_path":"minimal-units/image/image-analysis.yml","parallel_group":1},
                  {"task_id":"task-004","unit_name":"t2i-imagen3","unit_path":"minimal-units/image/t2i-imagen3.yml","parallel_group":2},
                  {"task_id":"task-005","unit_name":"video-generation","unit_path":"minimal-units/video/video-generation.yml","parallel_group":3}
                ],
                "parallel_optimization":{
                  "strategy":"3-way parallel for initial phase",
                  "groups":{"1":{"units":3,"type":"planning"},"2":{"units":1,"type":"generation"},"3":{"units":1,"type":"processing"}}
                },
                "unit_statistics":{"total_selected":5,"by_category":{"planning":2,"image":2,"video":1}}
              }' > generated/metadata/unit-selection/selected-units.json
            }
          
          # Extract metrics
          UNIT_COUNT=$(jq '.selected_units | length' generated/metadata/unit-selection/selected-units.json || echo "5")
          PARALLEL_OPT=$(jq -c '.parallel_optimization' generated/metadata/unit-selection/selected-units.json || echo '{}')
          
          echo "unit_count=$UNIT_COUNT" >> $GITHUB_OUTPUT
          echo "selected_units=generated/metadata/unit-selection/selected-units.json" >> $GITHUB_OUTPUT
          echo "parallel_optimization=$PARALLEL_OPT" >> $GITHUB_OUTPUT
          
          # Display selection summary
          echo "ðŸ“Š Unit Selection Summary:"
          echo "- Total units selected: $UNIT_COUNT"
          echo "- Parallel optimization: $(echo $PARALLEL_OPT | jq -r '.strategy')"
          echo "- Categories covered: $(jq -r '.unit_statistics.by_category | keys | join(", ")' generated/metadata/unit-selection/selected-units.json)"
          
      - name: Upload Unit Selection
        uses: actions/upload-artifact@v4
        with:
          name: unit-selection
          path: generated/metadata/unit-selection/
          retention-days: 1

  # Phase 4: Compose Human-like Dynamic Workflow
  compose-workflow:
    needs: [extract-requirements, select-minimal-units, decompose-tasks]
    runs-on: ubuntu-latest
    outputs:
      workflow_path: ${{ steps.compose.outputs.workflow_path }}
      workflow_ready: ${{ steps.compose.outputs.workflow_ready }}
      workflow_complexity: ${{ steps.compose.outputs.workflow_complexity }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Install Dependencies
        run: |
          npm init -y
          npm install @anthropic-ai/claude-code js-yaml
          
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: generated/metadata/
          
      - name: Compose Human-like Dynamic Workflow
        id: compose
        run: |
          echo "ðŸ”§ Composing human-like dynamic workflow with optimal parallelization..."
          
          mkdir -p generated/workflows
          
          # Create enhanced composition prompt
          cat > generated/metadata/compose-prompt.md << 'EOF'
          # Human-like Workflow Composition with Optimal Parallelization
          
          Compose a comprehensive GitHub Actions workflow that mimics human workflow patterns:
          
          ## Selected Units
          $(cat generated/metadata/unit-selection/selected-units.json)
          
          ## Task Decomposition
          $(cat generated/metadata/task-decomposition/task-plan.json)
          
          ## User Requirements
          ${{ needs.extract-requirements.outputs.user_request }}
          
          ## Composition Guidelines
          
          ### 1. Human-like Workflow Structure
          Create a workflow that follows natural human patterns:
          - **Initial Setup Phase**: Environment preparation, dependency checks
          - **Research & Planning Phase**: Information gathering, strategy formation
          - **Iterative Development Phase**: Multiple attempts with refinements
          - **Quality Assurance Phase**: Testing, validation, improvements
          - **Finalization Phase**: Polish, documentation, delivery
          
          ### 2. Optimal Parallel Execution
          Implement sophisticated parallelization:
          - **3-way parallel**: For independent research/analysis tasks
          - **4-way parallel**: For variation generation (e.g., multiple styles)
          - **5-way parallel**: For comprehensive coverage (e.g., multi-format)
          - Use matrix strategies where appropriate
          - Implement fan-out/fan-in patterns
          
          ### 3. Unit Integration Strategy
          For each minimal unit:
          - Read the YAML file from its path
          - Extract and adapt the job definition
          - Prefix job names with phase indicators (e.g., "research-", "generate-")
          - Connect outputs to inputs across jobs
          - Add retry logic for critical steps
          
          ### 4. Advanced Features
          Include human-like behaviors:
          - Progress tracking and status updates
          - Intermediate result saving
          - Quality gates between phases
          - Adaptive behavior based on results
          - Comprehensive error handling with fallbacks
          
          ### 5. Workflow Metadata
          Add detailed metadata:
          ```yaml
          name: "Dynamic Workflow - ${{ needs.extract-requirements.outputs.workflow_type }}"
          run-name: "ðŸš€ ${{ needs.extract-requirements.outputs.workflow_type }} | ${{ github.actor }} | Run #${{ github.run_number }}"
          
          on:
            workflow_dispatch:
              inputs:
                quality_mode:
                  description: 'Quality vs Speed preference'
                  type: choice
                  options: ['quality-first', 'balanced', 'speed-first']
                  default: 'balanced'
                parallel_scale:
                  description: 'Parallel execution scale'
                  type: choice
                  options: ['conservative', 'moderate', 'aggressive']
                  default: 'moderate'
                # Dynamic inputs based on requirements
          ```
          
          ### 6. Job Organization Pattern
          ```yaml
          jobs:
            # Phase 1: Setup & Planning (3-way parallel)
            setup-environment:
              runs-on: ubuntu-latest
              outputs: ...
            
            research-references:
              runs-on: ubuntu-latest
              outputs: ...
            
            plan-approach:
              runs-on: ubuntu-latest
              outputs: ...
            
            # Phase 2: Main Execution (4-5 way parallel based on needs)
            generate-variation-1:
              needs: [setup-environment, research-references, plan-approach]
              ...
            
            # Phase 3: Quality & Refinement
            quality-check:
              needs: [all-generation-jobs]
              ...
            
            # Phase 4: Final Assembly
            final-assembly:
              needs: [quality-check]
              ...
          ```
          
          Save the complete workflow as generated/workflows/dynamic-workflow.yml
          
          Also create a complexity report in generated/workflows/workflow-complexity.json:
          ```json
          {
            "total_jobs": 25,
            "parallel_groups": 5,
            "max_parallel_jobs": 5,
            "estimated_duration": "45-60 minutes",
            "complexity_score": 85
          }
          ```
          EOF
          
          # Execute comprehensive composition
          npx @anthropic-ai/claude-code \
            -f generated/metadata/compose-prompt.md \
            --allowedTools "Read,Write,Edit" \
            --permission-mode "acceptEdits" \
            --max-tokens 12000 || {
              # Create fallback workflow
              echo "âš ï¸ Creating fallback workflow..."
              cat > generated/workflows/dynamic-workflow.yml << 'FALLBACK'
          name: "Fallback Dynamic Workflow"
          run-name: "ðŸš€ Fallback Workflow | ${{ github.actor }}"
          
          on:
            workflow_dispatch:
              inputs:
                mode:
                  description: 'Execution mode'
                  type: choice
                  options: ['test', 'production']
                  default: 'test'
          
          jobs:
            execute:
              runs-on: ubuntu-latest
              steps:
                - name: Fallback Execution
                  run: echo "Fallback workflow executed"
          FALLBACK
              
              echo '{"total_jobs":1,"parallel_groups":1,"max_parallel_jobs":1,"estimated_duration":"5 minutes","complexity_score":10}' \
                > generated/workflows/workflow-complexity.json
            }
          
          # Validate and analyze generated workflow
          if [ -f "generated/workflows/dynamic-workflow.yml" ]; then
            echo "workflow_ready=true" >> $GITHUB_OUTPUT
            echo "workflow_path=generated/workflows/dynamic-workflow.yml" >> $GITHUB_OUTPUT
            
            # Calculate complexity
            JOB_COUNT=$(grep -c "^\s*[a-zA-Z0-9_-]*:\s*$" generated/workflows/dynamic-workflow.yml | grep -A1 "jobs:" | tail -1 || echo "1")
            COMPLEXITY=$(jq -r '.complexity_score // 50' generated/workflows/workflow-complexity.json 2>/dev/null || echo "50")
            
            echo "workflow_complexity=$COMPLEXITY" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Workflow Complexity Score: $COMPLEXITY/100"
          else
            echo "workflow_ready=false" >> $GITHUB_OUTPUT
            echo "workflow_complexity=0" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload Generated Workflow
        if: steps.compose.outputs.workflow_ready == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: generated-workflow
          path: generated/workflows/
          retention-days: 7

  # Phase 5: Validate & Deploy with Quality Assessment
  validate-and-deploy:
    needs: [compose-workflow, select-minimal-units, decompose-tasks, validate-trigger]
    runs-on: ubuntu-latest
    if: needs.compose-workflow.outputs.workflow_ready == 'true'
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Download Generated Workflow
        uses: actions/download-artifact@v4
        with:
          name: generated-workflow
          path: generated/workflows/
          
      - name: Comprehensive Workflow Validation
        id: validate
        run: |
          echo "âœ… Performing comprehensive workflow validation..."
          
          # YAML syntax check
          python3 -c "import yaml; yaml.safe_load(open('generated/workflows/dynamic-workflow.yml'))" || {
            echo "âŒ YAML syntax error"
            exit 1
          }
          
          # Structure validation
          VALIDATION_SCORE=0
          
          # Check required fields
          grep -q "^name:" generated/workflows/dynamic-workflow.yml && ((VALIDATION_SCORE+=20)) || echo "Missing: name"
          grep -q "^on:" generated/workflows/dynamic-workflow.yml && ((VALIDATION_SCORE+=20)) || echo "Missing: on trigger"
          grep -q "^jobs:" generated/workflows/dynamic-workflow.yml && ((VALIDATION_SCORE+=20)) || echo "Missing: jobs"
          grep -q "runs-on:" generated/workflows/dynamic-workflow.yml && ((VALIDATION_SCORE+=20)) || echo "Missing: runs-on"
          grep -q "steps:" generated/workflows/dynamic-workflow.yml && ((VALIDATION_SCORE+=20)) || echo "Missing: steps"
          
          echo "ðŸ“Š Validation Score: $VALIDATION_SCORE/100"
          
          if [ $VALIDATION_SCORE -lt 80 ]; then
            echo "âŒ Workflow validation failed (score: $VALIDATION_SCORE)"
            exit 1
          fi
          
          # Check complexity report
          if [ -f "generated/workflows/workflow-complexity.json" ]; then
            COMPLEXITY="${{ needs.compose-workflow.outputs.workflow_complexity }}"
            echo "ðŸ“Š Workflow Complexity: $COMPLEXITY/100"
            
            JOBS=$(jq -r '.total_jobs' generated/workflows/workflow-complexity.json)
            PARALLEL=$(jq -r '.max_parallel_jobs' generated/workflows/workflow-complexity.json)
            DURATION=$(jq -r '.estimated_duration' generated/workflows/workflow-complexity.json)
            
            echo "- Total Jobs: $JOBS"
            echo "- Max Parallel: $PARALLEL"
            echo "- Est. Duration: $DURATION"
          fi
          
          echo "âœ… Workflow validation passed!"
          
      - name: Deploy Workflow with Metadata
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "ðŸš€ Deploying human-like workflow..."
          
          # Generate workflow metadata
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          ISSUE_NUMBER="${{ needs.validate-trigger.outputs.issue_number }}"
          WORKFLOW_TYPE=$(echo "${{ needs.decompose-tasks.outputs.task_count }}" | cut -d'"' -f2)
          WORKFLOW_NAME="generated-issue-${ISSUE_NUMBER}-${TIMESTAMP}.yml"
          
          # Ensure directory exists
          mkdir -p .github/workflows/generated
          
          # Copy with .disabled for safety
          cp generated/workflows/dynamic-workflow.yml \
            .github/workflows/generated/${WORKFLOW_NAME}.disabled
          
          # Create comprehensive deployment summary
          cat > deployment-summary.md << 'EOF'
          ## ðŸŽ‰ Human-like Workflow Generated Successfully!
          
          **Workflow**: `$WORKFLOW_NAME`
          **Issue**: #$ISSUE_NUMBER
          **Status**: âœ… Deployed (disabled for safety)
          **Complexity**: ${{ needs.compose-workflow.outputs.workflow_complexity }}/100
          
          ### ðŸ“Š Workflow Statistics
          EOF
          
          if [ -f "generated/workflows/workflow-complexity.json" ]; then
            cat >> deployment-summary.md << 'EOF'
          - **Total Jobs**: $(jq -r '.total_jobs' generated/workflows/workflow-complexity.json)
          - **Parallel Groups**: $(jq -r '.parallel_groups' generated/workflows/workflow-complexity.json)
          - **Max Parallel Execution**: $(jq -r '.max_parallel_jobs' generated/workflows/workflow-complexity.json)
          - **Estimated Duration**: $(jq -r '.estimated_duration' generated/workflows/workflow-complexity.json)
          
          EOF
          fi
          
          cat >> deployment-summary.md << 'EOF'
          ### ðŸ§© Selected Minimal Units
          EOF
          
          # Add unit statistics
          UNIT_COUNT="${{ needs.select-minimal-units.outputs.unit_count }}"
          echo "- **Total Units Selected**: $UNIT_COUNT from 55 available units" >> deployment-summary.md
          
          cat >> deployment-summary.md << 'EOF'
          
          ### âš¡ Parallel Optimization
          The workflow implements optimal parallel execution patterns:
          - 3-way parallel for research/analysis phases
          - 4-way parallel for variation generation
          - 5-way parallel for comprehensive coverage
          
          ### ðŸš€ Activation Instructions
          1. Review the generated workflow file
          2. Remove `.disabled` extension to activate:
             ```bash
             mv .github/workflows/generated/$WORKFLOW_NAME.disabled \
                .github/workflows/generated/$WORKFLOW_NAME
             ```
          3. Commit and push the change
          4. Run the workflow via Actions tab
          
          ### ðŸ“ Generated Workflow Preview
          ```yaml
          $(head -100 generated/workflows/dynamic-workflow.yml)
          ...
          ```
          
          ---
          Generated by **Kamui Rossy v9.0** - Ultra-detailed minimal-unit based meta workflow system
          EOF
          
          # Post comprehensive summary to issue
          gh issue comment $ISSUE_NUMBER --body-file deployment-summary.md
          
      - name: Commit Generated Workflow
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git add .github/workflows/generated/
          git commit -m "feat: generate human-like workflow with ${{ needs.select-minimal-units.outputs.unit_count }} units for issue #${{ needs.validate-trigger.outputs.issue_number }}"
          git push