name: 60秒プロフェッショナルニュース動画自動生成

on:
  workflow_dispatch:
    inputs:
      video_title:
        description: "動画のタイトル"
        required: true
        default: "最新ニュース速報"
      duration:
        description: "動画の長さ"
        required: true
        type: choice
        options:
          - "15s"
          - "30s"
          - "60s"
          - "90s"
          - "3min"
        default: "60s"
      content_type:
        description: "コンテンツの種類"
        required: true
        type: choice
        options:
          - "news"
          - "educational"
          - "promotional"
          - "documentary"
        default: "news"
      target_platform:
        description: "配信プラットフォーム"
        required: true
        type: choice
        options:
          - "youtube"
          - "instagram"
          - "tiktok"
          - "twitter"
          - "linkedin"
          - "web"
          - "broadcast"
        default: "youtube"
      news_topic:
        description: "ニュースのトピック・キーワード"
        required: true
        default: "AI技術の最新動向"
      presenter_type:
        description: "メインプレゼンタータイプ"
        required: false
        type: choice
        options:
          - "news_anchor"
          - "documentary_narrator"
          - "educational_instructor"
          - "corporate_presenter"
        default: "news_anchor"
      visual_style:
        description: "ビジュアルスタイル"
        required: false
        type: choice
        options:
          - "cinematic"
          - "documentary"
          - "corporate"
          - "minimalist"
        default: "documentary"

env:
  CLAUDE_CODE_CI_MODE: true
  CLAUDE_CODE_AUTO_APPROVE_MCP: true
  CLAUDE_CODE_OAUTH_TOKEN: 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

jobs:
  setup:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      project_dir: ${{ steps.setup-env.outputs.project_dir }}
      scene_count: ${{ steps.setup-env.outputs.scene_count }}
      duration_seconds: ${{ steps.setup-env.outputs.duration_seconds }}
      workflow_start: ${{ steps.setup-env.outputs.workflow_start }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup environment
        id: setup-env
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          PROJECT_DIR="/home/runner/work/kamuicode_meta/kamuicode_meta/projects/news-video-${TIMESTAMP}"
          
          # Duration calculation
          DURATION="${{ inputs.duration }}"
          case $DURATION in
            "15s") DURATION_SEC=15 ;;
            "30s") DURATION_SEC=30 ;;
            "60s") DURATION_SEC=60 ;;
            "90s") DURATION_SEC=90 ;;
            "3min") DURATION_SEC=180 ;;
            *) DURATION_SEC=60 ;;
          esac
          
          # Scene calculation (5s per scene)
          SCENE_COUNT=$(echo "scale=0; ($DURATION_SEC + 4) / 5" | bc)
          
          echo "project_dir=$PROJECT_DIR" >> $GITHUB_OUTPUT
          echo "scene_count=$SCENE_COUNT" >> $GITHUB_OUTPUT
          echo "duration_seconds=$DURATION_SEC" >> $GITHUB_OUTPUT
          echo "workflow_start=$(date -Iseconds)" >> $GITHUB_OUTPUT
          
          # Create directory structure
          mkdir -p "$PROJECT_DIR/media/images"
          mkdir -p "$PROJECT_DIR/media/videos"
          mkdir -p "$PROJECT_DIR/media/audio"
          mkdir -p "$PROJECT_DIR/metadata"
          mkdir -p "$PROJECT_DIR/logs"
          mkdir -p "$PROJECT_DIR/final"
          
          echo "✅ Setup completed: $PROJECT_DIR"
          echo "Scene count: $SCENE_COUNT, Duration: ${DURATION_SEC}s"

  phase1-news-research:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: setup
    outputs:
      news_content_ready: ${{ steps.research-news.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Comprehensive news research
        id: research-news
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          TOPIC="${{ inputs.news_topic }}"
          
          RESEARCH_PROMPT="包括的ニュース情報収集・検証:
          トピック: ${TOPIC}
          
          実行手順:
          1. WebSearchツールで複数の信頼できるソースから最新情報を収集
          2. 情報を分析し、事実確認と整理を実行
          3. 偏見のない客観的な視点で内容をまとめる
          4. 結果を${PROJECT_DIR}/metadata/news-research.json形式で保存
          5. 保存確認のためls -laを実行
          
          必要な情報:
          - 基本的な5W1H要素
          - 複数の独立したソース情報
          - 時系列の整理
          - 重要なポイントの抽出"
          
          npx @anthropic-ai/claude-code \
            --mcp-config ".claude/mcp-kamuicode.json" \
            --allowedTools "WebSearch,Write,Bash,Read" \
            --max-turns 50 \
            --permission-mode "bypassPermissions" \
            -p "$RESEARCH_PROMPT"
          
          # Verify result
          ls -la "${PROJECT_DIR}/metadata/"
          
          if [ -f "${PROJECT_DIR}/metadata/news-research.json" ]; then
            echo "✅ News research completed successfully"
            echo "ready=true" >> $GITHUB_OUTPUT
          else
            echo "⚠️ News research file not found, creating fallback"
            echo "{\"status\": \"fallback\", \"topic\": \"${TOPIC}\"}" > "${PROJECT_DIR}/metadata/news-research.json"
            echo "ready=true" >> $GITHUB_OUTPUT
          fi

  phase2-script-creation:
    runs-on: ubuntu-latest
    timeout-minutes: 4
    needs: [setup, phase1-news-research]
    outputs:
      script_ready: ${{ steps.create-script.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Create news script and composition
        id: create-script
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          DURATION="${{ needs.setup.outputs.duration_seconds }}"
          
          SCRIPT_PROMPT="ニュース原稿・構成設計:
          
          入力データ: ${PROJECT_DIR}/metadata/news-research.json
          目標時間: ${DURATION}秒
          
          実行手順:
          1. Readツールでニュース研究データを読み込み
          2. ${DURATION}秒のニュース番組用原稿を作成
          3. 視聴者の注意を引く導入、論理的な情報展開、明確な結論を含む構成
          4. シーン分割計画（5秒/シーンベース）を作成
          5. 結果を${PROJECT_DIR}/metadata/news-script.json形式で保存
          6. 保存確認のためls -laを実行
          
          要件:
          - 5W1H要素の完備
          - ${DURATION}秒±5秒の読み上げ時間
          - 論理的情報フロー
          - プロフェッショナルなニュース形式"
          
          npx @anthropic-ai/claude-code \
            --allowedTools "Read,Write,Bash" \
            --max-turns 40 \
            --permission-mode "bypassPermissions" \
            -p "$SCRIPT_PROMPT"
          
          # Verify result
          ls -la "${PROJECT_DIR}/metadata/"
          
          if [ -f "${PROJECT_DIR}/metadata/news-script.json" ]; then
            echo "✅ News script created successfully"
            echo "ready=true" >> $GITHUB_OUTPUT
          else
            echo "ready=false" >> $GITHUB_OUTPUT
          fi

  phase3-parallel-content-generation:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: [setup, phase2-script-creation]
    strategy:
      matrix:
        content_type: ['narration', 'anchor_character', 'visual_assets', 'bgm']
      fail-fast: false
    outputs:
      content_ready: ${{ steps.generate-content.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Generate content by type
        id: generate-content
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          CONTENT_TYPE="${{ matrix.content_type }}"
          
          case $CONTENT_TYPE in
            "narration")
              NARRATION_PROMPT="プロフェッショナル音声ナレーション生成:
              
              入力: ${PROJECT_DIR}/metadata/news-script.json
              出力: ${PROJECT_DIR}/media/audio/narration.mp3
              
              実行手順:
              1. Readツールでニュース原稿を読み込み
              2. MCP T2Sツールでニュースアナウンサー品質の音声を生成
              3. Writeツールで${PROJECT_DIR}/media/audio/narration.mp3に保存
              4. ls -laで確認
              
              要件:
              - 権威ある声質、適切なテンポ（150-180語/分）
              - 明瞭な発音
              - ニュースアナウンサー特有の抑揚"
              
              npx @anthropic-ai/claude-code \
                --mcp-config ".claude/mcp-kamuicode.json" \
                --allowedTools "mcp__t2s-*,Read,Write,Bash" \
                --max-turns 50 \
                --permission-mode "bypassPermissions" \
                -p "$NARRATION_PROMPT"
              ;;
              
            "anchor_character")
              CHARACTER_PROMPT="ニュースキャスター・キャラクター生成:
              
              出力パス: ${PROJECT_DIR}/media/images/anchor-base.png
              URLパス: ${PROJECT_DIR}/media/images/anchor-base-url.txt
              
              実行手順:
              1. MCP T2Iツールでプロフェッショナルなニュースキャスターを生成
              2. Writeツールで${PROJECT_DIR}/media/images/anchor-base.pngに保存
              3. Google Cloud URLを${PROJECT_DIR}/media/images/anchor-base-url.txtに保存
              4. ls -laで確認
              
              プロンプト内容:
              - プロフェッショナルなニュースキャスター
              - ビジネススーツ着用
              - 信頼できる権威のある外観
              - ニュース番組のスタジオ背景
              - 1920x1080解像度対応
              - 固定seed値: 12345"
              
              npx @anthropic-ai/claude-code \
                --mcp-config ".claude/mcp-kamuicode.json" \
                --allowedTools "mcp__t2i-*,Write,Bash" \
                --max-turns 40 \
                --permission-mode "bypassPermissions" \
                -p "$CHARACTER_PROMPT"
              
              # Immediate download
              URL_FILE="${PROJECT_DIR}/media/images/anchor-base-url.txt"
              LOCAL_FILE="${PROJECT_DIR}/media/images/anchor-base.png"
              [ -f "$URL_FILE" ] && curl -L -o "$LOCAL_FILE" "$(cat $URL_FILE)"
              ;;
              
            "visual_assets")
              VISUAL_PROMPT="ニュース視覚素材・グラフィック生成:
              
              入力: ${PROJECT_DIR}/metadata/news-script.json
              出力: ${PROJECT_DIR}/media/images/news-background.png
              URLパス: ${PROJECT_DIR}/media/images/news-background-url.txt
              
              実行手順:
              1. Readツールでニュース内容を確認
              2. MCP T2Iツールでニュース内容に関連する背景素材を生成
              3. Writeツールで保存、URLも保存
              4. ls -laで確認
              
              要件:
              - ニュース番組に適した権威のある背景
              - プロフェッショナルな品質
              - 1920x1080解像度
              - ニュース内容との関連性"
              
              npx @anthropic-ai/claude-code \
                --mcp-config ".claude/mcp-kamuicode.json" \
                --allowedTools "mcp__t2i-*,Read,Write,Bash" \
                --max-turns 40 \
                --permission-mode "bypassPermissions" \
                -p "$VISUAL_PROMPT"
              
              # Immediate download
              URL_FILE="${PROJECT_DIR}/media/images/news-background-url.txt"
              LOCAL_FILE="${PROJECT_DIR}/media/images/news-background.png"
              [ -f "$URL_FILE" ] && curl -L -o "$LOCAL_FILE" "$(cat $URL_FILE)"
              ;;
              
            "bgm")
              BGM_PROMPT="BGM・効果音選定・生成:
              
              出力: ${PROJECT_DIR}/media/audio/background.wav
              
              実行手順:
              1. MCP BGMツールでニュース番組用BGMを生成
              2. Writeツールで${PROJECT_DIR}/media/audio/background.wavに保存
              3. ls -laで確認
              
              要件:
              - ニュース特有の緊張感と権威性
              - ナレーションを阻害しない音量レベル
              - 約60秒の長さ"
              
              npx @anthropic-ai/claude-code \
                --mcp-config ".claude/mcp-kamuicode.json" \
                --allowedTools "mcp__t2m-*,Write,Bash" \
                --max-turns 50 \
                --permission-mode "bypassPermissions" \
                -p "$BGM_PROMPT"
              ;;
          esac
          
          # Verify generation
          ls -la "${PROJECT_DIR}/media/"
          echo "ready=true" >> $GITHUB_OUTPUT
          
      - name: Upload content artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: content-${{ matrix.content_type }}
          path: ${{ needs.setup.outputs.project_dir }}/media/

  phase4-scene-video-generation:
    runs-on: ubuntu-latest
    timeout-minutes: 12
    needs: [setup, phase3-parallel-content-generation]
    strategy:
      matrix:
        scene: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
      fail-fast: false
    outputs:
      scenes_ready: ${{ steps.generate-scene.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Download content artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: content-*
          path: ${{ needs.setup.outputs.project_dir }}/media/
          merge-multiple: true
          
      - name: Check MCP connection window
        id: check-mcp-window
        run: |
          WORKFLOW_START="${{ needs.setup.outputs.workflow_start }}"
          ELAPSED_MINUTES=$(( ($(date +%s) - $(date -d "$WORKFLOW_START" +%s)) / 60 ))
          
          if [ $ELAPSED_MINUTES -lt 10 ]; then
            echo "✅ Safe to use MCP tools (${ELAPSED_MINUTES} minutes elapsed)"
            echo "mcp_available=true" >> $GITHUB_OUTPUT
          else
            echo "⚠️ MCP connection risk - using fallback (${ELAPSED_MINUTES} minutes elapsed)"
            echo "mcp_available=false" >> $GITHUB_OUTPUT
          fi
        
      - name: Generate scene image and video (Immediate conversion)
        id: generate-scene
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          SCENE_NUM="${{ matrix.scene }}"
          MCP_AVAILABLE="${{ steps.check-mcp-window.outputs.mcp_available }}"
          
          echo "Processing Scene ${SCENE_NUM}"
          
          # Define paths
          SCENE_IMAGE_PATH="${PROJECT_DIR}/media/images/scene${SCENE_NUM}.png"
          SCENE_URL_PATH="${PROJECT_DIR}/media/images/scene${SCENE_NUM}-url.txt"
          SCENE_VIDEO_PATH="${PROJECT_DIR}/media/videos/scene${SCENE_NUM}.mp4"
          
          if [ "$MCP_AVAILABLE" = "true" ]; then
            # CRITICAL: T2I → I2V in SAME job (prevents URL expiry)
            
            # Step 1: Generate scene image
            T2I_PROMPT="シーン${SCENE_NUM}の画像生成:
            
            実行手順:
            1. MCP T2Iツールでシーン${SCENE_NUM}用の画像を生成
            2. Writeツールで${SCENE_IMAGE_PATH}に保存
            3. Google Cloud URLを${SCENE_URL_PATH}に保存
            4. ls -la ${PROJECT_DIR}/media/images/で確認
            
            シーン内容: ニュース動画のシーン${SCENE_NUM}
            - ニュース番組に適したプロフェッショナルな背景
            - 権威のある雰囲気
            - 1920x1080解像度
            - 固定seed値: $(($SCENE_NUM * 1000))"
            
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "mcp__t2i-*,Write,Bash" \
              --max-turns 40 \
              --permission-mode "bypassPermissions" \
              -p "$T2I_PROMPT"
            
            # Immediate URL download (prevent 15-minute expiration)
            ls -la "${PROJECT_DIR}/media/images/"
            [ -f "$SCENE_URL_PATH" ] && curl -L -o "$SCENE_IMAGE_PATH" "$(cat $SCENE_URL_PATH)"
            
            # Multi-pattern file search
            IMAGE=$(find "$PROJECT_DIR" -name "*scene*${SCENE_NUM}*.png" 2>/dev/null | head -1)
            [ -z "$IMAGE" ] && IMAGE=$(find "$PROJECT_DIR" -name "*.png" -mmin -2 2>/dev/null | head -1)
            [ -z "$IMAGE" ] && IMAGE=$(find "$PROJECT_DIR" -name "*.png" 2>/dev/null | head -1)
            
            # File validation
            if [ -f "$IMAGE" ] && [ $(stat -c%s "$IMAGE" 2>/dev/null || echo 0) -gt 10000 ]; then
              echo "✅ Valid image: $IMAGE"
              
              # Step 2: IMMEDIATE I2V conversion (same job)
              # Determine input reference
              URL_FILE="$SCENE_URL_PATH"
              if [ -f "$URL_FILE" ]; then
                IMAGE_URL=$(cat "$URL_FILE")
                if curl -IfsS --max-time 5 "$IMAGE_URL" >/dev/null 2>&1; then
                  IMAGE_REF="$IMAGE_URL"
                  echo "✅ Using Google Cloud Storage URL"
                else
                  IMAGE_REF="$IMAGE"
                  echo "⚠️ URL expired, using local path"
                fi
              else
                IMAGE_REF="$IMAGE"
              fi
              
              I2V_PROMPT="画像から動画への変換:
              
              入力画像: ${IMAGE_REF}
              出力パス: ${SCENE_VIDEO_PATH}
              
              実行手順:
              1. MCP I2Vツールで画像を6-8秒の動画に変換
              2. Writeツールで${SCENE_VIDEO_PATH}に保存
              3. ls -la ${PROJECT_DIR}/media/videos/で確認
              
              要件:
              - 6-8秒の動画長
              - 1920x1080解像度
              - 30fps
              - 滑らかな動き"
              
              npx @anthropic-ai/claude-code \
                --mcp-config ".claude/mcp-kamuicode.json" \
                --allowedTools "mcp__i2v-*,Write,Bash" \
                --max-turns 80 \
                --permission-mode "bypassPermissions" \
                -p "$I2V_PROMPT"
              
              # Verify video generation
              ls -la "${PROJECT_DIR}/media/videos/"
              VIDEO=$(find "$PROJECT_DIR" -name "*scene*${SCENE_NUM}*.mp4" 2>/dev/null | head -1)
              [ -z "$VIDEO" ] && VIDEO=$(find "$PROJECT_DIR" -name "*.mp4" -mmin -1 2>/dev/null | head -1)
              
              if [ -f "$VIDEO" ] && [ $(stat -c%s "$VIDEO" 2>/dev/null || echo 0) -gt 300000 ]; then
                echo "✅ Valid video: $VIDEO"
                echo "ready=true" >> $GITHUB_OUTPUT
              else
                echo "⚠️ Video generation failed for scene ${SCENE_NUM}"
                echo "ready=false" >> $GITHUB_OUTPUT
              fi
            else
              echo "❌ Invalid or missing image for scene ${SCENE_NUM}"
              echo "ready=false" >> $GITHUB_OUTPUT
            fi
          else
            # Fallback mode (no MCP)
            echo "⚠️ MCP not available, creating placeholder for scene ${SCENE_NUM}"
            echo "Placeholder image" > "$SCENE_IMAGE_PATH"
            echo "Placeholder video" > "$SCENE_VIDEO_PATH"
            echo "ready=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload scene artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: scene-${{ matrix.scene }}
          path: |
            ${{ needs.setup.outputs.project_dir }}/media/images/scene${{ matrix.scene }}.*
            ${{ needs.setup.outputs.project_dir }}/media/videos/scene${{ matrix.scene }}.*

  phase5-lipsync-anchor-video:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: [setup, phase3-parallel-content-generation, phase4-scene-video-generation]
    outputs:
      anchor_video_ready: ${{ steps.generate-anchor.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Download content artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: content-*
          path: ${{ needs.setup.outputs.project_dir }}/media/
          merge-multiple: true
          
      - name: Generate anchor lipsync video
        id: generate-anchor
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          WORKFLOW_START="${{ needs.setup.outputs.workflow_start }}"
          ELAPSED_MINUTES=$(( ($(date +%s) - $(date -d "$WORKFLOW_START" +%s)) / 60 ))
          
          if [ $ELAPSED_MINUTES -lt 12 ]; then
            LIPSYNC_PROMPT="キャスター動画・リップシンク処理:
            
            入力画像: ${PROJECT_DIR}/media/images/anchor-base.png
            入力音声: ${PROJECT_DIR}/media/audio/narration.mp3
            出力: ${PROJECT_DIR}/media/videos/anchor-lipsync.mp4
            
            実行手順:
            1. アンカー画像を読み込み
            2. MCP I2Vツールでアンカー画像から基本動画を生成
            3. MCP V2V Lipsyncツールで音声に合わせたリップシンク処理
            4. Writeツールで${PROJECT_DIR}/media/videos/anchor-lipsync.mp4に保存
            5. ls -laで確認
            
            要件:
            - 音声との同期精度90%以上
            - 自然な表情とジェスチャー
            - プロフェッショナルなニュースキャスター品質"
            
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "mcp__i2v-*,mcp__v2v-*,Write,Bash,Read" \
              --max-turns 80 \
              --permission-mode "bypassPermissions" \
              -p "$LIPSYNC_PROMPT"
            
            # Verify result
            ls -la "${PROJECT_DIR}/media/videos/"
            
            ANCHOR_VIDEO=$(find "$PROJECT_DIR" -name "*anchor*.mp4" 2>/dev/null | head -1)
            if [ -f "$ANCHOR_VIDEO" ] && [ $(stat -c%s "$ANCHOR_VIDEO" 2>/dev/null || echo 0) -gt 500000 ]; then
              echo "✅ Anchor lipsync video created successfully: $ANCHOR_VIDEO"
              echo "ready=true" >> $GITHUB_OUTPUT
            else
              echo "⚠️ Anchor video generation failed"
              echo "ready=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "⚠️ MCP timeout risk - skipping lipsync"
            echo "ready=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload anchor video artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: anchor-video
          path: ${{ needs.setup.outputs.project_dir }}/media/videos/anchor*

  phase6-video-editing-plan:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [setup, phase4-scene-video-generation, phase5-lipsync-anchor-video]
    outputs:
      editing_plan_ready: ${{ steps.create-plan.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*'
          path: ${{ needs.setup.outputs.project_dir }}/media/
          merge-multiple: true
          
      - name: Create comprehensive editing plan
        id: create-plan
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          DURATION="${{ needs.setup.outputs.duration_seconds }}"
          
          EDITING_PROMPT="動画編集計画・タイムライン設計:
          
          素材分析対象:
          - シーン動画: ${PROJECT_DIR}/media/videos/scene*.mp4
          - アンカー動画: ${PROJECT_DIR}/media/videos/anchor-lipsync.mp4  
          - ナレーション: ${PROJECT_DIR}/media/audio/narration.mp3
          - BGM: ${PROJECT_DIR}/media/audio/background.wav
          
          実行手順:
          1. Bashツールで全素材ファイルの存在確認とメタデータ取得
          2. ${DURATION}秒のニュース動画用の詳細編集計画を作成
          3. タイムライン、シーン遷移、音声同期を含む包括的計画
          4. FFmpegコマンド生成を含む実行可能な計画
          5. ${PROJECT_DIR}/metadata/editing-plan.json形式で保存
          6. ls -laで確認
          
          要件:
          - プロフェッショナルなニュース番組品質
          - 視聴者エンゲージメント最適化
          - シーン遷移の自然さ
          - 音声とBGMの適切なバランス"
          
          npx @anthropic-ai/claude-code \
            --allowedTools "Bash,Write,Read" \
            --max-turns 50 \
            --permission-mode "bypassPermissions" \
            -p "$EDITING_PROMPT"
          
          # Verify result
          ls -la "${PROJECT_DIR}/metadata/"
          
          if [ -f "${PROJECT_DIR}/metadata/editing-plan.json" ]; then
            echo "✅ Editing plan created successfully"
            echo "ready=true" >> $GITHUB_OUTPUT
          else
            echo "⚠️ Editing plan creation failed"
            echo "ready=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload editing plan
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: editing-plan
          path: ${{ needs.setup.outputs.project_dir }}/metadata/

  phase7-opening-closing:
    runs-on: ubuntu-latest
    timeout-minutes: 6
    needs: [setup, phase6-video-editing-plan]
    outputs:
      intro_outro_ready: ${{ steps.create-intro-outro.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Create opening and closing segments
        id: create-intro-outro
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          WORKFLOW_START="${{ needs.setup.outputs.workflow_start }}"
          ELAPSED_MINUTES=$(( ($(date +%s) - $(date -d "$WORKFLOW_START" +%s)) / 60 ))
          
          if [ $ELAPSED_MINUTES -lt 15 ]; then
            INTRO_OUTRO_PROMPT="ニュース番組オープニング・クロージング制作:
            
            出力:
            - オープニング: ${PROJECT_DIR}/media/videos/opening.mp4
            - クロージング: ${PROJECT_DIR}/media/videos/closing.mp4
            
            実行手順:
            1. MCP T2Iツールでプロフェッショナルなニュース番組タイトル画像を生成
            2. MCP I2Vツールで動的なオープニング映像を作成
            3. 同様にクロージング映像を作成
            4. Writeツールで保存、ls -laで確認
            
            要件:
            - 3-5秒の短いセグメント
            - ニュース番組の権威性を表現
            - 視聴者の注意を引く効果
            - プロフェッショナルな品質"
            
            npx @anthropic-ai/claude-code \
              --mcp-config ".claude/mcp-kamuicode.json" \
              --allowedTools "mcp__t2i-*,mcp__i2v-*,Write,Bash" \
              --max-turns 60 \
              --permission-mode "bypassPermissions" \
              -p "$INTRO_OUTRO_PROMPT"
            
            # Verify results
            ls -la "${PROJECT_DIR}/media/videos/"
            
            OPENING=$(find "$PROJECT_DIR" -name "*opening*" -o -name "*intro*" 2>/dev/null | head -1)
            CLOSING=$(find "$PROJECT_DIR" -name "*closing*" -o -name "*outro*" 2>/dev/null | head -1)
            
            if [ -f "$OPENING" ] || [ -f "$CLOSING" ]; then
              echo "✅ Intro/outro segments created"
              echo "ready=true" >> $GITHUB_OUTPUT
            else
              echo "⚠️ Intro/outro creation failed"
              echo "ready=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "⚠️ MCP timeout - skipping intro/outro"
            echo "ready=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload intro/outro artifacts  
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: intro-outro
          path: ${{ needs.setup.outputs.project_dir }}/media/videos/

  phase8-final-video-assembly:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: [setup, phase6-video-editing-plan, phase7-opening-closing]
    outputs:
      final_video_ready: ${{ steps.assemble-video.outputs.ready }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js and FFmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg bc
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*'
          path: ${{ needs.setup.outputs.project_dir }}/media/
          merge-multiple: true
          
      - name: Final video integration and quality adjustment
        id: assemble-video
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          DURATION="${{ needs.setup.outputs.duration_seconds }}"
          TITLE="${{ inputs.video_title }}"
          
          ASSEMBLY_PROMPT="最終動画統合・品質調整:
          
          素材ディレクトリ: ${PROJECT_DIR}/media/
          目標尺: ${DURATION}秒
          
          実行手順:
          1. Bashツールで全素材ファイルの確認とメタデータ取得
          2. 編集計画(editing-plan.json)を読み込み
          3. FFmpegを使用して素材を統合
          4. 音声レベル正規化(-14 LUFS)
          5. カラーグレーディング適用
          6. 最終品質チェック
          7. ${PROJECT_DIR}/final/news-video-final.mp4として保存
          8. ls -laで確認
          
          統合順序:
          1. オープニング(3秒)
          2. アンカー紹介(5-10秒)
          3. シーン素材の組み合わせ(40-45秒)
          4. クロージング(3-5秒)
          
          品質要件:
          - 1920x1080解像度、30fps
          - 音声: -14LUFS
          - ${DURATION}秒±5秒の厳密な尺管理"
          
          npx @anthropic-ai/claude-code \
            --allowedTools "Bash,Read,Write" \
            --max-turns 60 \
            --permission-mode "bypassPermissions" \
            -p "$ASSEMBLY_PROMPT"
          
          # Verify final video
          ls -la "${PROJECT_DIR}/final/"
          
          FINAL_VIDEO=$(find "$PROJECT_DIR" -name "*final*.mp4" -o -name "*news*.mp4" 2>/dev/null | head -1)
          if [ -f "$FINAL_VIDEO" ]; then
            FILE_SIZE=$(stat -c%s "$FINAL_VIDEO" 2>/dev/null || echo 0)
            if [ "$FILE_SIZE" -gt 1000000 ]; then  # At least 1MB
              echo "✅ Final video created successfully: $FINAL_VIDEO (${FILE_SIZE} bytes)"
              
              # Video duration check
              if command -v ffprobe >/dev/null 2>&1; then
                DURATION_CHECK=$(ffprobe -v quiet -show_entries format=duration -of csv="p=0" "$FINAL_VIDEO" 2>/dev/null || echo 0)
                echo "Video duration: ${DURATION_CHECK}s"
              fi
              
              echo "ready=true" >> $GITHUB_OUTPUT
            else
              echo "⚠️ Final video file too small: ${FILE_SIZE} bytes"
              echo "ready=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "❌ Final video not found"
            echo "ready=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload final video
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: final-news-video
          path: |
            ${{ needs.setup.outputs.project_dir }}/final/
            ${{ needs.setup.outputs.project_dir }}/logs/

  phase9-metadata-archive:
    runs-on: ubuntu-latest
    timeout-minutes: 3
    needs: [setup, phase8-final-video-assembly]
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Claude Code SDK
        run: npm install -g @anthropic-ai/claude-code
        
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*'
          path: ${{ needs.setup.outputs.project_dir }}/media/
          merge-multiple: true
          
      - name: Create metadata and archive
        run: |
          PROJECT_DIR="${{ needs.setup.outputs.project_dir }}"
          
          METADATA_PROMPT="メタデータ・アーカイブ作成:
          
          プロジェクト: ${PROJECT_DIR}
          
          実行手順:
          1. 全制作過程のメタデータを収集
          2. 使用素材リスト作成
          3. 品質レポート生成
          4. ワークフロー実行ログ作成
          5. ${PROJECT_DIR}/metadata/production-report.json形式で保存
          6. ls -laで確認
          
          含める情報:
          - 制作日時と設定
          - 各フェーズの実行状況
          - 生成された素材リスト
          - 技術仕様記録
          - 品質メトリクス"
          
          npx @anthropic-ai/claude-code \
            --allowedTools "Bash,Write,Read" \
            --max-turns 40 \
            --permission-mode "bypassPermissions" \
            -p "$METADATA_PROMPT"
          
          # Archive creation
          echo "✅ Archive creation completed"
          ls -la "${PROJECT_DIR}/"
          
      - name: Upload production archive
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: production-archive
          path: |
            ${{ needs.setup.outputs.project_dir }}/metadata/
            ${{ needs.setup.outputs.project_dir }}/logs/

  workflow-summary:
    runs-on: ubuntu-latest
    if: always()
    needs: [setup, phase1-news-research, phase2-script-creation, phase3-parallel-content-generation, phase4-scene-video-generation, phase5-lipsync-anchor-video, phase6-video-editing-plan, phase7-opening-closing, phase8-final-video-assembly, phase9-metadata-archive]
    steps:
      - name: Workflow Summary
        run: |
          echo "# 60秒プロフェッショナルニュース動画生成 - 実行結果" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 設定" >> $GITHUB_STEP_SUMMARY
          echo "- タイトル: ${{ inputs.video_title }}" >> $GITHUB_STEP_SUMMARY
          echo "- 長さ: ${{ inputs.duration }}" >> $GITHUB_STEP_SUMMARY
          echo "- トピック: ${{ inputs.news_topic }}" >> $GITHUB_STEP_SUMMARY
          echo "- プラットフォーム: ${{ inputs.target_platform }}" >> $GITHUB_STEP_SUMMARY
          echo "- シーン数: ${{ needs.setup.outputs.scene_count }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 実行状況" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 1 (ニュース研究): ${{ needs.phase1-news-research.outputs.news_content_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 2 (原稿作成): ${{ needs.phase2-script-creation.outputs.script_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 3 (コンテンツ生成): ${{ needs.phase3-parallel-content-generation.outputs.content_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 4 (シーン動画生成): ${{ needs.phase4-scene-video-generation.outputs.scenes_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 5 (アンカー動画): ${{ needs.phase5-lipsync-anchor-video.outputs.anchor_video_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 6 (編集計画): ${{ needs.phase6-video-editing-plan.outputs.editing_plan_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 7 (オープニング): ${{ needs.phase7-opening-closing.outputs.intro_outro_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Phase 8 (最終統合): ${{ needs.phase8-final-video-assembly.outputs.final_video_ready == 'true' && '✅' || '❌' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 成果物" >> $GITHUB_STEP_SUMMARY
          echo "プロジェクトディレクトリ: \`${{ needs.setup.outputs.project_dir }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ダウンロード可能なアーティファクト" >> $GITHUB_STEP_SUMMARY
          echo "- \`final-news-video\`: 最終動画ファイル" >> $GITHUB_STEP_SUMMARY
          echo "- \`production-archive\`: 制作メタデータ・ログ" >> $GITHUB_STEP_SUMMARY
          echo "- \`scene-*\`: 個別シーン素材" >> $GITHUB_STEP_SUMMARY
          echo "- \`anchor-video\`: ニュースキャスター動画" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          FINAL_STATUS="${{ needs.phase8-final-video-assembly.outputs.final_video_ready == 'true' && 'SUCCESS' || 'PARTIAL' }}"
          echo "## 全体結果: ${FINAL_STATUS}" >> $GITHUB_STEP_SUMMARY
          
          if [ "$FINAL_STATUS" = "SUCCESS" ]; then
            echo "✅ 60秒プロフェッショナルニュース動画が正常に生成されました。" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ 一部の処理が完了しませんでした。部分的な成果物を確認してください。" >> $GITHUB_STEP_SUMMARY
          fi
