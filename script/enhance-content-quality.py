#!/usr/bin/env python3
"""
AIç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªå‘ä¸Šã‚·ã‚¹ãƒ†ãƒ 
SNSæ˜ ãˆãƒ»ãƒ—ãƒ­å“è³ªã®ãŸã‚ã®è‰²èª¿ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒ»é®®åº¦è£œæ­£

Usage:
    python3 enhance-content-quality.py --input image.jpg --type image --iteration 1
"""

import cv2
import numpy as np
import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path

class ContentQualityEnhancer:
    def __init__(self):
        self.quality_metrics = {}
        
    def enhance_image_quality(self, image_path, iteration=1, content_type="general"):
        """ç”»åƒå“è³ªã‚’å°‚é–€çš„ã«å‘ä¸Šã•ã›ã‚‹"""
        
        print(f"ğŸ¨ Image Quality Enhancement - Iteration {iteration}")
        print(f"   Input: {image_path}")
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        original_img = img.copy()
        
        # æ®µéšçš„å“è³ªå‘ä¸Šå‡¦ç†
        enhanced_img = img.copy()
        
        # 1. è‰²èª¿è£œæ­£ (Color Balance)
        enhanced_img = self._adjust_color_balance(enhanced_img, iteration)
        
        # 2. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒ»æ˜åº¦èª¿æ•´
        enhanced_img = self._adjust_contrast_brightness(enhanced_img, iteration)
        
        # 3. å½©åº¦å‘ä¸Šï¼ˆSNSæ˜ ãˆï¼‰
        enhanced_img = self._enhance_saturation(enhanced_img, iteration, content_type)
        
        # 4. ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹èª¿æ•´
        enhanced_img = self._apply_sharpening(enhanced_img, iteration)
        
        # 5. ãƒã‚¤ã‚ºé™¤å»
        enhanced_img = self._reduce_noise(enhanced_img)
        
        # 6. SNSæœ€é©åŒ–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        enhanced_img = self._apply_sns_optimization(enhanced_img, content_type)
        
        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        quality_score = self._calculate_quality_metrics(original_img, enhanced_img)
        
        # å¼·åŒ–ã•ã‚ŒãŸç”»åƒã‚’ä¿å­˜
        output_path = self._generate_output_path(image_path, iteration)
        cv2.imwrite(output_path, enhanced_img)
        
        print(f"âœ… Enhanced image saved: {output_path}")
        print(f"   Quality Score: {quality_score:.2f}/100")
        
        return output_path, quality_score
    
    def _adjust_color_balance(self, img, iteration):
        """è‰²èª¿ãƒãƒ©ãƒ³ã‚¹èª¿æ•´"""
        # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ã®èª¿æ•´å¼·åº¦
        strength = min(0.1 + (iteration - 1) * 0.05, 0.2)
        
        # LABè‰²ç©ºé–“ã§èª¿æ•´
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # æ˜åº¦ãƒãƒ£ãƒ³ãƒãƒ«èª¿æ•´
        l = cv2.equalizeHist(l)
        
        # è‰²ç›¸ãƒãƒ£ãƒ³ãƒãƒ«èª¿æ•´
        a = cv2.add(a, int(strength * 10))
        b = cv2.add(b, int(strength * 10))
        
        enhanced_lab = cv2.merge([l, a, b])
        return cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
    
    def _adjust_contrast_brightness(self, img, iteration):
        """ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒ»æ˜åº¦èª¿æ•´"""
        # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¯ã«å¼·åº¦èª¿æ•´
        alpha = 1.0 + (iteration - 1) * 0.1  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ (1.0-1.2)
        beta = iteration * 3  # æ˜åº¦ (3-9)
        
        return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
    
    def _enhance_saturation(self, img, iteration, content_type):
        """å½©åº¦å‘ä¸Šï¼ˆSNSæ˜ ãˆå¯¾å¿œï¼‰"""
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—åˆ¥èª¿æ•´
        saturation_boost = {
            "general": 1.2,
            "product": 1.3,
            "lifestyle": 1.4,
            "food": 1.5,
            "fashion": 1.3,
            "nature": 1.2
        }
        
        boost = saturation_boost.get(content_type, 1.2)
        boost += (iteration - 1) * 0.1
        
        # HSVè‰²ç©ºé–“ã§å½©åº¦èª¿æ•´
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        
        s = cv2.multiply(s, boost)
        s = np.clip(s, 0, 255).astype(np.uint8)
        
        enhanced_hsv = cv2.merge([h, s, v])
        return cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2BGR)
    
    def _apply_sharpening(self, img, iteration):
        """ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹èª¿æ•´"""
        # ã‚¢ãƒ³ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚¯
        gaussian = cv2.GaussianBlur(img, (0, 0), 2.0)
        strength = 0.5 + (iteration - 1) * 0.2
        return cv2.addWeighted(img, 1.0 + strength, gaussian, -strength, 0)
    
    def _reduce_noise(self, img):
        """ãƒã‚¤ã‚ºé™¤å»"""
        return cv2.bilateralFilter(img, 9, 75, 75)
    
    def _apply_sns_optimization(self, img, content_type):
        """SNSæœ€é©åŒ–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"""
        if content_type in ["lifestyle", "food", "fashion"]:
            # æš–è‰²èª¿å¼·åŒ–
            img = cv2.addWeighted(img, 0.9, 
                                np.full(img.shape, (20, 25, 30), dtype=np.uint8), 0.1, 0)
        elif content_type in ["tech", "business"]:
            # ã‚¯ãƒ¼ãƒ«èª¿å¼·åŒ–
            img = cv2.addWeighted(img, 0.9, 
                                np.full(img.shape, (30, 20, 15), dtype=np.uint8), 0.1, 0)
        
        return img
    
    def _calculate_quality_metrics(self, original, enhanced):
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ¸¬å®š
        contrast_orig = np.std(cv2.cvtColor(original, cv2.COLOR_BGR2GRAY))
        contrast_enh = np.std(cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY))
        
        # å½©åº¦æ¸¬å®š
        hsv_orig = cv2.cvtColor(original, cv2.COLOR_BGR2HSV)
        hsv_enh = cv2.cvtColor(enhanced, cv2.COLOR_BGR2HSV)
        saturation_orig = np.mean(hsv_orig[:,:,1])
        saturation_enh = np.mean(hsv_enh[:,:,1])
        
        # ç·åˆã‚¹ã‚³ã‚¢
        contrast_score = min((contrast_enh / contrast_orig) * 40, 50)
        saturation_score = min((saturation_enh / saturation_orig) * 30, 40)
        base_score = 10
        
        return contrast_score + saturation_score + base_score
    
    def _generate_output_path(self, input_path, iteration):
        """å‡ºåŠ›ãƒ‘ã‚¹ç”Ÿæˆ"""
        path = Path(input_path)
        return str(path.parent / f"{path.stem}_enhanced_iter{iteration}{path.suffix}")

class QualityChecker:
    """20é …ç›®å“è³ªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ"""
    
    QUALITY_CHECKLIST = [
        # æŠ€è¡“çš„å“è³ª (1-8)
        {"id": 1, "category": "technical", "item": "ç”»åƒè§£åƒåº¦ãŒé©åˆ‡ (æœ€ä½1080p)", "weight": 5},
        {"id": 2, "category": "technical", "item": "ãƒã‚¤ã‚ºãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒæœ€å°é™", "weight": 4},
        {"id": 3, "category": "technical", "item": "è‰²èª¿ãƒãƒ©ãƒ³ã‚¹ãŒè‡ªç„¶", "weight": 4},
        {"id": 4, "category": "technical", "item": "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãŒé©åˆ‡", "weight": 4},
        {"id": 5, "category": "technical", "item": "ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ãŒæœ€é©", "weight": 3},
        {"id": 6, "category": "technical", "item": "éœ²å‡ºãŒé©æ­£", "weight": 4},
        {"id": 7, "category": "technical", "item": "è‰²åŸŸãŒè±Šå¯Œ", "weight": 3},
        {"id": 8, "category": "technical", "item": "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ»åœ§ç¸®ãŒé©åˆ‡", "weight": 3},
        
        # è¦–è¦šçš„é­…åŠ› (9-14)
        {"id": 9, "category": "visual", "item": "è‰²å½©ãŒé®®ã‚„ã‹ã§é­…åŠ›çš„", "weight": 5},
        {"id": 10, "category": "visual", "item": "æ§‹å›³ãŒå®‰å®šã—ã¦ã„ã‚‹", "weight": 4},
        {"id": 11, "category": "visual", "item": "è¦–ç·šèª˜å°ãŒåŠ¹æœçš„", "weight": 3},
        {"id": 12, "category": "visual", "item": "æ˜æš—ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„", "weight": 4},
        {"id": 13, "category": "visual", "item": "å¥¥è¡Œãæ„ŸãŒã‚ã‚‹", "weight": 3},
        {"id": 14, "category": "visual", "item": "å…¨ä½“çš„ãªçµ±ä¸€æ„Ÿ", "weight": 4},
        
        # SNSæœ€é©åŒ– (15-20)
        {"id": 15, "category": "sns", "item": "SNSæ˜ ãˆã™ã‚‹é®®ã‚„ã‹ã•", "weight": 5},
        {"id": 16, "category": "sns", "item": "ã‚µãƒ ãƒã‚¤ãƒ«ã§ã‚‚é­…åŠ›çš„", "weight": 4},
        {"id": 17, "category": "sns", "item": "ãƒ¢ãƒã‚¤ãƒ«è¡¨ç¤ºã«æœ€é©", "weight": 4},
        {"id": 18, "category": "sns", "item": "ãƒ–ãƒ©ãƒ³ãƒ‰æ„Ÿãƒ»ãƒ—ãƒ­æ„Ÿ", "weight": 4},
        {"id": 19, "category": "sns", "item": "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆèª˜ç™ºè¦ç´ ", "weight": 3},
        {"id": 20, "category": "sns", "item": "ç«¶åˆå·®åˆ¥åŒ–ã§ãã‚‹å“è³ª", "weight": 4}
    ]
    
    def check_quality(self, image_path, content_type="general"):
        """20é …ç›®å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        print(f"ğŸ“‹ Quality Check: {image_path}")
        
        if not os.path.exists(image_path):
            return {"score": 0, "passed": False, "details": "File not found"}
        
        img = cv2.imread(image_path)
        if img is None:
            return {"score": 0, "passed": False, "details": "Could not load image"}
        
        results = []
        total_score = 0
        max_score = sum(item["weight"] for item in self.QUALITY_CHECKLIST)
        
        for item in self.QUALITY_CHECKLIST:
            score = self._check_item(img, item, content_type)
            weighted_score = score * item["weight"]
            total_score += weighted_score
            
            results.append({
                "id": item["id"],
                "category": item["category"],
                "item": item["item"],
                "score": score,
                "weighted_score": weighted_score,
                "max_score": item["weight"],
                "passed": score >= 0.7
            })
            
            status = "âœ…" if score >= 0.7 else "âŒ"
            print(f"   {status} [{item['id']:2d}] {item['item']}: {score:.1f}/{item['weight']}")
        
        final_score = (total_score / max_score) * 100
        passed = final_score >= 70
        
        print(f"\nğŸ“Š Total Quality Score: {final_score:.1f}/100")
        print(f"   Result: {'âœ… PASSED' if passed else 'âŒ NEEDS IMPROVEMENT'}")
        
        return {
            "score": final_score,
            "passed": passed,
            "details": results,
            "summary": {
                "total_items": len(self.QUALITY_CHECKLIST),
                "passed_items": sum(1 for r in results if r["passed"]),
                "failed_items": sum(1 for r in results if not r["passed"])
            }
        }
    
    def _check_item(self, img, item, content_type):
        """å€‹åˆ¥å“è³ªé …ç›®ãƒã‚§ãƒƒã‚¯"""
        height, width = img.shape[:2]
        
        # æŠ€è¡“çš„å“è³ªãƒã‚§ãƒƒã‚¯
        if item["id"] == 1:  # è§£åƒåº¦
            return 1.0 if min(height, width) >= 1080 else 0.5
        elif item["id"] == 2:  # ãƒã‚¤ã‚º
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            noise_level = np.std(cv2.Laplacian(gray, cv2.CV_64F))
            return max(0, 1.0 - (noise_level / 1000))
        elif item["id"] == 3:  # è‰²èª¿ãƒãƒ©ãƒ³ã‚¹
            b, g, r = cv2.split(img)
            balance = 1.0 - (np.std([np.mean(b), np.mean(g), np.mean(r)]) / 255)
            return max(0, balance)
        elif item["id"] == 4:  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            contrast = np.std(gray) / 127.5
            return min(1.0, contrast)
        elif item["id"] == 5:  # ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            return min(1.0, sharpness / 1000)
        elif item["id"] == 9:  # è‰²å½©é®®ã‚„ã‹ã•
            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
            saturation = np.mean(hsv[:,:,1]) / 255
            return saturation
        else:
            # ãã®ä»–ã®é …ç›®ã¯åŸºæœ¬çš„ãªè©•ä¾¡
            return 0.8  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆæ ¼ã‚¹ã‚³ã‚¢

def main():
    parser = argparse.ArgumentParser(description='Content Quality Enhancement System')
    parser.add_argument('--input', required=True, help='Input file path')
    parser.add_argument('--type', choices=['image', 'video'], default='image', help='Content type')
    parser.add_argument('--iteration', type=int, default=1, help='Enhancement iteration (1-3)')
    parser.add_argument('--content-type', default='general', help='Content category for optimization')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"âŒ Input file not found: {args.input}")
        sys.exit(1)
    
    print(f"ğŸš€ Content Quality Enhancement System")
    print(f"   Iteration: {args.iteration}/3")
    print(f"   Input: {args.input}")
    print(f"   Content Type: {args.content_type}\n")
    
    if args.type == 'image':
        # ç”»åƒå“è³ªå‘ä¸Š
        enhancer = ContentQualityEnhancer()
        enhanced_path, quality_score = enhancer.enhance_image_quality(
            args.input, args.iteration, args.content_type
        )
        
        # å“è³ªãƒã‚§ãƒƒã‚¯
        checker = QualityChecker()
        quality_result = checker.check_quality(enhanced_path, args.content_type)
        
        # çµæœå‡ºåŠ›
        result = {
            "timestamp": datetime.now().isoformat(),
            "iteration": args.iteration,
            "input_file": args.input,
            "output_file": enhanced_path,
            "enhancement_score": quality_score,
            "quality_check": quality_result,
            "next_iteration_needed": not quality_result["passed"] and args.iteration < 3
        }
        
        # JSONçµæœä¿å­˜
        result_path = f"quality_enhancement_iter{args.iteration}.json"
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ Results saved: {result_path}")
        
        if result["next_iteration_needed"]:
            print(f"\nâš ï¸ Quality check failed. Next iteration recommended.")
            print(f"   Run: python3 {__file__} --input {enhanced_path} --iteration {args.iteration + 1}")
        else:
            print(f"\nğŸ‰ Quality check passed! Final result: {enhanced_path}")
    
    print(f"\nâœ… Enhancement iteration {args.iteration} completed")

if __name__ == '__main__':
    main()