#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Task Node Extraction System
æ—¢å­˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ã‚¿ã‚¹ã‚¯ãƒãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã€å‹•çš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ„ã¿ç«‹ã¦ã«ä½¿ç”¨
"""

import yaml
import json
import os
import re
from typing import Dict, List, Any, Optional
from pathlib import Path

class TaskNodeExtractor:
    def __init__(self, templates_dir: str = "meta/examples"):
        self.templates_dir = Path(templates_dir)
        self.task_nodes = {}
        self.capabilities = {}
        
    def extract_all_nodes(self) -> Dict[str, Any]:
        """å…¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ã‚¿ã‚¹ã‚¯ãƒãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        for template_file in self.templates_dir.glob("*.yml"):
            if template_file.name == "README.md":
                continue
                
            try:
                with open(template_file, 'r', encoding='utf-8') as f:
                    template_data = yaml.safe_load(f)
                
                template_name = template_file.stem
                self.extract_nodes_from_template(template_name, template_data)
                
            except Exception as e:
                print(f"âš ï¸ Error processing {template_file}: {e}")
        
        return self.task_nodes
    
    def extract_nodes_from_template(self, template_name: str, template_data: Dict) -> None:
        """å€‹åˆ¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ã‚¿ã‚¹ã‚¯ãƒãƒ¼ãƒ‰æŠ½å‡º"""
        if 'tasks' not in template_data:
            return
            
        for task in template_data.get('tasks', []):
            node_id = f"{template_name}_{task.get('stage', 0)}_{len(self.task_nodes)}"
            
            # ã‚¿ã‚¹ã‚¯ãƒãƒ¼ãƒ‰ã®æ¨™æº–åŒ–
            task_node = {
                'id': node_id,
                'source_template': template_name,
                'stage': task.get('stage', 0),
                'name': task.get('name', 'Unknown Task'),
                'parallel': task.get('parallel', False),
                'jobs': task.get('jobs', []),
                'capabilities': self.extract_capabilities(task),
                'mcp_services': self.extract_mcp_services(template_data, task),
                'dependencies': task.get('depends_on', []),
                'duration_estimate': task.get('duration_minutes', 5),
                'complexity': task.get('complexity', 1)
            }
            
            self.task_nodes[node_id] = task_node
            
            # æ©Ÿèƒ½åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            for capability in task_node['capabilities']:
                if capability not in self.capabilities:
                    self.capabilities[capability] = []
                self.capabilities[capability].append(node_id)
    
    def extract_capabilities(self, task: Dict) -> List[str]:
        """ã‚¿ã‚¹ã‚¯ã®æ©Ÿèƒ½ã‚’æ¨å®šï¼ˆæ—¥æœ¬èªå¯¾å¿œå¼·åŒ–ï¼‰"""
        capabilities = []
        name = task.get('name', '').lower()
        jobs = [j.lower() for j in task.get('jobs', [])]
        
        # å¤šè¨€èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ©Ÿèƒ½æ¨å®š
        capability_keywords = {
            'text_to_image': [
                'image', 'generation', 'picture', 'visual', 't2i', 'imagen',
                'ç”»åƒ', 'ç”Ÿæˆ', 'ã‚¤ãƒ¡ãƒ¼ã‚¸', 'ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«', 'æç”»', 'ä½œç”»'
            ],
            'image_to_video': [
                'video', 'animation', 'motion', 'i2v', 'movie', 'clip',
                'å‹•ç”»', 'ãƒ“ãƒ‡ã‚ª', 'ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', 'æ˜ åƒ', 'ãƒ ãƒ¼ãƒ“ãƒ¼'
            ],
            'text_to_music': [
                'music', 'audio', 'sound', 'bgm', 't2m', 'lyria', 'composition',
                'éŸ³æ¥½', 'éŸ³å£°', 'ã‚µã‚¦ãƒ³ãƒ‰', 'ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª', 'ä½œæ›²', 'BGM'
            ],
            'video_to_audio': [
                'audio', 'extract', 'voice', 'v2a', 'sound', 'narration',
                'éŸ³å£°', 'æŠ½å‡º', 'ãƒœã‚¤ã‚¹', 'ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', 'ã‚»ãƒªãƒ•', 'SE'
            ],
            'text_analysis': [
                'analysis', 'processing', 'nlp', 'prompt', 'planning', 'concept',
                'åˆ†æ', 'è§£æ', 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ', 'è¨ˆç”»', 'ã‚³ãƒ³ã‚»ãƒ—ãƒˆ', 'ä¼ç”»'
            ],
            'quality_control': [
                'validation', 'quality', 'check', 'review', 'test', 'verify',
                'æ¤œè¨¼', 'å“è³ª', 'ãƒã‚§ãƒƒã‚¯', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼', 'ãƒ†ã‚¹ãƒˆ', 'ç¢ºèª'
            ],
            'file_management': [
                'package', 'format', 'output', 'save', 'export', 'compile',
                'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸', 'ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ', 'å‡ºåŠ›', 'ä¿å­˜', 'æ›¸ãå‡ºã—', 'ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ'
            ],
            '3d_generation': [
                '3d', 'model', 'three-dimensional', 'mesh', 'render',
                '3D', 'ãƒ¢ãƒ‡ãƒ«', 'ç«‹ä½“', 'ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°'
            ]
        }
        
        text_to_analyze = f"{name} {' '.join(jobs)}"
        
        for capability, keywords in capability_keywords.items():
            if any(keyword in text_to_analyze for keyword in keywords):
                capabilities.append(capability)
        
        return capabilities if capabilities else ['general']
    
    def extract_mcp_services(self, template_data: Dict, task: Dict) -> List[str]:
        """ä½¿ç”¨ã™ã‚‹MCPã‚µãƒ¼ãƒ“ã‚¹ã‚’æŠ½å‡º"""
        mcp_services = []
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå…¨ä½“ã‹ã‚‰MCPå‚ç…§ã‚’æ¢ã™
        template_str = str(template_data)
        mcp_patterns = [
            r'--mcp\s+([a-zA-Z0-9-_]+)',
            r'mcp[_-]([a-zA-Z0-9-_]+)',
            r't2i-([a-zA-Z0-9-_]+)',
            r'i2v-([a-zA-Z0-9-_]+)',
            r't2m-([a-zA-Z0-9-_]+)',
            r'v2a-([a-zA-Z0-9-_]+)'
        ]
        
        for pattern in mcp_patterns:
            matches = re.findall(pattern, template_str)
            mcp_services.extend(matches)
        
        return list(set(mcp_services))
    
    def find_nodes_for_requirements(self, requirements: List[str]) -> List[str]:
        """è¦æ±‚ã«åŸºã¥ã„ã¦é©åˆ‡ãªã‚¿ã‚¹ã‚¯ãƒãƒ¼ãƒ‰ã‚’é¸æŠï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        selected_nodes = []
        
        # è¦æ±‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ—ï¼ˆæ—¥æœ¬èªâ†’è‹±èªæ©Ÿèƒ½ï¼‰
        requirement_mapping = {
            'ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒ': 'text_to_image',
            'ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒç”Ÿæˆ': 'text_to_image', 
            'ç”»åƒç”Ÿæˆ': 'text_to_image',
            'ç”»åƒã‹ã‚‰å‹•ç”»': 'image_to_video',
            'ç”»åƒã‹ã‚‰å‹•ç”»ç”Ÿæˆ': 'image_to_video',
            'å‹•ç”»ç”Ÿæˆ': 'image_to_video',
            'ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³æ¥½': 'text_to_music',
            'ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³æ¥½ç”Ÿæˆ': 'text_to_music',
            'éŸ³æ¥½ç”Ÿæˆ': 'text_to_music',
            'BGM': 'text_to_music',
            'å‹•ç”»ã‹ã‚‰éŸ³å£°': 'video_to_audio',
            'å‹•ç”»ã‹ã‚‰éŸ³å£°æŠ½å‡º': 'video_to_audio',
            'éŸ³å£°æŠ½å‡º': 'video_to_audio',
            'ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³': 'video_to_audio',
            'ã‚»ãƒªãƒ•': 'video_to_audio',
            'SE': 'video_to_audio',
            '3D': '3d_generation',
            '3d': '3d_generation',
            'å“è³ª': 'quality_control',
            'ãƒ•ã‚¡ã‚¤ãƒ«': 'file_management',
            'åˆ†æ': 'text_analysis'
        }
        
        for requirement in requirements:
            req_lower = requirement.lower()
            
            # ç›´æ¥ãƒãƒƒãƒ”ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
            matched_capability = None
            for req_key, capability in requirement_mapping.items():
                if req_key.lower() in req_lower:
                    matched_capability = capability
                    break
            
            if matched_capability and matched_capability in self.capabilities:
                selected_nodes.extend(self.capabilities[matched_capability])
                print(f"ğŸ¯ '{requirement}' â†’ {matched_capability} â†’ {len(self.capabilities[matched_capability])} nodes")
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šéƒ¨åˆ†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
                for capability, node_ids in self.capabilities.items():
                    capability_keywords = capability.split('_')
                    if any(keyword in req_lower for keyword in capability_keywords):
                        selected_nodes.extend(node_ids)
                        print(f"ğŸ” '{requirement}' â†’ {capability} (partial) â†’ {len(node_ids)} nodes")
        
        # é‡è¤‡é™¤å»
        unique_nodes = list(set(selected_nodes))
        
        # å„ªå…ˆåº¦ã‚½ãƒ¼ãƒˆï¼ˆè¤‡é›‘ã•ã€ã‚¹ãƒ†ãƒ¼ã‚¸ã€ç¶™ç¶šæ™‚é–“ï¼‰
        sorted_nodes = sorted(unique_nodes, key=lambda n: (
            self.task_nodes[n]['stage'],
            self.task_nodes[n]['complexity'],
            self.task_nodes[n]['duration_estimate']
        ))
        
        return sorted_nodes
    
    def generate_dependency_order(self, selected_nodes: List[str]) -> List[List[str]]:
        """é¸æŠã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã«åŸºã¥ãå®Ÿè¡Œé †åºã‚’ç”Ÿæˆ"""
        stages = {}
        
        for node_id in selected_nodes:
            node = self.task_nodes[node_id]
            stage = node['stage']
            
            if stage not in stages:
                stages[stage] = []
            stages[stage].append(node_id)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸é †ã§ã‚½ãƒ¼ãƒˆ
        ordered_stages = [stages[stage] for stage in sorted(stages.keys())]
        
        return ordered_stages
    
    def save_node_database(self, output_file: str = ".meta/task-nodes.json"):
        """æŠ½å‡ºã—ãŸãƒãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜"""
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        database = {
            'task_nodes': self.task_nodes,
            'capabilities_index': self.capabilities,
            'extraction_metadata': {
                'total_nodes': len(self.task_nodes),
                'total_capabilities': len(self.capabilities),
                'source_templates': list(set(node['source_template'] for node in self.task_nodes.values()))
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(database, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Task node database saved: {output_file}")
        print(f"ğŸ“Š Total nodes: {len(self.task_nodes)}")
        print(f"ğŸ¯ Capabilities: {list(self.capabilities.keys())}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    extractor = TaskNodeExtractor()
    
    print("ğŸ” Extracting task nodes from templates...")
    extractor.extract_all_nodes()
    
    print("ğŸ’¾ Saving task node database...")
    extractor.save_node_database()
    
    # ãƒ†ã‚¹ãƒˆç”¨: ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢è¦æ±‚ã§ã®é¸æŠãƒ†ã‚¹ãƒˆ
    test_requirements = [
        "ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒç”Ÿæˆ",
        "ç”»åƒã‹ã‚‰å‹•ç”»ç”Ÿæˆ", 
        "ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³æ¥½ç”Ÿæˆ",
        "å‹•ç”»ã‹ã‚‰éŸ³å£°æŠ½å‡º"
    ]
    
    print(f"\nğŸ§ª Testing node selection for: {test_requirements}")
    selected = extractor.find_nodes_for_requirements(test_requirements)
    execution_order = extractor.generate_dependency_order(selected)
    
    print(f"ğŸ“‹ Selected nodes: {len(selected)}")
    print(f"âš¡ Execution stages: {len(execution_order)}")
    
    for i, stage in enumerate(execution_order):
        print(f"  Stage {i+1}: {[extractor.task_nodes[n]['name'] for n in stage]}")

if __name__ == "__main__":
    main()