#!/usr/bin/env python3
"""
ãƒ­ã‚°å±¥æ­´ã‹ã‚‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è‡ªå‹•æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ›´æ–°ã—ã¾ã™ï¼š
1. projects/workflow-execution-logs/meta-workflow-construction-checklist.md (æ±ç”¨)
2. meta/domain-templates/[domain]/checklist-[domain]-specific.md (ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰)
"""

import os
import sys
import re
import json
import yaml
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional

class ChecklistUpdater:
    def __init__(self, base_dir: Path = Path(".")):
        self.base_dir = base_dir
        self.logs_dir = base_dir / "projects" / "workflow-execution-logs"
        self.domain_templates_dir = base_dir / "meta" / "domain-templates"
        self.updates_made = []
        
    def parse_execution_log(self, log_file: Path) -> Dict:
        """å®Ÿè¡Œãƒ­ã‚°ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å•é¡Œã¨è§£æ±ºç­–ã‚’æŠ½å‡º"""
        issues = []
        solutions = []
        domain = None
        
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡º
            domain_match = re.search(r'Domain:\s*(\w+[-\w]*)', content)
            if domain_match:
                domain = domain_match.group(1)
            
            # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            error_patterns = [
                r'ERROR:\s*(.+?)(?:\n|$)',
                r'âŒ\s*(.+?)(?:\n|$)',
                r'Failed:\s*(.+?)(?:\n|$)',
                r'Issue:\s*(.+?)(?:\n|$)'
            ]
            
            for pattern in error_patterns:
                matches = re.findall(pattern, content, re.MULTILINE)
                for match in matches:
                    issues.append(match.strip())
            
            # è§£æ±ºç­–ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            solution_patterns = [
                r'Solution:\s*(.+?)(?:\n|$)',
                r'Fixed by:\s*(.+?)(?:\n|$)',
                r'âœ…\s*Fixed:\s*(.+?)(?:\n|$)',
                r'Action:\s*(.+?)(?:\n|$)'
            ]
            
            for pattern in solution_patterns:
                matches = re.findall(pattern, content, re.MULTILINE)
                for match in matches:
                    solutions.append(match.strip())
                    
        return {
            'domain': domain,
            'issues': issues,
            'solutions': solutions,
            'log_file': log_file.name
        }
    
    def categorize_issues(self, issues: List[Dict]) -> Dict[str, List]:
        """å•é¡Œã‚’æ±ç”¨çš„ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã«åˆ†é¡"""
        generic_issues = []
        domain_specific = {}
        
        # æ±ç”¨çš„ãªå•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
        generic_patterns = [
            'YAML syntax',
            'HEREDOC',
            'GitHub Actions',
            'artifact',
            'timeout',
            'MCP config',
            'file path',
            'uses:',
            'max-turns',
            'validation'
        ]
        
        for issue_data in issues:
            for issue in issue_data['issues']:
                is_generic = any(pattern.lower() in issue.lower() for pattern in generic_patterns)
                
                if is_generic:
                    generic_issues.append({
                        'issue': issue,
                        'solutions': issue_data.get('solutions', []),
                        'source': issue_data['log_file']
                    })
                elif issue_data['domain']:
                    if issue_data['domain'] not in domain_specific:
                        domain_specific[issue_data['domain']] = []
                    domain_specific[issue_data['domain']].append({
                        'issue': issue,
                        'solutions': issue_data.get('solutions', []),
                        'source': issue_data['log_file']
                    })
                    
        return {
            'generic': generic_issues,
            'domain_specific': domain_specific
        }
    
    def update_generic_checklist(self, issues: List[Dict]):
        """æ±ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’æ›´æ–°"""
        checklist_path = self.logs_dir / "meta-workflow-construction-checklist.md"
        
        if not checklist_path.exists():
            print(f"Creating new generic checklist at {checklist_path}")
            checklist_path.parent.mkdir(parents=True, exist_ok=True)
            content = self._create_generic_checklist_template()
        else:
            with open(checklist_path, 'r', encoding='utf-8') as f:
                content = f.read()
        
        # æ–°ã—ã„å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
        new_patterns = []
        for issue_data in issues:
            pattern = self._extract_pattern(issue_data['issue'])
            if pattern and pattern not in content:
                new_patterns.append({
                    'pattern': pattern,
                    'solution': issue_data['solutions'][0] if issue_data['solutions'] else 'Manual investigation required',
                    'source': issue_data['source']
                })
        
        if new_patterns:
            # æ—¢å­˜ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦è¿½åŠ 
            update_section = self._generate_update_section(new_patterns, 'generic')
            
            # Auto-generated sectionsãƒãƒ¼ã‚«ãƒ¼ã‚’æ¢ã™
            marker = "<!-- AUTO-GENERATED-PATTERNS -->"
            if marker in content:
                content = content.replace(marker, f"{marker}\n\n{update_section}")
            else:
                # ãƒãƒ¼ã‚«ãƒ¼ãŒãªã„å ´åˆã¯æœ€å¾Œã«è¿½åŠ 
                content += f"\n\n{marker}\n\n{update_section}"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
            with open(checklist_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.updates_made.append(f"Updated generic checklist: {len(new_patterns)} new patterns")
            print(f"âœ… Updated generic checklist with {len(new_patterns)} new patterns")
    
    def update_domain_checklist(self, domain: str, issues: List[Dict]):
        """ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’æ›´æ–°"""
        domain_dir = self.domain_templates_dir / domain
        if not domain_dir.exists():
            print(f"Warning: Domain directory not found: {domain_dir}")
            return
            
        checklist_path = domain_dir / f"checklist-{domain}-specific.md"
        
        if not checklist_path.exists():
            print(f"Creating new domain checklist at {checklist_path}")
            content = self._create_domain_checklist_template(domain)
        else:
            with open(checklist_path, 'r', encoding='utf-8') as f:
                content = f.read()
        
        # æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
        new_patterns = []
        for issue_data in issues:
            pattern = self._extract_pattern(issue_data['issue'])
            if pattern and pattern not in content:
                new_patterns.append({
                    'pattern': pattern,
                    'solution': issue_data['solutions'][0] if issue_data['solutions'] else 'Domain-specific investigation required',
                    'source': issue_data['source']
                })
        
        if new_patterns:
            update_section = self._generate_update_section(new_patterns, domain)
            
            marker = f"<!-- AUTO-GENERATED-{domain.upper()}-PATTERNS -->"
            if marker in content:
                content = content.replace(marker, f"{marker}\n\n{update_section}")
            else:
                content += f"\n\n{marker}\n\n{update_section}"
            
            with open(checklist_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.updates_made.append(f"Updated {domain} checklist: {len(new_patterns)} new patterns")
            print(f"âœ… Updated {domain} checklist with {len(new_patterns)} new patterns")
    
    def _extract_pattern(self, issue: str) -> Optional[str]:
        """å•é¡Œã‹ã‚‰å†åˆ©ç”¨å¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        # å…·ä½“çš„ãªå€¤ã‚’ä¸€èˆ¬åŒ–
        pattern = issue
        pattern = re.sub(r'\d+', 'N', pattern)  # æ•°å­—ã‚’ N ã«ç½®æ›
        pattern = re.sub(r'issue-\d+', 'issue-NUMBER', pattern)
        pattern = re.sub(r'/[\w/.-]+\.(yml|yaml|json)', '/PATH/FILE.EXT', pattern)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒçŸ­ã™ãã‚‹å ´åˆã¯ç„¡è¦–
        if len(pattern) < 10:
            return None
            
        return pattern
    
    def _generate_update_section(self, patterns: List[Dict], context: str) -> str:
        """æ›´æ–°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        section = f"### ğŸ”„ Auto-Updated Patterns ({timestamp})\n\n"
        
        for i, pattern_data in enumerate(patterns, 1):
            section += f"#### Pattern {context.upper()}-AUTO-{i:03d}\n"
            section += f"- **Issue**: {pattern_data['pattern']}\n"
            section += f"- **Solution**: {pattern_data['solution']}\n"
            section += f"- **Source**: {pattern_data['source']}\n"
            section += f"- **Auto-detected**: {timestamp}\n\n"
            
        return section
    
    def _create_generic_checklist_template(self) -> str:
        """æ±ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ"""
        return """# Meta Workflow Construction Checklist (Auto-Updated)

## ğŸš¨ Common Issues and Solutions

This document is automatically updated from workflow execution logs.

### Critical YAML Construction Issues
1. **HEREDOC in GitHub Actions**: Never use HEREDOC, use echo commands
2. **File path references**: Always use relative paths with variables
3. **MCP configuration**: Include --mcp-config for all MCP tools

### Validation Requirements
1. **Max turns for I2V**: Must be >= 80
2. **File size validation**: Check for files > 300KB
3. **Progressive reporting**: Use if: always() in at least 5 places

<!-- AUTO-GENERATED-PATTERNS -->

## ğŸ“ Manual Entries

Add any manual observations below this line.
"""
    
    def _create_domain_checklist_template(self, domain: str) -> str:
        """ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ"""
        return f"""# {domain.replace('-', ' ').title()} Domain-Specific Checklist

## ğŸ¯ Domain-Specific Patterns

This document is automatically updated from {domain} workflow execution logs.

### Domain Requirements
- Specific to {domain} workflows
- Auto-detected patterns from execution

<!-- AUTO-GENERATED-{domain.upper()}-PATTERNS -->

## ğŸ“ Manual Domain Insights

Add domain-specific insights below this line.
"""
    
    def scan_recent_logs(self, hours: int = 24) -> List[Dict]:
        """æœ€è¿‘ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        if not self.logs_dir.exists():
            print(f"Logs directory not found: {self.logs_dir}")
            return []
            
        log_files = list(self.logs_dir.glob("execution-log-*.md"))
        log_files.extend(list(self.logs_dir.glob("*.log")))
        
        issues = []
        for log_file in log_files:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚åˆ»ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            parsed = self.parse_execution_log(log_file)
            if parsed['issues']:
                issues.append(parsed)
                
        return issues
    
    def run(self, scan_hours: int = 24):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("ğŸ” Scanning execution logs...")
        all_issues = self.scan_recent_logs(scan_hours)
        
        if not all_issues:
            print("No issues found in recent logs")
            return
            
        print(f"Found {len(all_issues)} log files with issues")
        
        # å•é¡Œã‚’åˆ†é¡
        categorized = self.categorize_issues(all_issues)
        
        # æ±ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆæ›´æ–°
        if categorized['generic']:
            self.update_generic_checklist(categorized['generic'])
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆæ›´æ–°
        for domain, domain_issues in categorized['domain_specific'].items():
            self.update_domain_checklist(domain, domain_issues)
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        if self.updates_made:
            print("\nğŸ“Š Update Summary:")
            for update in self.updates_made:
                print(f"  - {update}")
        else:
            print("\nâœ… All checklists are up to date")


def main():
    parser = argparse.ArgumentParser(description='Update checklists from execution logs')
    parser.add_argument('--hours', type=int, default=24,
                       help='Scan logs from past N hours (default: 24)')
    parser.add_argument('--base-dir', type=str, default='.',
                       help='Base directory of the project')
    
    args = parser.parse_args()
    
    updater = ChecklistUpdater(Path(args.base_dir))
    updater.run(args.hours)


if __name__ == "__main__":
    main()