#!/usr/bin/env python3
"""
Domain-Specific Planning Validation Script
ã‚¿ã‚¹ã‚¯åˆ†è§£å¾Œã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆå‰ã®è¨ˆç”»æ®µéšæ¤œè¨¼
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple

class PlanningValidator:
    def __init__(self, task_decomposition_path: str, domain: str):
        self.task_decomposition_path = Path(task_decomposition_path)
        self.domain = domain
        self.issues = []
        self.warnings = []
        self.recommendations = []
        
    def validate_planning(self) -> Dict[str, Any]:
        """è¨ˆç”»æ®µéšã®åŒ…æ‹¬æ¤œè¨¼"""
        with open(self.task_decomposition_path) as f:
            decomposition = json.load(f)
        
        results = {
            "domain_requirements": self.validate_domain_requirements(decomposition),
            "pipeline_structure": self.validate_planned_pipeline_structure(decomposition), 
            "url_expiration_strategy": self.validate_url_expiration_strategy(decomposition),
            "parallel_optimization": self.validate_parallel_planning(decomposition),
            "mcp_usage_planning": self.validate_mcp_planning(decomposition),
            "issues": self.issues,
            "warnings": self.warnings,
            "recommendations": self.recommendations,
            "requires_modification": len(self.issues) > 0
        }
        
        return results
    
    def validate_domain_requirements(self, decomposition: Dict) -> bool:
        """ãƒ‰ãƒ¡ã‚¤ãƒ³è¦ä»¶æ¤œè¨¼"""
        if self.domain == "video-production":
            return self.validate_video_production_requirements(decomposition)
        elif self.domain == "article-blog":
            return self.validate_article_requirements(decomposition)
        return True
    
    def validate_video_production_requirements(self, decomposition: Dict) -> bool:
        """å‹•ç”»åˆ¶ä½œãƒ‰ãƒ¡ã‚¤ãƒ³è¦ä»¶æ¤œè¨¼"""
        tasks = decomposition.get("tasks", [])
        
        # å¿…é ˆè¦ç´ ãƒã‚§ãƒƒã‚¯
        required_elements = {
            "image_generation": False,
            "video_conversion": False,
            "audio_generation": False,
            "video_editing": False
        }
        
        for task in tasks:
            task_desc = task.get("description", "").lower()
            task_name = task.get("name", "").lower()
            combined = f"{task_name} {task_desc}"
            
            if "ç”»åƒ" in combined or "image" in combined:
                required_elements["image_generation"] = True
            if "å‹•ç”»" in combined and ("å¤‰æ›" in combined or "ç”Ÿæˆ" in combined or "i2v" in combined):
                required_elements["video_conversion"] = True
            if "éŸ³å£°" in combined or "audio" in combined or "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³" in combined:
                required_elements["audio_generation"] = True
            if "ç·¨é›†" in combined or "åˆæˆ" in combined or "composition" in combined:
                required_elements["video_editing"] = True
        
        missing = [k for k, v in required_elements.items() if not v]
        if missing:
            self.issues.append(f"âŒ Missing essential video production elements: {', '.join(missing)}")
            return False
        
        return True
    
    def validate_planned_pipeline_structure(self, decomposition: Dict) -> bool:
        """è¨ˆç”»ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹é€ æ¤œè¨¼"""
        tasks = decomposition.get("tasks", [])
        
        # ç›´åˆ—ä¸¦åˆ—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œå‡º
        image_tasks = []
        video_tasks = []
        
        for i, task in enumerate(tasks):
            task_desc = task.get("description", "").lower()
            task_name = task.get("name", "").lower()
            
            if "ç”»åƒç”Ÿæˆ" in f"{task_name} {task_desc}" or "image generation" in f"{task_name} {task_desc}":
                image_tasks.append(i)
            elif ("å‹•ç”»ç”Ÿæˆ" in f"{task_name} {task_desc}" or "video generation" in f"{task_name} {task_desc}" or 
                  "i2v" in f"{task_name} {task_desc}"):
                video_tasks.append(i)
        
        # ç›´åˆ—ä¸¦åˆ—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¨å¥¨
        if len(image_tasks) >= 3 and len(video_tasks) >= 3:
            # ä¾å­˜é–¢ä¿‚ç¢ºèª
            proper_dependencies = False
            for video_idx in video_tasks:
                video_task = tasks[video_idx]
                deps = video_task.get("dependencies", [])
                
                # ç”»åƒã‚¿ã‚¹ã‚¯ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
                for dep in deps:
                    dep_task_id = dep if isinstance(dep, str) else dep
                    for img_idx in image_tasks:
                        if tasks[img_idx].get("id") == dep_task_id:
                            proper_dependencies = True
                            break
            
            if not proper_dependencies:
                self.issues.append("âŒ CRITICAL: No proper imageâ†’video dependencies detected for URL expiration handling")
                self.recommendations.append("ğŸ”§ Implement serial-parallel pipeline: Individual image generation jobs â†’ Individual video conversion jobs")
                return False
        else:
            self.warnings.append("âš ï¸ Limited parallel processing detected - may impact efficiency")
        
        return True
    
    def validate_url_expiration_strategy(self, decomposition: Dict) -> bool:
        """URLæœŸé™åˆ‡ã‚Œå¯¾ç­–æ¤œè¨¼"""
        tasks = decomposition.get("tasks", [])
        
        # ãƒãƒƒãƒå‡¦ç†æ¤œå‡ºï¼ˆå•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        batch_processing_detected = False
        for task in tasks:
            desc = task.get("description", "").lower()
            if "å…¨ã¦" in desc and ("ç”»åƒ" in desc or "å‹•ç”»" in desc):
                batch_processing_detected = True
                break
            if "ä¸€æ‹¬" in desc and ("ç”Ÿæˆ" in desc or "å¤‰æ›" in desc):
                batch_processing_detected = True
                break
        
        if batch_processing_detected:
            self.issues.append("âŒ CRITICAL: Batch processing detected - high risk of Google URL expiration")
            self.recommendations.append("ğŸ”§ Switch to rolling processing: Generateâ†’Convertâ†’Generateâ†’Convert pattern")
            return False
        
        # URLä¿å­˜æˆ¦ç•¥ç¢ºèª
        url_strategy_found = False
        for task in tasks:
            desc = task.get("description", "").lower()
            if "url" in desc and ("ä¿å­˜" in desc or "è¨˜éŒ²" in desc or "save" in desc):
                url_strategy_found = True
                break
        
        if not url_strategy_found:
            self.warnings.append("âš ï¸ No explicit URL preservation strategy detected")
            self.recommendations.append("ğŸ’¡ Add Google URL saving to text files for each generated asset")
        
        return True
    
    def validate_parallel_planning(self, decomposition: Dict) -> bool:
        """ä¸¦åˆ—å‡¦ç†è¨ˆç”»æ¤œè¨¼"""
        tasks = decomposition.get("tasks", [])
        
        # ä¸¦åˆ—åŒ–å¯èƒ½ã‚¿ã‚¹ã‚¯ã®æ¤œå‡º
        parallelizable_groups = []
        current_group = []
        
        for task in tasks:
            deps = task.get("dependencies", [])
            if not deps:  # ä¾å­˜é–¢ä¿‚ãªã—
                current_group.append(task["name"])
            elif len(current_group) > 1:
                parallelizable_groups.append(current_group)
                current_group = [task["name"]]
            else:
                current_group = [task["name"]]
        
        if len(current_group) > 1:
            parallelizable_groups.append(current_group)
        
        # åŠ¹ç‡æ€§è©•ä¾¡
        total_parallel_potential = sum(len(group) for group in parallelizable_groups if len(group) > 1)
        if total_parallel_potential < 5:
            self.warnings.append("âš ï¸ Limited parallelization opportunities detected")
            self.recommendations.append("ğŸ’¡ Consider reorganizing independent tasks for better parallel execution")
        
        return True
    
    def validate_mcp_planning(self, decomposition: Dict) -> bool:
        """MCPä½¿ç”¨è¨ˆç”»æ¤œè¨¼"""
        tasks = decomposition.get("tasks", [])
        
        mcp_heavy_tasks = 0
        total_estimated_time = 0
        
        for task in tasks:
            desc = task.get("description", "").lower()
            minimal_units = task.get("minimal_units", [])
            estimated = task.get("estimated_duration", "0åˆ†")
            
            # æ™‚é–“æŠ½å‡º
            import re
            time_match = re.search(r'(\d+)åˆ†', estimated)
            if time_match:
                total_estimated_time += int(time_match.group(1))
            
            # MCP heavy ã‚¿ã‚¹ã‚¯åˆ¤å®š
            if any(unit in ["t2i", "i2v", "t2v", "t2s", "v2v"] for unit in minimal_units):
                mcp_heavy_tasks += 1
        
        # 15åˆ†åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if total_estimated_time > 15:
            self.warnings.append(f"âš ï¸ Total estimated time ({total_estimated_time}min) exceeds MCP safe window (15min)")
            self.recommendations.append("ğŸ”§ Front-load all MCP operations in first 12 minutes")
        
        if mcp_heavy_tasks > 8:
            self.warnings.append(f"âš ï¸ High MCP usage ({mcp_heavy_tasks} tasks) - timeout risk")
            self.recommendations.append("ğŸ”§ Consider fallback strategies for MCP-heavy operations")
        
        return True
    
    def validate_article_requirements(self, decomposition: Dict) -> bool:
        """è¨˜äº‹ãƒ»ãƒ–ãƒ­ã‚°ãƒ‰ãƒ¡ã‚¤ãƒ³è¦ä»¶æ¤œè¨¼"""
        tasks = decomposition.get("tasks", [])
        
        required_elements = {
            "research": False,
            "content_generation": False,
            "formatting": False
        }
        
        for task in tasks:
            combined = f"{task.get('name', '')} {task.get('description', '')}".lower()
            
            if "èª¿æŸ»" in combined or "research" in combined or "æƒ…å ±åé›†" in combined:
                required_elements["research"] = True
            if "è¨˜äº‹" in combined or "content" in combined or "åŸ·ç­†" in combined:
                required_elements["content_generation"] = True
            if "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ" in combined or "format" in combined or "æ•´å½¢" in combined:
                required_elements["formatting"] = True
        
        missing = [k for k, v in required_elements.items() if not v]
        if missing:
            self.issues.append(f"âŒ Missing essential article elements: {', '.join(missing)}")
            return False
        
        return True

def main():
    if len(sys.argv) != 3:
        print("Usage: python domain-planning-validator.py <task_decomposition_path> <domain>")
        sys.exit(1)
    
    task_decomposition_path = sys.argv[1]
    domain = sys.argv[2]
    
    validator = PlanningValidator(task_decomposition_path, domain)
    results = validator.validate_planning()
    
    print("# Domain-Specific Planning Validation Report")
    print()
    
    if results['issues']:
        print("## ğŸš¨ Critical Planning Issues")
        for issue in results['issues']:
            print(f"- {issue}")
        print()
    
    if results['warnings']:
        print("## âš ï¸ Planning Warnings")
        for warning in results['warnings']:
            print(f"- {warning}")
        print()
    
    if results['recommendations']:
        print("## ğŸ’¡ Improvement Recommendations")
        for rec in results['recommendations']:
            print(f"- {rec}")
        print()
    
    print("## ğŸ“Š Planning Validation Results")
    for category, result in results.items():
        if category not in ['issues', 'warnings', 'recommendations', 'requires_modification']:
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"- **{category.replace('_', ' ').title()}**: {status}")
    
    if results['requires_modification']:
        print("\n## ğŸ”§ **ACTION REQUIRED: PLANNING MODIFICATION NEEDED**")
        sys.exit(1)
    else:
        print("\n## âœ… **PLANNING VALIDATION: APPROVED FOR GENERATION**")
        sys.exit(0)

if __name__ == "__main__":
    main()