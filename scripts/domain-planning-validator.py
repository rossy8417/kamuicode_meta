#!/usr/bin/env python3
"""
Domain-Specific Planning Validation Script
„Çø„Çπ„ÇØÂàÜËß£Âæå„ÄÅ„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÁîüÊàêÂâç„ÅÆË®àÁîªÊÆµÈöéÊ§úË®º
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple

class PlanningValidator:
    def __init__(self, task_decomposition_path: str, domain: str):
        self.task_decomposition_path = Path(task_decomposition_path)
        self.domain = domain
        self.issues = []
        self.warnings = []
        self.recommendations = []
        
    def validate_planning(self) -> Dict[str, Any]:
        """Ë®àÁîªÊÆµÈöé„ÅÆÂåÖÊã¨Ê§úË®º"""
        with open(self.task_decomposition_path) as f:
            decomposition = json.load(f)
        
        results = {
            "domain_requirements": self.validate_domain_requirements(decomposition),
            "pipeline_structure": self.validate_planned_pipeline_structure(decomposition), 
            "url_expiration_strategy": self.validate_url_expiration_strategy(decomposition),
            "parallel_optimization": self.validate_parallel_planning(decomposition),
            "mcp_usage_planning": self.validate_mcp_planning(decomposition),
            "issues": self.issues,
            "warnings": self.warnings,
            "recommendations": self.recommendations,
            "requires_modification": len(self.issues) > 0
        }
        
        return results
    
    def validate_domain_requirements(self, decomposition: Dict) -> bool:
        """„Éâ„É°„Ç§„É≥Ë¶Å‰ª∂Ê§úË®º"""
        if self.domain == "video-production":
            return self.validate_video_production_requirements(decomposition)
        elif self.domain == "article-blog":
            return self.validate_article_requirements(decomposition)
        return True
    
    def validate_video_production_requirements(self, decomposition: Dict) -> bool:
        """ÂãïÁîªÂà∂‰Ωú„Éâ„É°„Ç§„É≥Ë¶Å‰ª∂Ê§úË®º"""
        tasks = decomposition.get("tasks", [])
        
        # ÂøÖÈ†àË¶ÅÁ¥†„ÉÅ„Çß„ÉÉ„ÇØ
        required_elements = {
            "image_generation": False,
            "video_conversion": False,
            "audio_generation": False,
            "video_editing": False
        }
        
        for task in tasks:
            task_desc = task.get("description", "").lower()
            task_name = task.get("name", "").lower()
            combined = f"{task_name} {task_desc}"
            
            if "ÁîªÂÉè" in combined or "image" in combined:
                required_elements["image_generation"] = True
            if "ÂãïÁîª" in combined and ("Â§âÊèõ" in combined or "ÁîüÊàê" in combined or "i2v" in combined):
                required_elements["video_conversion"] = True
            if "Èü≥Â£∞" in combined or "audio" in combined or "„Éä„É¨„Éº„Ç∑„Éß„É≥" in combined:
                required_elements["audio_generation"] = True
            if "Á∑®ÈõÜ" in combined or "ÂêàÊàê" in combined or "composition" in combined:
                required_elements["video_editing"] = True
        
        missing = [k for k, v in required_elements.items() if not v]
        if missing:
            self.issues.append(f"‚ùå Missing essential video production elements: {', '.join(missing)}")
            return False
        
        return True
    
    def validate_planned_pipeline_structure(self, decomposition: Dict) -> bool:
        """Ë®àÁîª„Åï„Çå„Åü„Éë„Ç§„Éó„É©„Ç§„É≥ÊßãÈÄ†Ê§úË®º"""
        tasks = decomposition.get("tasks", [])
        
        # Áõ¥Âàó‰∏¶Âàó„Éë„Ç§„Éó„É©„Ç§„É≥Ê§úÂá∫
        image_tasks = []
        video_tasks = []
        
        for i, task in enumerate(tasks):
            task_desc = task.get("description", "").lower()
            task_name = task.get("name", "").lower()
            
            if "ÁîªÂÉèÁîüÊàê" in f"{task_name} {task_desc}" or "image generation" in f"{task_name} {task_desc}":
                image_tasks.append(i)
            elif ("ÂãïÁîªÁîüÊàê" in f"{task_name} {task_desc}" or "video generation" in f"{task_name} {task_desc}" or 
                  "i2v" in f"{task_name} {task_desc}"):
                video_tasks.append(i)
        
        # Áõ¥Âàó‰∏¶Âàó„Éë„Ç§„Éó„É©„Ç§„É≥Êé®Â•®
        if len(image_tasks) >= 3 and len(video_tasks) >= 3:
            # ‰æùÂ≠òÈñ¢‰øÇÁ¢∫Ë™ç
            proper_dependencies = False
            for video_idx in video_tasks:
                video_task = tasks[video_idx]
                deps = video_task.get("dependencies", [])
                
                # ÁîªÂÉè„Çø„Çπ„ÇØ„Å´‰æùÂ≠ò„Åó„Å¶„ÅÑ„Çã„ÅãÔºü
                for dep in deps:
                    dep_task_id = dep if isinstance(dep, str) else dep
                    for img_idx in image_tasks:
                        if tasks[img_idx].get("id") == dep_task_id:
                            proper_dependencies = True
                            break
            
            if not proper_dependencies:
                self.issues.append("‚ùå CRITICAL: No proper image‚Üívideo dependencies detected for URL expiration handling")
                self.recommendations.append("üîß Implement serial-parallel pipeline: Individual image generation jobs ‚Üí Individual video conversion jobs")
                return False
        else:
            self.warnings.append("‚ö†Ô∏è Limited parallel processing detected - may impact efficiency")
        
        return True
    
    def validate_url_expiration_strategy(self, decomposition: Dict) -> bool:
        """URLÊúüÈôêÂàá„ÇåÂØæÁ≠ñÊ§úË®º"""
        tasks = decomposition.get("tasks", [])
        
        # „Éê„ÉÉ„ÉÅÂá¶ÁêÜÊ§úÂá∫ÔºàÂïèÈ°å„Éë„Çø„Éº„É≥Ôºâ
        batch_processing_detected = False
        for task in tasks:
            desc = task.get("description", "").lower()
            if "ÂÖ®„Å¶" in desc and ("ÁîªÂÉè" in desc or "ÂãïÁîª" in desc):
                batch_processing_detected = True
                break
            if "‰∏ÄÊã¨" in desc and ("ÁîüÊàê" in desc or "Â§âÊèõ" in desc):
                batch_processing_detected = True
                break
        
        if batch_processing_detected:
            self.issues.append("‚ùå CRITICAL: Batch processing detected - high risk of Google URL expiration")
            self.recommendations.append("üîß Switch to rolling processing: Generate‚ÜíConvert‚ÜíGenerate‚ÜíConvert pattern")
            return False
        
        # URL‰øùÂ≠òÊà¶Áï•Á¢∫Ë™ç
        url_strategy_found = False
        for task in tasks:
            desc = task.get("description", "").lower()
            if "url" in desc and ("‰øùÂ≠ò" in desc or "Ë®òÈå≤" in desc or "save" in desc):
                url_strategy_found = True
                break
        
        if not url_strategy_found:
            self.warnings.append("‚ö†Ô∏è No explicit URL preservation strategy detected")
            self.recommendations.append("üí° Add Google URL saving to text files for each generated asset")
        
        return True
    
    def validate_parallel_planning(self, decomposition: Dict) -> bool:
        """‰∏¶ÂàóÂá¶ÁêÜË®àÁîªÊ§úË®º"""
        tasks = decomposition.get("tasks", [])
        
        # ‰∏¶ÂàóÂåñÂèØËÉΩ„Çø„Çπ„ÇØ„ÅÆÊ§úÂá∫
        parallelizable_groups = []
        current_group = []
        
        for task in tasks:
            deps = task.get("dependencies", [])
            if not deps:  # ‰æùÂ≠òÈñ¢‰øÇ„Å™„Åó
                current_group.append(task["name"])
            elif len(current_group) > 1:
                parallelizable_groups.append(current_group)
                current_group = [task["name"]]
            else:
                current_group = [task["name"]]
        
        if len(current_group) > 1:
            parallelizable_groups.append(current_group)
        
        # ÂäπÁéáÊÄßË©ï‰æ°
        total_parallel_potential = sum(len(group) for group in parallelizable_groups if len(group) > 1)
        if total_parallel_potential < 5:
            self.warnings.append("‚ö†Ô∏è Limited parallelization opportunities detected")
            self.recommendations.append("üí° Consider reorganizing independent tasks for better parallel execution")
        
        return True
    
    def validate_mcp_planning(self, decomposition: Dict) -> bool:
        """MCP‰ΩøÁî®Ë®àÁîªÊ§úË®º"""
        tasks = decomposition.get("tasks", [])
        
        mcp_heavy_tasks = 0
        total_estimated_time = 0
        
        for task in tasks:
            desc = task.get("description", "").lower()
            minimal_units = task.get("minimal_units", [])
            estimated = task.get("estimated_duration", "0ÂàÜ")
            
            # ÊôÇÈñìÊäΩÂá∫
            import re
            time_match = re.search(r'(\d+)ÂàÜ', estimated)
            if time_match:
                total_estimated_time += int(time_match.group(1))
            
            # MCP heavy „Çø„Çπ„ÇØÂà§ÂÆö
            if any(unit in ["t2i", "i2v", "t2v", "t2s", "v2v"] for unit in minimal_units):
                mcp_heavy_tasks += 1
        
        # 15ÂàÜÂà∂Èôê„ÉÅ„Çß„ÉÉ„ÇØ
        if total_estimated_time > 15:
            self.warnings.append(f"‚ö†Ô∏è Total estimated time ({total_estimated_time}min) exceeds MCP safe window (15min)")
            self.recommendations.append("üîß Front-load all MCP operations in first 12 minutes")
        
        if mcp_heavy_tasks > 8:
            self.warnings.append(f"‚ö†Ô∏è High MCP usage ({mcp_heavy_tasks} tasks) - timeout risk")
            self.recommendations.append("üîß Consider fallback strategies for MCP-heavy operations")
        
        return True
    
    def validate_article_requirements(self, decomposition: Dict) -> bool:
        """Ë®ò‰∫ã„Éª„Éñ„É≠„Ç∞„Éâ„É°„Ç§„É≥Ë¶Å‰ª∂Ê§úË®º"""
        tasks = decomposition.get("tasks", [])
        
        required_elements = {
            "research": False,
            "content_generation": False,
            "formatting": False
        }
        
        for task in tasks:
            combined = f"{task.get('name', '')} {task.get('description', '')}".lower()
            
            if "Ë™øÊüª" in combined or "research" in combined or "ÊÉÖÂ†±ÂèéÈõÜ" in combined:
                required_elements["research"] = True
            if "Ë®ò‰∫ã" in combined or "content" in combined or "Âü∑Á≠Ü" in combined:
                required_elements["content_generation"] = True
            if "„Éï„Ç©„Éº„Éû„ÉÉ„Éà" in combined or "format" in combined or "Êï¥ÂΩ¢" in combined:
                required_elements["formatting"] = True
        
        missing = [k for k, v in required_elements.items() if not v]
        if missing:
            self.issues.append(f"‚ùå Missing essential article elements: {', '.join(missing)}")
            return False
        
        return True

def main():
    if len(sys.argv) != 3:
        print("Usage: python domain-planning-validator.py <task_decomposition_path> <domain>")
        sys.exit(1)
    
    task_decomposition_path = sys.argv[1]
    domain = sys.argv[2]
    
    validator = PlanningValidator(task_decomposition_path, domain)
    results = validator.validate_planning()
    
    print("# Domain-Specific Planning Validation Report")
    print()
    
    if results['issues']:
        print("## üö® Critical Planning Issues")
        for issue in results['issues']:
            print(f"- {issue}")
        print()
    
    if results['warnings']:
        print("## ‚ö†Ô∏è Planning Warnings")
        for warning in results['warnings']:
            print(f"- {warning}")
        print()
    
    if results['recommendations']:
        print("## üí° Improvement Recommendations")
        for rec in results['recommendations']:
            print(f"- {rec}")
        print()
    
    print("## üìä Planning Validation Results")
    for category, result in results.items():
        if category not in ['issues', 'warnings', 'recommendations', 'requires_modification']:
            status = "‚úÖ PASS" if result else "‚ùå FAIL"
            print(f"- **{category.replace('_', ' ').title()}**: {status}")
    
    if results['requires_modification']:
        print("\n## üîß **ACTION REQUIRED: PLANNING MODIFICATION NEEDED**")
        sys.exit(1)
    else:
        print("\n## ‚úÖ **PLANNING VALIDATION: APPROVED FOR GENERATION**")
        sys.exit(0)

if __name__ == "__main__":
    main()